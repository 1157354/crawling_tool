2018-10-27 23:32:29,870 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-27 23:32:35,783 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:32:35] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-27 23:32:38,619 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:32:38] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-27 23:33:12,091 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:12] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-27 23:33:12,235 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:12] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:12,318 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-27 23:33:12,339 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-27 23:33:12,344 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-27 23:33:12,373 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-27 23:33:12,409 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-27 23:33:12,452 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-27 23:33:12,455 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-27 23:33:12,485 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-27 23:33:12,486 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-27 23:33:12,495 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:33:12,497 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-27 23:33:14,924 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:33:15,132 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/11/30/art_12_206775.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,136 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/8/24/art_12_209032.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,140 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/12/7/art_12_206842.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,145 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/7/2/art_12_208638.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,150 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/12/4/art_12_206821.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,153 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/7/17/art_12_208771.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,160 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207215.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,183 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/1/4/art_12_207124.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,186 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/12/30/art_12_207076.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,197 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/8/31/art_12_209099.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,209 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/3/27/art_12_207739.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,212 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/4/8/art_12_207841.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,217 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/11/13/art_12_206635.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,273 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 447:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬690å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹ï¼Œ...
2018-10-27 23:33:15,276 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,276 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,277 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,277 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4081
2018-10-27 23:33:15,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,279 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/11/30/art_12_206775.html>
None
2018-10-27 23:33:15,281 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/9/29/art_12_209295.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,288 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,324 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:15] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:15,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4428:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬702å·ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå…¨å›½ç»æµæ™®æŸ¥æ¡ä¾‹ã€‰çš„å†³å®šã€‹å·²...
2018-10-27 23:33:15,359 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :34151
2018-10-27 23:33:15,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,364 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/8/24/art_12_209032.html>
None
2018-10-27 23:33:15,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,414 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3023:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬692å·ç°å…¬å¸ƒã€Šä¸­åäººæ°‘å…±å’Œå›½åé—´è°æ³•å®æ–½ç»†åˆ™ã€‹ï¼Œè‡ªå…¬...
2018-10-27 23:33:15,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,420 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :54320
2018-10-27 23:33:15,421 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,422 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,422 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/12/7/art_12_206842.html>
None
2018-10-27 23:33:15,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,463 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2599:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬699å·ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šå¥¥æ—åŒ¹å…‹æ ‡å¿—ä¿æŠ¤æ¡ä¾‹ã€‹ï¼Œè‡ª20...
2018-10-27 23:33:15,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :71243
2018-10-27 23:33:15,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,470 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/7/2/art_12_208638.html>
None
2018-10-27 23:33:15,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,521 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5470:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬691å·ã€Šå›½åŠ¡é™¢å…³äºåºŸæ­¢ã€ˆä¸­åäººæ°‘å…±å’Œå›½è¥ä¸šç¨æš‚è¡Œæ¡ä¾‹...
2018-10-27 23:33:15,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :106457
2018-10-27 23:33:15,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,528 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/12/4/art_12_206821.html>
None
2018-10-27 23:33:15,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,581 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4961:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬700å·ã€ŠäººåŠ›èµ„æºå¸‚åœºæš‚è¡Œæ¡ä¾‹ã€‹å·²ç»2018å¹´5æœˆ2æ—¥...
2018-10-27 23:33:15,586 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,587 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :139090
2018-10-27 23:33:15,591 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,591 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,591 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/7/17/art_12_208771.html>
None
2018-10-27 23:33:15,592 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,654 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 8454:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬695å·ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆè§„ç« åˆ¶å®šç¨‹åºæ¡ä¾‹ã€‰çš„å†³...
2018-10-27 23:33:15,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,664 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,665 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,665 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :193711
2018-10-27 23:33:15,669 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,669 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,670 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207215.html>
None
2018-10-27 23:33:15,673 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207214.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:33:15,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3464:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬696å· ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šé£Ÿç›ä¸“è¥åŠæ³•ã€‹ï¼Œè‡ªå…¬å¸ƒä¹‹æ—¥èµ·...
2018-10-27 23:33:15,744 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :217222
2018-10-27 23:33:15,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,752 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/1/4/art_12_207124.html>
None
2018-10-27 23:33:15,755 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2777:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬693å· ç°å…¬å¸ƒã€Šä¸­åäººæ°‘å…±å’Œå›½ç¯å¢ƒä¿æŠ¤ç¨æ³•å®æ–½æ¡ä¾‹ã€‹...
2018-10-27 23:33:15,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,807 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,808 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :235554
2018-10-27 23:33:15,813 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,813 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,814 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/12/30/art_12_207076.html>
None
2018-10-27 23:33:15,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,926 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7512:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬701å· ã€ŠåŒ»ç–—çº çº·é¢„é˜²å’Œå¤„ç†æ¡ä¾‹ã€‹å·²ç»2018å¹´6æœˆ...
2018-10-27 23:33:15,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:15,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:15,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:15,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:15,937 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :283443
2018-10-27 23:33:15,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:15,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:15,941 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/8/31/art_12_209099.html>
None
2018-10-27 23:33:15,942 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:15,996 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6604:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬697å·ã€Šå¿«é€’æš‚è¡Œæ¡ä¾‹ã€‹å·²ç»2018å¹´2æœˆ7æ—¥å›½åŠ¡é™¢ç¬¬...
2018-10-27 23:33:16,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:16,012 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:16,012 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:16,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:16,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :326012
2018-10-27 23:33:16,018 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:16,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:16,019 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/3/27/art_12_207739.html>
None
2018-10-27 23:33:16,020 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:16,115 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3247:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬698å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹å’ŒåºŸæ­¢éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³...
2018-10-27 23:33:16,128 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:16,130 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:16,130 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:16,131 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:16,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :346879
2018-10-27 23:33:16,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:16,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:16,138 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/4/8/art_12_207841.html>
None
2018-10-27 23:33:16,139 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:16,201 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5531:  ç¬¬689å·ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šä¸­å›½äººæ°‘è§£æ”¾å†›æ–‡èŒäººå‘˜æ¡ä¾‹ã€‹ï¼Œè‡ªå…¬å¸ƒä¹‹æ—¥èµ·æ–½è¡Œã€‚ä¸­å¤®...
2018-10-27 23:33:16,205 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gov.cn:80
2018-10-27 23:33:16,284 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gov.cn:80 "GET /zhengce/content/2017-11/10/5238592/images/ec0d8820938642c2be5d4a8a632a6057.jpg HTTP/1.1" 200 15945
2018-10-27 23:33:16,318 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.chinalaw.gov.cn/art/2017/11/13/art_12_206635.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:33:16_ec0d8820938642c2be5d4a8a632a6057.jpg'
2018-10-27 23:33:16,320 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:16,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4298:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬703å·ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹ï¼Œè‡ª...
2018-10-27 23:33:16,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:16,378 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:16,378 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:16,378 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:16,379 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :373974
2018-10-27 23:33:16,385 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:16,385 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:16,386 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/9/29/art_12_209295.html>
None
2018-10-27 23:33:16,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:33:16,465 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7964:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬694å·ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆè¡Œæ”¿æ³•è§„åˆ¶å®šç¨‹åºæ¡ä¾‹ã€‰...
2018-10-27 23:33:16,479 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:33:16,481 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:33:16,481 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:33:16,481 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:91907
2018-10-27 23:33:16,483 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :425554
2018-10-27 23:33:16,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:33:16,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:33:16,490 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207214.html>
None
2018-10-27 23:33:18,434 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:18] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:19,195 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:nosw
2018-10-27 23:33:19,195 - /Users/tian/zaluan/ScrapyA/app/views.py[line:374] - INFO: nosw
2018-10-27 23:33:21,200 - /Users/tian/zaluan/ScrapyA/app/views.py[line:391] - INFO: userinfo in crawling:{}
2018-10-27 23:33:21,219 - /Users/tian/zaluan/ScrapyA/app/views.py[line:393] - INFO: before
2018-10-27 23:33:21,220 - /Users/tian/zaluan/ScrapyA/app/views.py[line:394] - INFO: after:open
2018-10-27 23:33:21,531 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:21] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:24,619 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:24] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:26,227 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:26] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-27 23:33:26,399 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-27 23:33:26,414 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-27 23:33:26,418 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-27 23:33:26,448 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-27 23:33:26,484 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-27 23:33:27,506 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": []}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": []}}}
2018-10-27 23:33:27,507 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): 127.0.0.1:57239
2018-10-27 23:33:27,704 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:27] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:28,987 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session HTTP/1.1" 200 903
2018-10-27 23:33:28,991 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:28,992 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:80] - INFO: é¡µç æ‰€åœ¨çš„xpath://*[@id="1648"]/table/tbody/tr/td/table
2018-10-27 23:33:29,035 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-27 23:33:29,038 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-27 23:33:29,067 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-27 23:33:29,068 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-27 23:33:29,074 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:33:29,076 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6024
2018-10-27 23:33:29,258 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1> (referer: None)
2018-10-27 23:33:29,361 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/url {"url": "http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:30,692 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/url HTTP/1.1" 200 72
2018-10-27 23:33:30,693 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:30,694 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/source {"sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:30,700 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/source HTTP/1.1" 200 19682
2018-10-27 23:33:30,701 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:30,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2018/9/29/art_12_209295.html', '/art/2018/8/31/art_12_209099.html', '/art/2018/8/24/art_12_209032.html', '/art/2018/7/17/art_12_208771.html', '/art/2018/7/2/art_12_208638.html', '/art/2018/4/8/art_12_207841.html', '/art/2018/3/27/art_12_207739.html', '/art/2018/1/16/art_12_207215.html', '/art/2018/1/16/art_12_207214.html', '/art/2018/1/4/art_12_207124.html', '/art/2017/12/30/art_12_207076.html', '/art/2017/12/7/art_12_206842.html', '/art/2017/12/4/art_12_206821.html', '/art/2017/11/30/art_12_206775.html', '/art/2017/11/13/art_12_206635.html']
2018-10-27 23:33:30,817 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:30] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:33,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:142] - INFO: ttt
2018-10-27 23:33:33,714 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:33,730 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:33,731 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:33,904 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:33] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:34,232 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:34,243 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:34,244 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:34,745 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:34,752 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:34,752 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:35,254 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:35,264 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:35,265 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:35,767 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:35,777 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:35,777 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:36,279 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:36,289 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:36,290 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:36,791 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:36,804 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:36,805 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:36,992 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:37,305 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:37,316 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:37,316 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:37,817 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:37,825 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:37,826 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:38,326 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:38,334 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:38,334 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:38,835 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:38,842 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:38,843 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:39,344 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:39,351 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:39,352 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:39,852 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:39,859 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:39,860 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:40,087 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:40] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:40,361 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:40,371 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:40,372 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:40,874 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:40,884 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:40,885 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:41,386 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:41,397 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:41,398 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:41,900 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:41,910 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:41,911 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:42,412 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:42,422 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:42,423 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:42,925 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:42,935 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:42,935 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:43,189 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:43] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:43,380 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:33:43,436 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:43,446 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:43,446 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:43,489 - /anaconda3/lib/python3.6/site-packages/scrapy/dupefilters.py[line:70] - DEBUG: Filtered duplicate request: <GET http://www.chinalaw.gov.cn/art/2018/4/8/art_12_207841.html> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-27 23:33:43,495 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (finished)
2018-10-27 23:33:43,499 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-27 23:33:43,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-27 23:33:43,500 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8826,
 'downloader/request_count': 17,
 'downloader/request_method_count/GET': 15,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 176410,
 'downloader/response_count': 17,
 'downloader/response_status_count/200': 17,
 'dupefilter/filtered': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 10, 27, 15, 33, 43, 499498),
 'item_scraped_count': 14,
 'log_count/DEBUG': 94,
 'log_count/ERROR': 1,
 'log_count/INFO': 79,
 'memusage/max': 63524864,
 'memusage/startup': 63520768,
 'request_depth_max': 2,
 'response_received_count': 17,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'spider_exceptions/FileNotFoundError': 1,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 15, 33, 12, 495606)}
2018-10-27 23:33:43,501 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (finished)
2018-10-27 23:33:43,948 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:43,958 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:43,959 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:44,460 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:44,471 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:44,472 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:44,973 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:44,984 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:44,984 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:45,486 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:45,496 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:45,496 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:45,998 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:46,008 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:46,009 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:46,291 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:46] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:46,511 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:46,521 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:46,521 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:47,023 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:47,033 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:47,033 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:47,535 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:47,546 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:47,547 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:48,048 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:48,058 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:48,058 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:48,559 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:48,569 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:48,569 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:49,071 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:49,077 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:49,078 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:49,401 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:49] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:49,578 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:49,585 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:49,586 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:50,087 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:50,098 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:50,099 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:50,601 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:50,608 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:50,609 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:51,110 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:51,123 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:51,124 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:51,626 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:51,636 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:51,636 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:52,138 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:52,149 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:52,150 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:52,488 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:52] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:52,651 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:52,665 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:52,665 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:53,166 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:53,176 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:53,177 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:53,678 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:53,689 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:33:53,690 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:54,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:149] - DEBUG: the error is Message: 

2018-10-27 23:33:54,191 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:151] - INFO: aaaaa
2018-10-27 23:33:54,192 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:54,205 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 102
2018-10-27 23:33:54,206 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:54,206 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:155] - INFO: bbbbb
2018-10-27 23:33:54,206 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/clear {"id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:54,222 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/clear HTTP/1.1" 200 72
2018-10-27 23:33:54,222 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:54,223 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:157] - INFO: ppppp
2018-10-27 23:33:54,223 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value {"text": "2", "value": ["2"], "id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:54,287 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value HTTP/1.1" 200 72
2018-10-27 23:33:54,287 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:54,288 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:159] - INFO: yyyyy
2018-10-27 23:33:54,288 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "tag name", "value": "html", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:54,299 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 102
2018-10-27 23:33:54,300 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:54,300 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:161] - INFO: 00000
2018-10-27 23:33:54,300 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:54,329 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value HTTP/1.1" 200 72
2018-10-27 23:33:54,330 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:54,330 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:163] - INFO: 11111
2018-10-27 23:33:54,330 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:54,338 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:54,338 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:54,839 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:54,846 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:54,848 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:55,349 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:55,358 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:55,359 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:55,584 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:55] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:55,861 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:55,868 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:55,869 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:56,370 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:56,378 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:56,380 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:56,882 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:56,889 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:56,890 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:57,390 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:57,401 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:57,402 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:57,903 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:57,911 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:57,911 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:58,412 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:58,420 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:58,421 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:58,693 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:33:58] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:33:58,921 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:58,927 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:58,927 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:59,428 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:59,433 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:59,434 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:33:59,935 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:33:59,940 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:33:59,940 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:00,441 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:00,447 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:00,447 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:00,949 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:00,954 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:00,954 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:01,455 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:01,460 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:01,460 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:01,783 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:01] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:01,961 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:01,970 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:01,971 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:02,472 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:02,479 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:02,480 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:02,982 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:02,989 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:02,989 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:03,491 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:03,498 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:03,499 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:04,000 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:04,007 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:04,008 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:04,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:167] - DEBUG: again the error is Message: 

2018-10-27 23:34:04,510 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:168] - DEBUG: æ²¡æ‰¾åˆ°æ–¹æ¡†
2018-10-27 23:34:04,511 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:04,525 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:04,525 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:04,880 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:04] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:05,027 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:05,036 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:05,037 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:05,537 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:05,548 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:05,548 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:06,050 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:06,060 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:06,061 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:06,561 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:06,582 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:06,583 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:07,083 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:07,095 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:07,095 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:07,597 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:07,608 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:07,609 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:07,968 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:07] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:08,110 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:08,120 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:08,121 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:08,622 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:08,632 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:08,633 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:09,133 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:09,143 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:09,143 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:09,645 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:09,656 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:09,658 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:10,161 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:10,168 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:10,169 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:10,669 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:10,683 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:10,683 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:11,054 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:11] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:11,184 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:11,191 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:11,191 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:11,692 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:11,698 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:11,699 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:12,200 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:12,207 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:12,207 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:12,709 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:12,719 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:12,719 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:13,221 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:13,230 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:13,231 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:13,731 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:13,742 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:13,742 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:14,244 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:14,256 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:14,257 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:14,308 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:14] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:14,758 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:14,768 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:14,769 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:15,270 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:15,279 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:15,280 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:15,782 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:15,791 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:15,792 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:16,293 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:16,301 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:16,302 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:16,803 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:16,813 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:16,813 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:17,315 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:17,326 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:17,326 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:17,413 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:17] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:17,828 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:17,837 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:17,838 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:18,339 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:18,349 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:18,349 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:18,851 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:18,867 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:18,868 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:19,369 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:19,379 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:19,379 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:19,880 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:19,890 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:19,891 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:20,391 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:20,398 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:20,399 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:20,501 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:20] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:20,900 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:20,909 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:20,910 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:21,411 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:21,419 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:21,419 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:21,920 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:21,928 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:21,929 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:22,430 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:22,438 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:22,439 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:22,939 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:22,947 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:22,947 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:23,448 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:23,459 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:23,460 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:23,673 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:23] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:23,962 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:23,971 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:23,972 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:24,474 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[1]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:24,483 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:34:24,484 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:24,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:175] - DEBUG: æ— æ³•ç‚¹å‡»
2018-10-27 23:34:26,765 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:26] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:26,987 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/source {"sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:26,995 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/source HTTP/1.1" 200 19514
2018-10-27 23:34:26,996 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:26,999 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2017/10/30/art_12_206524.html', '/art/2017/10/24/art_12_206461.html', '/art/2017/9/7/art_12_206178.html', '/art/2017/9/6/art_12_206160.html', '/art/2017/8/23/art_12_206046.html', '/art/2017/8/21/art_12_206018.html', '/art/2017/8/2/art_12_205857.html', '/art/2017/6/20/art_12_205442.html', '/art/2017/5/22/art_12_89728.html', '/art/2017/5/3/art_12_89727.html', '/art/2017/4/5/art_12_89726.html', '/art/2017/3/22/art_12_89725.html', '/art/2017/2/28/art_12_89724.html', '/art/2017/2/24/art_12_89723.html', '/art/2016/12/14/art_12_89722.html']
2018-10-27 23:34:29,875 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:29] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:30,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:142] - INFO: ttt
2018-10-27 23:34:30,028 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:30,037 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:30,037 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:30,539 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:30,550 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:30,551 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:31,051 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:31,061 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:31,062 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:31,563 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:31,570 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:31,571 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:32,072 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:32,084 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:32,085 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:32,585 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:32,598 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:32,599 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:32,994 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:32] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:33,101 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:33,113 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:33,117 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:33,618 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:33,625 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:33,625 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:34,126 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:34,139 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:34,139 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:34,640 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:34,647 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:34,648 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:35,150 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:35,160 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:35,160 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:35,661 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:35,676 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:35,676 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:36,119 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:36,177 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:36,185 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:36,185 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:36,687 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:36,697 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:36,708 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:37,209 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:37,217 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:37,217 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:37,719 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:37,730 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:37,731 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:38,232 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:38,243 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:38,243 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:38,745 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:38,755 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:38,755 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:39,230 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:39,257 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:39,265 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:39,266 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:39,767 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:39,778 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:39,778 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:40,280 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:40,290 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:40,291 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:40,792 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:40,803 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:40,803 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:41,305 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:41,315 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:41,315 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:41,816 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:41,829 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:41,830 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:42,330 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:42,332 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:42,349 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:42,351 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:42,854 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:42,865 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:42,866 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:43,367 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:43,378 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:43,379 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:43,881 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:43,891 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:43,892 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:44,393 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:44,399 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:44,400 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:44,901 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:44,914 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:44,914 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:45,415 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:45,425 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:45,426 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:45,486 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:45,928 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:45,940 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:45,940 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:46,442 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:46,453 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:46,455 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:46,956 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:46,973 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:46,974 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:47,476 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:47,487 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:47,487 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:47,988 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:47,998 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:47,999 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:48,500 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:48,510 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:48,510 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:48,572 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:48] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:49,011 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:49,021 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:49,022 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:49,523 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:49,537 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:34:49,539 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:50,041 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:149] - DEBUG: the error is Message: 

2018-10-27 23:34:50,042 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:151] - INFO: aaaaa
2018-10-27 23:34:50,042 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:50,050 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 102
2018-10-27 23:34:50,051 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:50,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:155] - INFO: bbbbb
2018-10-27 23:34:50,052 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/clear {"id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:50,060 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/clear HTTP/1.1" 200 72
2018-10-27 23:34:50,061 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:50,061 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:157] - INFO: ppppp
2018-10-27 23:34:50,062 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value {"text": "3", "value": ["3"], "id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:50,088 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value HTTP/1.1" 200 72
2018-10-27 23:34:50,089 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:50,089 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:159] - INFO: yyyyy
2018-10-27 23:34:50,090 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "tag name", "value": "html", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:50,096 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 102
2018-10-27 23:34:50,096 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:50,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:161] - INFO: 00000
2018-10-27 23:34:50,097 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:50,131 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value HTTP/1.1" 200 72
2018-10-27 23:34:50,131 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:50,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:163] - INFO: 11111
2018-10-27 23:34:50,132 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:50,138 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:50,139 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:50,640 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:50,649 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:50,650 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:51,151 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:51,159 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:51,160 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:51,660 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:51,667 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:51,669 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:51,670 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:52,172 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:52,176 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:52,177 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:52,678 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:52,685 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:52,687 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:53,189 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:53,194 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:53,194 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:53,695 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:53,700 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:53,700 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:54,201 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:54,206 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:54,206 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:54,707 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:54,717 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:54,718 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:55,219 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:55,229 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:55,230 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:55,268 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:55] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:55,731 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:55,739 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:55,739 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:56,240 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:56,250 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:56,251 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:56,752 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:56,762 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:56,762 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:57,264 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:57,272 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:57,273 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:57,775 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:57,783 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:57,783 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:58,285 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:58,292 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:58,293 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:58,407 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:34:58] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:34:58,795 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:58,802 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:58,802 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:59,304 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:59,311 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:59,312 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:34:59,813 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:34:59,821 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:34:59,821 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:00,322 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:167] - DEBUG: again the error is Message: 

2018-10-27 23:35:00,323 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:168] - DEBUG: æ²¡æ‰¾åˆ°æ–¹æ¡†
2018-10-27 23:35:00,324 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:00,337 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:00,338 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:00,840 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:00,849 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:00,850 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:01,351 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:01,361 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:01,361 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:01,489 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:01] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:01,862 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:01,872 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:01,872 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:02,374 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:02,384 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:02,385 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:02,886 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:02,894 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:02,895 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:03,396 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:03,403 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:03,403 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:03,904 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:03,910 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:03,911 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:04,411 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:04,418 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:04,418 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:04,577 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:04] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:04,919 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:04,925 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:04,925 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:05,426 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:05,433 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:05,433 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:05,934 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:05,944 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:05,945 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:06,446 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:06,456 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:06,456 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:06,958 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:06,967 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:06,968 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:07,469 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:07,482 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:07,482 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:07,663 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:07] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:07,984 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:07,994 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:07,994 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:08,495 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:08,506 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:08,506 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:09,008 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:09,019 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:09,022 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:09,523 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:09,532 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:09,533 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:10,034 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:10,045 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:10,046 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:10,547 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:10,556 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:10,557 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:10,784 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:10] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:11,058 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:11,068 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:11,069 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:11,570 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:11,580 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:11,580 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:12,082 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:12,092 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:12,092 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:12,594 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:12,604 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:12,604 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:13,106 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:13,114 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:13,115 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:13,615 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:13,623 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:13,623 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:13,875 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:13] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:14,124 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:14,130 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:14,131 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:14,632 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:14,639 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:14,640 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:15,140 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:15,147 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:15,147 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:15,648 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:15,655 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:15,656 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:16,156 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:16,166 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:16,167 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:16,668 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:16,678 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:16,679 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:16,964 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:16] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:17,180 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:17,189 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:17,190 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:17,691 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:17,700 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:17,701 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:18,203 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:18,212 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:18,213 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:18,715 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:18,724 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:18,725 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:19,226 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:19,234 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:19,235 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:19,737 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:19,748 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:19,748 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:20,055 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:20] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:20,249 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[2]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:20,258 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:20,258 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:20,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:175] - DEBUG: æ— æ³•ç‚¹å‡»
2018-10-27 23:35:22,761 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/source {"sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:22,768 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/source HTTP/1.1" 200 19355
2018-10-27 23:35:22,770 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:22,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2016/11/28/art_12_89721.html', '/art/2016/7/6/art_12_89720.html', '/art/2016/6/3/art_12_89719.html', '/art/2016/4/26/art_12_89718.html', '/art/2016/3/29/art_12_89717.html', '/art/2016/3/2/art_12_89716.html', '/art/2015/12/14/art_12_89715.html', '/art/2015/12/14/art_12_89714.html', '/art/2015/6/24/art_12_89713.html', '/art/2015/6/19/art_12_89712.html', '/art/2015/4/1/art_12_89711.html', '/art/2015/3/2/art_12_89710.html', '/art/2015/2/27/art_12_89709.html', '/art/2014/12/22/art_12_89708.html', '/art/2014/12/22/art_12_89707.html']
2018-10-27 23:35:22,778 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:35:23,141 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:23] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:25,787 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:142] - INFO: ttt
2018-10-27 23:35:25,787 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:25,795 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:25,795 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:26,219 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:26] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:26,296 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:26,305 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:26,305 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:26,806 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:26,815 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:26,815 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:27,317 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:27,327 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:27,327 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:27,829 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:27,840 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:27,840 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:28,342 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:28,352 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:28,352 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:28,854 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:28,864 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:28,865 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:29,298 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:29] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:29,366 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:29,373 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:29,374 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:29,875 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:29,885 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:29,886 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:30,387 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:30,397 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:30,398 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:30,899 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:30,910 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:30,910 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:31,411 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:31,422 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:31,423 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:31,924 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:31,935 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:31,935 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:32,398 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:32] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:32,436 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:32,445 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:32,446 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:32,947 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:32,955 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:32,956 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:33,456 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:33,466 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:33,467 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:33,969 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:33,979 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:33,979 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:34,481 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:34,492 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:34,493 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:34,993 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:35,004 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:35,005 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:35,506 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:35] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:35,506 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:35,524 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:35,526 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:36,027 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:36,039 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:36,040 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:36,541 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:36,556 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:36,559 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:37,060 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:37,068 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:37,068 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:37,569 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:37,576 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:37,577 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:38,077 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:38,089 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:38,089 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:38,591 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:38,602 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:38,603 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:38,642 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:38] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:39,105 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:39,119 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:39,120 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:39,622 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:39,634 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:39,634 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:40,136 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:40,146 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:40,147 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:40,647 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:40,658 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:40,659 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:41,159 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:41,169 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:41,170 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:41,671 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:41,681 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:41,681 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:41,778 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:41] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:42,182 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:42,192 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:42,193 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:42,694 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:42,703 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:42,704 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:43,206 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:43,216 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:43,216 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:43,718 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:43,729 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:43,729 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:44,231 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:44,241 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:44,241 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:44,743 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:44,753 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:44,753 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:44,861 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:44] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:45,254 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:45,261 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:45,261 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:45,762 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:45,769 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:35:45,769 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:46,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:149] - DEBUG: the error is Message: 

2018-10-27 23:35:46,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:151] - INFO: aaaaa
2018-10-27 23:35:46,271 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:46,278 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 102
2018-10-27 23:35:46,278 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:46,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:155] - INFO: bbbbb
2018-10-27 23:35:46,279 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/clear {"id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:46,286 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/clear HTTP/1.1" 200 72
2018-10-27 23:35:46,287 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:46,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:157] - INFO: ppppp
2018-10-27 23:35:46,288 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value {"text": "4", "value": ["4"], "id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:46,306 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value HTTP/1.1" 200 72
2018-10-27 23:35:46,307 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:46,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:159] - INFO: yyyyy
2018-10-27 23:35:46,307 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "tag name", "value": "html", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:46,315 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 102
2018-10-27 23:35:46,315 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:46,316 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:161] - INFO: 00000
2018-10-27 23:35:46,316 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:46,346 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value HTTP/1.1" 200 72
2018-10-27 23:35:46,347 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:46,347 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:163] - INFO: 11111
2018-10-27 23:35:46,348 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:46,354 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:46,355 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:46,856 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:46,860 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:46,861 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:47,362 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:47,367 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:47,368 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:47,869 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:47,876 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:47,877 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:47,951 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:47] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:48,379 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:48,386 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:48,387 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:48,888 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:48,895 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:48,895 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:49,396 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:49,401 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:49,402 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:49,903 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:49,908 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:49,909 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:50,410 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:50,418 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:50,419 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:50,921 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:50,932 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:50,934 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:51,046 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:51,435 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:51,442 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:51,443 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:51,944 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:51,951 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:51,952 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:52,453 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:52,460 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:52,461 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:52,962 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:52,969 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:52,970 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:53,471 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:53,479 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:53,479 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:53,980 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:53,990 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:53,991 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:54,171 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:54,492 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:54,500 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:54,500 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:55,002 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:55,009 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:55,010 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:55,511 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:55,518 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:55,519 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:56,019 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:56,024 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:35:56,024 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:56,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:167] - DEBUG: again the error is Message: 

2018-10-27 23:35:56,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:168] - DEBUG: æ²¡æ‰¾åˆ°æ–¹æ¡†
2018-10-27 23:35:56,526 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:56,538 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:56,538 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:57,040 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:57,047 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:57,048 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:57,273 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:35:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:35:57,549 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:57,556 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:57,556 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:58,057 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:58,064 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:58,064 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:58,566 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:58,575 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:58,576 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:59,078 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:59,087 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:59,088 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:35:59,589 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:35:59,599 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:35:59,599 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:00,101 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:00,111 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:00,111 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:00,366 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:00] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:00,613 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:00,621 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:00,622 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:01,124 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:01,131 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:01,131 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:01,633 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:01,642 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:01,643 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:02,145 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:02,154 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:02,155 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:02,656 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:02,666 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:02,666 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:03,167 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:03,174 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:03,175 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:03,453 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:03] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:03,676 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:03,686 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:03,687 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:04,188 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:04,198 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:04,198 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:04,700 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:04,709 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:04,710 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:05,212 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:05,221 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:05,222 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:05,723 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:05,733 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:05,733 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:06,235 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:06,241 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:06,242 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:06,552 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:06] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:06,742 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:06,749 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:06,749 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:07,250 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:07,257 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:07,257 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:07,759 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:07,765 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:07,766 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:08,267 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:08,274 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:08,274 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:08,776 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:08,785 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:08,786 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:09,287 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:09,295 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:09,296 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:09,648 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:09] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:09,797 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:09,807 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:09,807 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:10,308 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:10,319 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:10,322 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:10,823 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:10,832 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:10,833 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:11,335 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:11,347 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:11,348 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:11,849 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:11,858 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:11,859 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:12,360 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:12,369 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:12,370 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:12,735 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:12] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:12,870 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:12,880 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:12,881 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:13,382 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:13,390 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:13,391 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:13,892 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:13,901 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:13,902 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:14,403 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:14,413 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:14,414 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:14,916 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:14,926 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:14,926 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:15,428 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:15,438 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:15,438 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:15,822 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:15] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:15,940 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:15,949 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:15,950 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:16,451 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table/a[3]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:16,462 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 369
2018-10-27 23:36:16,462 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:16,964 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:175] - DEBUG: æ— æ³•ç‚¹å‡»
2018-10-27 23:36:18,906 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:18] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:18,964 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/source {"sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:18,971 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/source HTTP/1.1" 200 19462
2018-10-27 23:36:18,972 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:18,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2014/11/6/art_12_89706.html', '/art/2014/8/25/art_12_89705.html', '/art/2014/8/25/art_12_89704.html', '/art/2014/5/15/art_12_89703.html', '/art/2014/5/14/art_12_89702.html', '/art/2014/3/31/art_12_89701.html', '/art/2014/3/3/art_12_89700.html', '/art/2014/2/28/art_12_89699.html', '/art/2014/2/28/art_12_89698.html', '/art/2014/2/7/art_12_89697.html', '/art/2013/12/19/art_12_89696.html', '/art/2013/12/12/art_12_89695.html', '/art/2013/11/27/art_12_89694.html', '/art/2013/11/27/art_12_89693.html', '/art/2013/10/17/art_12_89692.html']
2018-10-27 23:36:18,977 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:36:21,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:142] - INFO: ttt
2018-10-27 23:36:21,986 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:21,992 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:21] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:21,996 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:21,997 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:22,498 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:22,508 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:22,509 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:23,011 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:23,020 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:23,020 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:23,521 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:23,532 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:23,532 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:24,033 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:24,044 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:24,044 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:24,546 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:24,557 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:24,557 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:25,059 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:25,069 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:25,070 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:25,104 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:25] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:25,570 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:25,581 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:25,581 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:26,083 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:26,093 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:26,093 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:26,595 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:26,605 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:26,606 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:27,106 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:27,114 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:27,115 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:27,616 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:27,626 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:27,626 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:28,128 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:28,137 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:28,137 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:28,205 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:28] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:28,638 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:28,651 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:28,652 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:29,154 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:29,161 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:29,161 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:29,662 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:29,673 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:29,673 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:30,175 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:30,182 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:30,182 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:30,684 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:30,693 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:30,694 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:31,195 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:31,205 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:31,205 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:31,331 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:31] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:31,707 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:31,717 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:31,717 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:32,219 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:32,229 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:32,230 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:32,731 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:32,741 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:32,742 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:33,243 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:33,253 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:33,254 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:33,755 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:33,765 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:33,765 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:34,267 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:34,278 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:34,278 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:34,420 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:34] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:34,779 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:34,789 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:34,789 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:35,290 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:35,300 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:35,301 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:35,802 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:35,812 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:35,812 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:36,314 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:36,323 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:36,324 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:36,825 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:36,837 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:36,837 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:37,339 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:37,350 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:37,350 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:37,511 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:37] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:37,851 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:37,858 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:37,859 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:38,359 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:38,366 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:38,366 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:38,868 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:38,874 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:38,875 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:39,375 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:39,382 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:39,382 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:39,884 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:39,891 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:39,892 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:40,393 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:40,404 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:40,404 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:40,680 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:40] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:40,906 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:40,916 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:40,917 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:41,419 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:41,429 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:41,430 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:41,930 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:41,942 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 391
2018-10-27 23:36:41,943 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:42,444 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:149] - DEBUG: the error is Message: 

2018-10-27 23:36:42,444 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:151] - INFO: aaaaa
2018-10-27 23:36:42,445 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:42,455 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 102
2018-10-27 23:36:42,456 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:42,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:155] - INFO: bbbbb
2018-10-27 23:36:42,457 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/clear {"id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:42,466 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/clear HTTP/1.1" 200 72
2018-10-27 23:36:42,466 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:42,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:157] - INFO: ppppp
2018-10-27 23:36:42,468 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value {"text": "5", "value": ["5"], "id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:42,505 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value HTTP/1.1" 200 72
2018-10-27 23:36:42,507 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:42,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:159] - INFO: yyyyy
2018-10-27 23:36:42,508 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element {"using": "tag name", "value": "html", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:42,520 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element HTTP/1.1" 200 102
2018-10-27 23:36:42,521 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:42,521 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:161] - INFO: 00000
2018-10-27 23:36:42,522 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5775475734613766-1", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:42,571 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "POST /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-1/value HTTP/1.1" 200 72
2018-10-27 23:36:42,572 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:42,572 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:163] - INFO: 11111
2018-10-27 23:36:42,573 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:42,581 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:42,581 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:43,083 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:43,090 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:43,091 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:43,593 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:43,600 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:43,601 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:43,770 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:43] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:44,102 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:44,110 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:44,111 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:44,612 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:44,619 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:44,620 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:45,121 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:45,129 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:45,130 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:45,632 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:45,637 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:45,638 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:46,138 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:46,146 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:46,147 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:46,648 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:46,655 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:46,656 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:46,909 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:36:46] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:36:47,158 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:47,165 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:47,166 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:47,668 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:57239/session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled {"id": "0.5775475734613766-2", "sessionId": "841d132490677f33b1c9dbad4652bd68"}
2018-10-27 23:36:47,675 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:57239 "GET /session/841d132490677f33b1c9dbad4652bd68/element/0.5775475734613766-2/enabled HTTP/1.1" 200 72
2018-10-27 23:36:47,676 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:36:47,943 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-27 23:36:48,040 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-27 23:37:48,565 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-27 23:37:51,282 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:37:51] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-27 23:37:53,323 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:37:53] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-27 23:38:26,507 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:26] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-27 23:38:26,663 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:26] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:26,724 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-27 23:38:26,742 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-27 23:38:26,747 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-27 23:38:26,777 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-27 23:38:26,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-27 23:38:26,859 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-27 23:38:26,862 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-27 23:38:26,896 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-27 23:38:26,897 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-27 23:38:26,904 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:38:26,906 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-27 23:38:29,199 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:38:29,413 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/12/7/art_12_206842.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,417 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/1/4/art_12_207124.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,420 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/9/29/art_12_209295.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,425 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/8/24/art_12_209032.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,429 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207215.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,433 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/3/27/art_12_207739.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,437 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207214.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,440 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/8/31/art_12_209099.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,466 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/7/17/art_12_208771.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,475 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/11/30/art_12_206775.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,481 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/11/13/art_12_206635.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,484 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/7/2/art_12_208638.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,486 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/4/8/art_12_207841.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,491 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/12/30/art_12_207076.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,495 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/12/4/art_12_206821.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
2018-10-27 23:38:29,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:29,565 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3023:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬692å·ç°å…¬å¸ƒã€Šä¸­åäººæ°‘å…±å’Œå›½åé—´è°æ³•å®æ–½ç»†åˆ™ã€‹ï¼Œè‡ªå…¬...
2018-10-27 23:38:29,568 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:29,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:29,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:29,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:29,570 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :20886
2018-10-27 23:38:29,571 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:29,571 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:29,571 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/12/7/art_12_206842.html>
None
2018-10-27 23:38:29,578 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:29,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3464:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬696å· ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šé£Ÿç›ä¸“è¥åŠæ³•ã€‹ï¼Œè‡ªå…¬å¸ƒä¹‹æ—¥èµ·...
2018-10-27 23:38:29,633 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:29,633 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:29,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:29,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:29,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :44397
2018-10-27 23:38:29,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:29,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:29,637 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/1/4/art_12_207124.html>
None
2018-10-27 23:38:29,637 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:29,687 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4298:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬703å·ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹ï¼Œè‡ª...
2018-10-27 23:38:29,692 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:29,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:29,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:29,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:29,694 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :71492
2018-10-27 23:38:29,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:29,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:29,696 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/9/29/art_12_209295.html>
None
2018-10-27 23:38:29,697 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:29,757 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:29] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:29,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4428:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬702å·ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå…¨å›½ç»æµæ™®æŸ¥æ¡ä¾‹ã€‰çš„å†³å®šã€‹å·²...
2018-10-27 23:38:29,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:29,777 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:29,777 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:29,777 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:29,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :101562
2018-10-27 23:38:29,781 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:29,781 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:29,782 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/8/24/art_12_209032.html>
None
2018-10-27 23:38:29,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:29,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 8454:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬695å·ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆè§„ç« åˆ¶å®šç¨‹åºæ¡ä¾‹ã€‰çš„å†³...
2018-10-27 23:38:29,879 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:29,880 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:29,880 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:29,881 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:29,882 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :156183
2018-10-27 23:38:29,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:29,889 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:29,889 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207215.html>
None
2018-10-27 23:38:29,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:29,971 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6604:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬697å·ã€Šå¿«é€’æš‚è¡Œæ¡ä¾‹ã€‹å·²ç»2018å¹´2æœˆ7æ—¥å›½åŠ¡é™¢ç¬¬...
2018-10-27 23:38:29,980 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:29,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:29,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:29,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:29,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :198752
2018-10-27 23:38:29,986 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:29,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:29,987 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/3/27/art_12_207739.html>
None
2018-10-27 23:38:29,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:30,056 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7964:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬694å·ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆè¡Œæ”¿æ³•è§„åˆ¶å®šç¨‹åºæ¡ä¾‹ã€‰...
2018-10-27 23:38:30,065 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:30,066 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:30,067 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:30,067 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:30,068 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :250332
2018-10-27 23:38:30,072 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:30,072 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:30,073 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207214.html>
None
2018-10-27 23:38:30,074 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:30,168 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7512:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬701å· ã€ŠåŒ»ç–—çº çº·é¢„é˜²å’Œå¤„ç†æ¡ä¾‹ã€‹å·²ç»2018å¹´6æœˆ...
2018-10-27 23:38:30,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:30,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:30,195 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:30,195 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:30,196 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :298221
2018-10-27 23:38:30,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:30,206 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:30,206 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/8/31/art_12_209099.html>
None
2018-10-27 23:38:30,207 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:30,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4961:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬700å·ã€ŠäººåŠ›èµ„æºå¸‚åœºæš‚è¡Œæ¡ä¾‹ã€‹å·²ç»2018å¹´5æœˆ2æ—¥...
2018-10-27 23:38:30,270 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:30,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:30,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:30,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:30,273 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :330854
2018-10-27 23:38:30,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:30,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:30,279 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/7/17/art_12_208771.html>
None
2018-10-27 23:38:30,288 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:30,323 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 447:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬690å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹ï¼Œ...
2018-10-27 23:38:30,341 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:30,343 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:30,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:30,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:30,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :334218
2018-10-27 23:38:30,355 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:30,355 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:30,355 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/11/30/art_12_206775.html>
None
2018-10-27 23:38:30,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:30,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5531:  ç¬¬689å·ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šä¸­å›½äººæ°‘è§£æ”¾å†›æ–‡èŒäººå‘˜æ¡ä¾‹ã€‹ï¼Œè‡ªå…¬å¸ƒä¹‹æ—¥èµ·æ–½è¡Œã€‚ä¸­å¤®...
2018-10-27 23:38:30,442 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gov.cn:80
2018-10-27 23:38:30,552 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gov.cn:80 "GET /zhengce/content/2017-11/10/5238592/images/ec0d8820938642c2be5d4a8a632a6057.jpg HTTP/1.1" 200 15945
2018-10-27 23:38:30,614 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.chinalaw.gov.cn/art/2017/11/13/art_12_206635.html> (referer: http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:38:30_ec0d8820938642c2be5d4a8a632a6057.jpg'
2018-10-27 23:38:30,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:30,653 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2599:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬699å·ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šå¥¥æ—åŒ¹å…‹æ ‡å¿—ä¿æŠ¤æ¡ä¾‹ã€‹ï¼Œè‡ª20...
2018-10-27 23:38:30,664 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:30,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:30,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:30,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:30,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :351141
2018-10-27 23:38:30,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:30,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:30,673 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/7/2/art_12_208638.html>
None
2018-10-27 23:38:30,674 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:30,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3247:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬698å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹å’ŒåºŸæ­¢éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³...
2018-10-27 23:38:30,726 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:30,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:30,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:30,729 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:30,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :372008
2018-10-27 23:38:30,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:30,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:30,736 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/4/8/art_12_207841.html>
None
2018-10-27 23:38:30,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:30,792 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2777:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬693å· ç°å…¬å¸ƒã€Šä¸­åäººæ°‘å…±å’Œå›½ç¯å¢ƒä¿æŠ¤ç¨æ³•å®æ–½æ¡ä¾‹ã€‹...
2018-10-27 23:38:30,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:30,821 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:30,823 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:30,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:30,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :390340
2018-10-27 23:38:30,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:30,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:30,847 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/12/30/art_12_207076.html>
None
2018-10-27 23:38:30,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:38:30,928 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5470:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬691å·ã€Šå›½åŠ¡é™¢å…³äºåºŸæ­¢ã€ˆä¸­åäººæ°‘å…±å’Œå›½è¥ä¸šç¨æš‚è¡Œæ¡ä¾‹...
2018-10-27 23:38:30,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:38:30,948 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:38:30,949 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:38:30,949 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:38:30,951 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :425554
2018-10-27 23:38:30,957 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:38:30,957 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:38:30,957 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/12/4/art_12_206821.html>
None
2018-10-27 23:38:32,865 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:32] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:35,953 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:35] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:37,264 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:38:37,373 - /anaconda3/lib/python3.6/site-packages/scrapy/dupefilters.py[line:70] - DEBUG: Filtered duplicate request: <GET http://www.chinalaw.gov.cn/art/2018/4/8/art_12_207841.html> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-27 23:38:37,380 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (finished)
2018-10-27 23:38:37,391 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-27 23:38:37,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-27 23:38:37,401 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8536,
 'downloader/request_count': 17,
 'downloader/request_method_count/GET': 15,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 176410,
 'downloader/response_count': 17,
 'downloader/response_status_count/200': 17,
 'dupefilter/filtered': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 10, 27, 15, 38, 37, 390867),
 'item_scraped_count': 14,
 'log_count/DEBUG': 94,
 'log_count/ERROR': 1,
 'log_count/INFO': 79,
 'memusage/max': 64237568,
 'memusage/startup': 64237568,
 'request_depth_max': 2,
 'response_received_count': 17,
 'scheduler/dequeued': 19,
 'scheduler/dequeued/memory': 19,
 'scheduler/enqueued': 19,
 'scheduler/enqueued/memory': 19,
 'spider_exceptions/FileNotFoundError': 1,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 15, 38, 26, 904510)}
2018-10-27 23:38:37,401 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (finished)
2018-10-27 23:38:39,054 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:42,151 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:45,246 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:45,731 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:nosw
2018-10-27 23:38:45,731 - /Users/tian/zaluan/ScrapyA/app/views.py[line:374] - INFO: nosw
2018-10-27 23:38:47,733 - /Users/tian/zaluan/ScrapyA/app/views.py[line:391] - INFO: userinfo in crawling:{}
2018-10-27 23:38:47,751 - /Users/tian/zaluan/ScrapyA/app/views.py[line:393] - INFO: before
2018-10-27 23:38:47,753 - /Users/tian/zaluan/ScrapyA/app/views.py[line:394] - INFO: after:open
2018-10-27 23:38:48,344 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:48] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:51,435 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:52,758 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:52] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-27 23:38:52,934 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-27 23:38:52,949 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-27 23:38:52,954 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-27 23:38:52,990 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-27 23:38:53,029 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-27 23:38:54,051 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": []}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": []}}}
2018-10-27 23:38:54,053 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): 127.0.0.1:58792
2018-10-27 23:38:54,647 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:55,435 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session HTTP/1.1" 200 903
2018-10-27 23:38:55,438 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:38:55,440 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:80] - INFO: é¡µç æ‰€åœ¨çš„xpath://*[@id="1648"]/table/tbody/tr/td/table
2018-10-27 23:38:55,478 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-27 23:38:55,480 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-27 23:38:55,507 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-27 23:38:55,508 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-27 23:38:55,513 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:38:55,515 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-27 23:38:55,626 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1> (referer: None)
2018-10-27 23:38:55,729 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/url {"url": "http://www.chinalaw.gov.cn/col/col12/index.html?uid=1648&pageNum=1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:38:56,590 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/url HTTP/1.1" 200 72
2018-10-27 23:38:56,591 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:38:56,591 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:38:56,597 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19682
2018-10-27 23:38:56,598 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:38:56,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2018/9/29/art_12_209295.html', '/art/2018/8/31/art_12_209099.html', '/art/2018/8/24/art_12_209032.html', '/art/2018/7/17/art_12_208771.html', '/art/2018/7/2/art_12_208638.html', '/art/2018/4/8/art_12_207841.html', '/art/2018/3/27/art_12_207739.html', '/art/2018/1/16/art_12_207215.html', '/art/2018/1/16/art_12_207214.html', '/art/2018/1/4/art_12_207124.html', '/art/2017/12/30/art_12_207076.html', '/art/2017/12/7/art_12_206842.html', '/art/2017/12/4/art_12_206821.html', '/art/2017/11/30/art_12_206775.html', '/art/2017/11/13/art_12_206635.html']
2018-10-27 23:38:57,730 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:38:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:38:59,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:142] - INFO: ttt
2018-10-27 23:38:59,610 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:38:59,627 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:38:59,627 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:00,129 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:00,140 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:00,141 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:00,642 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:00,653 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:00,653 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:00,814 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:00] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:01,155 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:01,162 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:01,163 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:01,664 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:01,676 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:01,676 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:02,177 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:02,188 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:02,188 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:02,689 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:02,697 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:02,698 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:03,198 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:03,208 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:03,208 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:03,709 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:03,719 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:03,720 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:04,221 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:04,231 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:04,232 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:04,353 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:04] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:04,733 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:04,744 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:04,745 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:05,246 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:05,257 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:05,257 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:05,759 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:05,769 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:05,769 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:06,271 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:06,280 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:06,281 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:06,782 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:06,789 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:06,789 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:07,290 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:07,298 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:07,298 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:07,799 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:07,807 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:07,807 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:07,928 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:07] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:08,308 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:08,320 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:08,320 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:08,822 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:08,832 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:08,833 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:09,335 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:09,345 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:09,345 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:09,846 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:09,856 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:09,857 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:10,358 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:10,369 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:10,370 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:10,871 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:10,881 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:10,882 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:11,383 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:11,393 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:11,393 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:11,508 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:11] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:11,895 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:11,906 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:11,906 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:12,408 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:12,418 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:12,418 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:12,920 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:12,930 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:12,931 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:13,433 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:13,444 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:13,444 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:13,946 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:13,956 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:13,957 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:14,458 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:14,468 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:14,469 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:14,602 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:14] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:14,971 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:14,981 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:14,981 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:15,483 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:15,493 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:15,493 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:15,995 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:16,005 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:16,005 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:16,507 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:16,518 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:16,518 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:17,020 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:17,027 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:17,028 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:17,528 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:17,535 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:17,536 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:17,678 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:17] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:18,036 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:18,043 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:18,044 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:18,545 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:18,552 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:18,552 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:19,053 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:19,059 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:19,060 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:19,562 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:19,572 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 391
2018-10-27 23:39:19,573 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:20,073 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:149] - DEBUG: the error is Message: 

2018-10-27 23:39:20,074 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:151] - INFO: aaaaa
2018-10-27 23:39:20,075 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:20,088 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:39:20,088 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:20,089 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:155] - INFO: bbbbb
2018-10-27 23:39:20,089 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:20,105 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:39:20,105 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:20,106 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:157] - INFO: ppppp
2018-10-27 23:39:20,106 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "2", "value": ["2"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:20,166 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:20,167 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:20,167 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:159] - INFO: yyyyy
2018-10-27 23:39:20,167 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:161] - INFO: 00000
2018-10-27 23:39:20,168 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:20,199 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:20,199 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:20,200 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:163] - INFO: 11111
2018-10-27 23:39:20,200 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:164] - INFO: rrrrr
2018-10-27 23:39:20,765 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:20] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:22,202 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:22,208 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19514
2018-10-27 23:39:22,210 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:22,212 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2017/10/30/art_12_206524.html', '/art/2017/10/24/art_12_206461.html', '/art/2017/9/7/art_12_206178.html', '/art/2017/9/6/art_12_206160.html', '/art/2017/8/23/art_12_206046.html', '/art/2017/8/21/art_12_206018.html', '/art/2017/8/2/art_12_205857.html', '/art/2017/6/20/art_12_205442.html', '/art/2017/5/22/art_12_89728.html', '/art/2017/5/3/art_12_89727.html', '/art/2017/4/5/art_12_89726.html', '/art/2017/3/22/art_12_89725.html', '/art/2017/2/28/art_12_89724.html', '/art/2017/2/24/art_12_89723.html', '/art/2016/12/14/art_12_89722.html']
2018-10-27 23:39:23,861 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:23] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:25,238 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:25,247 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:39:25,248 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:25,248 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:25,256 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:39:25,256 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:25,257 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "3", "value": ["3"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:25,277 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:25,277 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:25,277 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:25,316 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:25,317 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:26,954 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:26] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:27,317 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:27,324 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19355
2018-10-27 23:39:27,325 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:27,327 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2016/11/28/art_12_89721.html', '/art/2016/7/6/art_12_89720.html', '/art/2016/6/3/art_12_89719.html', '/art/2016/4/26/art_12_89718.html', '/art/2016/3/29/art_12_89717.html', '/art/2016/3/2/art_12_89716.html', '/art/2015/12/14/art_12_89715.html', '/art/2015/12/14/art_12_89714.html', '/art/2015/6/24/art_12_89713.html', '/art/2015/6/19/art_12_89712.html', '/art/2015/4/1/art_12_89711.html', '/art/2015/3/2/art_12_89710.html', '/art/2015/2/27/art_12_89709.html', '/art/2014/12/22/art_12_89708.html', '/art/2014/12/22/art_12_89707.html']
2018-10-27 23:39:30,041 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:30] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:30,335 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:30,346 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:39:30,347 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:30,347 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:30,355 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:39:30,356 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:30,356 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "4", "value": ["4"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:30,382 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:30,383 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:30,383 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:30,413 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:30,413 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:32,415 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:32,421 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19462
2018-10-27 23:39:32,422 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:32,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2014/11/6/art_12_89706.html', '/art/2014/8/25/art_12_89705.html', '/art/2014/8/25/art_12_89704.html', '/art/2014/5/15/art_12_89703.html', '/art/2014/5/14/art_12_89702.html', '/art/2014/3/31/art_12_89701.html', '/art/2014/3/3/art_12_89700.html', '/art/2014/2/28/art_12_89699.html', '/art/2014/2/28/art_12_89698.html', '/art/2014/2/7/art_12_89697.html', '/art/2013/12/19/art_12_89696.html', '/art/2013/12/12/art_12_89695.html', '/art/2013/11/27/art_12_89694.html', '/art/2013/11/27/art_12_89693.html', '/art/2013/10/17/art_12_89692.html']
2018-10-27 23:39:33,137 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:33] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:35,434 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:35,444 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:39:35,444 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:35,445 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:35,452 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:39:35,453 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:35,453 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "5", "value": ["5"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:35,477 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:35,477 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:35,478 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:35,506 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:35,507 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:36,217 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:37,508 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:37,515 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19655
2018-10-27 23:39:37,516 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:37,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2013/9/17/art_12_89691.html', '/art/2013/9/6/art_12_89690.html', '/art/2013/8/1/art_12_89689.html', '/art/2013/7/23/art_12_89688.html', '/art/2013/6/9/art_12_89687.html', '/art/2013/2/16/art_12_89686.html', '/art/2013/2/16/art_12_89685.html', '/art/2013/2/16/art_12_89684.html', '/art/2013/2/16/art_12_89683.html', '/art/2013/1/30/art_12_89682.html', '/art/2013/1/6/art_12_89681.html', '/art/2013/1/6/art_12_89680.html', '/art/2012/11/23/art_12_89679.html', '/art/2012/11/23/art_12_89678.html', '/art/2012/11/23/art_12_89677.html']
2018-10-27 23:39:39,304 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:40,527 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:40,536 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:39:40,537 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:40,537 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:40,545 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:39:40,546 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:40,546 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "6", "value": ["6"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:40,569 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:40,570 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:40,570 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:40,600 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:40,600 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:42,394 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:42,602 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:42,610 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19350
2018-10-27 23:39:42,611 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:42,613 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2012/11/23/art_12_89676.html', '/art/2012/11/23/art_12_89675.html', '/art/2012/11/19/art_12_89674.html', '/art/2012/11/19/art_12_89673.html', '/art/2012/11/6/art_12_89672.html', '/art/2012/10/31/art_12_89671.html', '/art/2012/10/23/art_12_89670.html', '/art/2012/9/18/art_12_89669.html', '/art/2012/9/7/art_12_89668.html', '/art/2012/7/11/art_12_89667.html', '/art/2012/6/19/art_12_89666.html', '/art/2012/6/11/art_12_89665.html', '/art/2012/5/8/art_12_89664.html', '/art/2012/4/10/art_12_89663.html', '/art/2012/3/8/art_12_89662.html']
2018-10-27 23:39:42,618 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/9/29/art_12_209295.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:39:42,620 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/11/30/art_12_206775.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:39:45,494 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:45,630 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:45,639 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:39:45,639 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:45,640 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:45,647 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:39:45,648 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:45,648 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "7", "value": ["7"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:45,671 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:45,671 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:45,672 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:45,699 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:45,699 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:47,701 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:47,708 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19397
2018-10-27 23:39:47,709 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:47,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2012/3/2/art_12_89661.html', '/art/2011/12/30/art_12_89660.html', '/art/2011/12/30/art_12_89659.html', '/art/2011/12/12/art_12_89658.html', '/art/2011/12/12/art_12_89657.html', '/art/2011/11/16/art_12_89656.html', '/art/2011/10/31/art_12_89655.html', '/art/2011/10/11/art_12_89654.html', '/art/2011/10/11/art_12_89653.html', '/art/2011/10/11/art_12_89652.html', '/art/2011/9/8/art_12_89651.html', '/art/2011/8/1/art_12_89650.html', '/art/2011/7/28/art_12_89649.html', '/art/2011/7/28/art_12_89648.html', '/art/2011/4/29/art_12_89647.html']
2018-10-27 23:39:47,716 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/1/4/art_12_207124.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:39:47,718 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/12/7/art_12_206842.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:39:47,721 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/10/30/art_12_206524.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:39:47,723 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/12/30/art_12_207076.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:39:47,726 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/12/4/art_12_206821.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:39:48,570 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:48] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:50,742 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:50,748 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:39:50,748 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:50,749 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:50,755 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:39:50,756 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:50,756 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "8", "value": ["8"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:50,778 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:50,778 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:50,779 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:50,805 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:50,806 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:51,653 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:52,807 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:52,814 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19395
2018-10-27 23:39:52,815 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:52,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2011/3/23/art_12_89646.html', '/art/2011/3/23/art_12_89645.html', '/art/2011/3/15/art_12_89644.html', '/art/2011/3/13/art_12_89643.html', '/art/2011/3/13/art_12_89642.html', '/art/2011/1/24/art_12_89641.html', '/art/2011/1/21/art_12_89640.html', '/art/2011/1/17/art_12_89639.html', '/art/2010/12/27/art_12_89638.html', '/art/2010/12/24/art_12_89637.html', '/art/2010/12/13/art_12_89636.html', '/art/2010/11/26/art_12_89635.html', '/art/2010/9/20/art_12_89634.html', '/art/2010/9/13/art_12_89633.html', '/art/2010/9/2/art_12_89632.html']
2018-10-27 23:39:52,823 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/11/13/art_12_206635.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:39:52,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:39:52,882 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4298:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬703å·ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹ï¼Œè‡ª...
2018-10-27 23:39:52,887 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:39:52,887 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:39:52,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:39:52,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:39:52,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :27797
2018-10-27 23:39:52,889 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:39:52,889 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:39:52,890 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/9/29/art_12_209295.html>
None
2018-10-27 23:39:52,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:39:52,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 447:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬690å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹ï¼Œ...
2018-10-27 23:39:52,925 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:39:52,925 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:39:52,925 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:39:52,926 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:39:52,926 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :31146
2018-10-27 23:39:52,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:39:52,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:39:52,927 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/11/30/art_12_206775.html>
None
2018-10-27 23:39:54,740 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:55,936 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:55,946 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:39:55,947 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:55,947 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:55,955 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:39:55,956 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:55,956 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "9", "value": ["9"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:55,984 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:55,984 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:55,985 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:56,015 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:39:56,016 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:57,829 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:39:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:39:58,018 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:39:58,024 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19591
2018-10-27 23:39:58,025 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:39:58,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2010/7/19/art_12_89631.html', '/art/2010/5/31/art_12_89630.html', '/art/2010/4/29/art_12_89629.html', '/art/2010/4/29/art_12_89628.html', '/art/2010/4/19/art_12_89627.html', '/art/2010/3/30/art_12_89626.html', '/art/2009/12/14/art_12_89625.html', '/art/2009/11/18/art_12_89624.html', '/art/2009/10/20/art_12_89623.html', '/art/2009/7/24/art_12_89622.html', '/art/2009/2/11/art_12_89621.html', '/art/2009/2/11/art_12_89620.html', '/art/2009/2/11/art_12_89619.html', '/art/2009/2/11/art_12_89618.html', '/art/2009/2/11/art_12_89617.html']
2018-10-27 23:39:58,031 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/7/2/art_12_208638.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:39:58,037 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:39:58,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3464:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬696å· ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šé£Ÿç›ä¸“è¥åŠæ³•ã€‹ï¼Œè‡ªå…¬å¸ƒä¹‹æ—¥èµ·...
2018-10-27 23:39:58,103 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:39:58,103 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:39:58,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:39:58,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:39:58,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :54642
2018-10-27 23:39:58,105 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:39:58,106 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:39:58,106 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/1/4/art_12_207124.html>
None
2018-10-27 23:39:58,106 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:39:58,153 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3023:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬692å·ç°å…¬å¸ƒã€Šä¸­åäººæ°‘å…±å’Œå›½åé—´è°æ³•å®æ–½ç»†åˆ™ã€‹ï¼Œè‡ªå…¬...
2018-10-27 23:39:58,157 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:39:58,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:39:58,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:39:58,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:39:58,159 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :74796
2018-10-27 23:39:58,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:39:58,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:39:58,160 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/12/7/art_12_206842.html>
None
2018-10-27 23:39:58,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:39:58,209 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2729:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬688å·ã€Šæœºå…³å›¢ä½“å»ºè®¾æ¥¼å ‚é¦†æ‰€ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2017å¹´...
2018-10-27 23:39:58,213 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:39:58,214 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:39:58,214 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:39:58,214 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:39:58,215 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :93280
2018-10-27 23:39:58,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:39:58,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:39:58,217 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/10/30/art_12_206524.html>
None
2018-10-27 23:39:58,217 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:39:58,273 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2777:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬693å· ç°å…¬å¸ƒã€Šä¸­åäººæ°‘å…±å’Œå›½ç¯å¢ƒä¿æŠ¤ç¨æ³•å®æ–½æ¡ä¾‹ã€‹...
2018-10-27 23:39:58,280 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:39:58,281 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:39:58,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:39:58,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:39:58,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :111597
2018-10-27 23:39:58,285 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:39:58,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:39:58,286 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/12/30/art_12_207076.html>
None
2018-10-27 23:39:58,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:39:58,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5470:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬691å·ã€Šå›½åŠ¡é™¢å…³äºåºŸæ­¢ã€ˆä¸­åäººæ°‘å…±å’Œå›½è¥ä¸šç¨æš‚è¡Œæ¡ä¾‹...
2018-10-27 23:39:58,377 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:39:58,378 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:39:58,379 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:39:58,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:39:58,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :146796
2018-10-27 23:39:58,385 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:39:58,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:39:58,387 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/12/4/art_12_206821.html>
None
2018-10-27 23:39:58,388 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 10 pages (at 10 pages/min), scraped 7 items (at 7 items/min)
2018-10-27 23:40:00,914 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:00] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:01,396 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:01,402 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:01,403 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:01,403 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:01,411 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:01,411 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:01,412 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "10", "value": ["1", "0"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:01,442 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:01,443 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:01,443 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:01,470 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:01,471 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:03,472 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:03,479 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19429
2018-10-27 23:40:03,480 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:03,483 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2009/2/11/art_12_89616.html', '/art/2009/2/11/art_12_89615.html', '/art/2009/2/11/art_12_89614.html', '/art/2009/2/11/art_12_89613.html', '/art/2009/2/11/art_12_89612.html', '/art/2009/2/11/art_12_89611.html', '/art/2009/2/11/art_12_89610.html', '/art/2009/2/11/art_12_89609.html', '/art/2009/2/11/art_12_89608.html', '/art/2009/2/11/art_12_89607.html', '/art/2009/2/11/art_12_89606.html', '/art/2009/2/11/art_12_89605.html', '/art/2009/2/11/art_12_89604.html', '/art/2009/1/20/art_12_89603.html', '/art/2009/1/20/art_12_89602.html']
2018-10-27 23:40:03,488 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/3/27/art_12_207739.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:03,491 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207214.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:03,495 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207215.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:03,498 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/7/17/art_12_208771.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:03,501 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/8/24/art_12_209032.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:03,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:03,603 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5531:  ç¬¬689å·ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šä¸­å›½äººæ°‘è§£æ”¾å†›æ–‡èŒäººå‘˜æ¡ä¾‹ã€‹ï¼Œè‡ªå…¬å¸ƒä¹‹æ—¥èµ·æ–½è¡Œã€‚ä¸­å¤®...
2018-10-27 23:40:03,606 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gov.cn:80
2018-10-27 23:40:03,637 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gov.cn:80 "GET /zhengce/content/2017-11/10/5238592/images/ec0d8820938642c2be5d4a8a632a6057.jpg HTTP/1.1" 200 15945
2018-10-27 23:40:03,660 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.chinalaw.gov.cn/art/2017/11/13/art_12_206635.html via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:40:03_ec0d8820938642c2be5d4a8a632a6057.jpg'
2018-10-27 23:40:04,002 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:04] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:06,675 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:06,683 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:06,684 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:06,684 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:06,692 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:06,693 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:06,693 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "11", "value": ["1", "1"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:06,728 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:06,729 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:06,729 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:06,759 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:06,760 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:07,141 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:07] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:08,761 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:08,768 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19455
2018-10-27 23:40:08,769 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:08,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2009/1/20/art_12_89601.html', '/art/2009/1/20/art_12_89600.html', '/art/2009/1/20/art_12_89599.html', '/art/2008/11/28/art_12_89598.html', '/art/2008/11/28/art_12_89597.html', '/art/2008/11/28/art_12_89596.html', '/art/2008/9/16/art_12_89595.html', '/art/2008/8/12/art_12_89594.html', '/art/2008/8/12/art_12_89593.html', '/art/2008/8/11/art_12_89592.html', '/art/2008/8/7/art_12_89591.html', '/art/2008/3/24/art_12_89590.html', '/art/2008/1/14/art_12_89589.html', '/art/2007/10/30/art_12_89588.html', '/art/2007/10/15/art_12_89587.html']
2018-10-27 23:40:08,775 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/4/8/art_12_207841.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:08,777 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89676.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:08,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:08,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2599:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬699å·ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šå¥¥æ—åŒ¹å…‹æ ‡å¿—ä¿æŠ¤æ¡ä¾‹ã€‹ï¼Œè‡ª20...
2018-10-27 23:40:08,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:08,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:08,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:08,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:08,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :163704
2018-10-27 23:40:08,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:08,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:08,849 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/7/2/art_12_208638.html>
None
2018-10-27 23:40:10,235 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:10] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:11,855 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:11,862 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:11,862 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:11,863 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:11,871 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:11,871 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:11,872 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "12", "value": ["1", "2"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:11,907 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:11,908 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:11,908 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:11,942 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:11,943 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:13,331 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:13] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:13,943 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:13,950 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19468
2018-10-27 23:40:13,951 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:13,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2007/9/22/art_12_89586.html', '/art/2007/7/22/art_12_89585.html', '/art/2007/7/22/art_12_89584.html', '/art/2017/8/25/art_12_206076.html', '/art/2006/12/28/art_12_89583.html', '/art/2006/10/24/art_12_89582.html', '/art/2006/10/8/art_12_89581.html', '/art/2006/9/30/art_12_89580.html', '/art/2006/7/31/art_12_89579.html', '/art/2006/5/24/art_12_89578.html', '/art/2006/5/22/art_12_89577.html', '/art/2006/5/8/art_12_89576.html', '/art/2006/5/8/art_12_89575.html', '/art/2006/5/8/art_12_89574.html', '/art/2006/1/4/art_12_89573.html']
2018-10-27 23:40:13,955 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:14,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6604:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬697å·ã€Šå¿«é€’æš‚è¡Œæ¡ä¾‹ã€‹å·²ç»2018å¹´2æœˆ7æ—¥å›½åŠ¡é™¢ç¬¬...
2018-10-27 23:40:14,020 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:14,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:14,022 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:14,022 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:14,022 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :206258
2018-10-27 23:40:14,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:14,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:14,027 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/3/27/art_12_207739.html>
None
2018-10-27 23:40:14,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:14,105 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7964:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬694å·ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆè¡Œæ”¿æ³•è§„åˆ¶å®šç¨‹åºæ¡ä¾‹ã€‰...
2018-10-27 23:40:14,114 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:14,116 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:14,116 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:14,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:14,118 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :257823
2018-10-27 23:40:14,122 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:14,122 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:14,122 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207214.html>
None
2018-10-27 23:40:14,123 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:14,221 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 8454:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬695å·ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆè§„ç« åˆ¶å®šç¨‹åºæ¡ä¾‹ã€‰çš„å†³...
2018-10-27 23:40:14,238 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:14,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:14,241 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:14,241 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:14,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :312429
2018-10-27 23:40:14,253 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:14,253 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:14,254 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/1/16/art_12_207215.html>
None
2018-10-27 23:40:14,254 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:14,331 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4961:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬700å·ã€ŠäººåŠ›èµ„æºå¸‚åœºæš‚è¡Œæ¡ä¾‹ã€‹å·²ç»2018å¹´5æœˆ2æ—¥...
2018-10-27 23:40:14,348 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:14,350 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:14,350 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:14,351 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:14,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :345047
2018-10-27 23:40:14,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:14,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:14,359 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/7/17/art_12_208771.html>
None
2018-10-27 23:40:14,359 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:14,420 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4428:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬702å·ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå…¨å›½ç»æµæ™®æŸ¥æ¡ä¾‹ã€‰çš„å†³å®šã€‹å·²...
2018-10-27 23:40:14,436 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:14,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:14,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:14,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:14,440 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :375102
2018-10-27 23:40:14,446 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:14,448 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:14,449 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/8/24/art_12_209032.html>
None
2018-10-27 23:40:16,426 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:16] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:17,461 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:17,469 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:17,470 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:17,470 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:17,478 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:17,479 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:17,479 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "13", "value": ["1", "3"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:17,514 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:17,514 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:17,515 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:17,546 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:17,546 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:19,516 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:19] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:19,547 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:19,552 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19530
2018-10-27 23:40:19,553 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:19,555 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2005/12/26/art_12_89572.html', '/art/2005/10/17/art_12_89571.html', '/art/2005/10/17/art_12_89570.html', '/art/2005/10/17/art_12_89569.html', '/art/2005/10/17/art_12_89568.html', '/art/2005/10/17/art_12_89567.html', '/art/2005/10/17/art_12_89566.html', '/art/2005/4/27/art_12_89565.html', '/art/2005/4/27/art_12_89564.html', '/art/2005/4/27/art_12_89563.html', '/art/2005/4/27/art_12_89562.html', '/art/2005/4/27/art_12_89561.html', '/art/2005/4/27/art_12_89560.html', '/art/2005/4/27/art_12_89559.html', '/art/2005/4/27/art_12_89558.html']
2018-10-27 23:40:19,559 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/3/2/art_12_89661.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:19,561 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/3/8/art_12_89662.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:19,565 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2018/8/31/art_12_209099.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:19,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:19,631 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3247:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬698å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹å’ŒåºŸæ­¢éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³...
2018-10-27 23:40:19,643 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:19,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:19,646 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:19,646 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:19,647 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :395954
2018-10-27 23:40:19,652 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:19,653 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:19,653 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/4/8/art_12_207841.html>
None
2018-10-27 23:40:19,653 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:19,690 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2187:  ï¼ˆ1997å¹´7æœˆ11æ—¥å›½åŠ¡é™¢ç¬¬60æ¬¡å¸¸åŠ¡ä¼šè®®é€šè¿‡ 1997å¹´7æœˆ21æ—¥ä¸­åäººæ°‘...
2018-10-27 23:40:19,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:19,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:19,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:19,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:19,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :411098
2018-10-27 23:40:19,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:19,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:19,711 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89676.html>
None
2018-10-27 23:40:22,717 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:22,724 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:22,725 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:22,726 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:22,734 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:22,735 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:22,735 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "14", "value": ["1", "4"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:22,781 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:22,781 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:22,782 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:22,817 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:22,818 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:23,775 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:23] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:24,819 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:24,826 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19445
2018-10-27 23:40:24,826 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:24,829 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2005/4/27/art_12_89557.html', '/art/2005/4/27/art_12_89556.html', '/art/2005/4/27/art_12_89555.html', '/art/2005/4/27/art_12_89554.html', '/art/2005/4/27/art_12_89553.html', '/art/2005/4/27/art_12_89552.html', '/art/2005/4/27/art_12_89551.html', '/art/2005/4/27/art_12_89550.html', '/art/2005/4/27/art_12_89549.html', '/art/2004/11/5/art_12_89548.html', '/art/2004/11/5/art_12_89547.html', '/art/2004/11/5/art_12_89546.html', '/art/2004/11/5/art_12_89545.html', '/art/2004/8/16/art_12_89544.html', '/art/2004/7/30/art_12_89543.html']
2018-10-27 23:40:24,833 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89677.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:24,836 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/6/11/art_12_89665.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:24,838 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/3/23/art_12_89646.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:26,883 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:26] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:27,854 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:27,864 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:27,864 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:27,865 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:27,873 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:27,873 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:27,874 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "15", "value": ["1", "5"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:27,914 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:27,914 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:27,915 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:27,945 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:27,946 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:29,946 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:29,951 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19530
2018-10-27 23:40:29,952 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:29,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2004/7/6/art_12_89542.html', '/art/2004/6/30/art_12_89541.html', '/art/2004/6/9/art_12_89540.html', '/art/2004/6/4/art_12_89539.html', '/art/2004/5/27/art_12_89538.html', '/art/2004/5/24/art_12_89537.html', '/art/2004/5/24/art_12_89536.html', '/art/2004/5/24/art_12_89535.html', '/art/2004/5/24/art_12_89534.html', '/art/2004/5/24/art_12_89533.html', '/art/2004/5/17/art_12_89532.html', '/art/2004/5/8/art_12_89531.html', '/art/2004/5/8/art_12_89530.html', '/art/2004/4/20/art_12_89529.html', '/art/2004/4/20/art_12_89528.html']
2018-10-27 23:40:29,956 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:29,972 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:29] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:30,004 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2820:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬614å· ã€Šæ‹˜ç•™æ‰€æ¡ä¾‹ã€‹å·²ç»2012å¹´2æœˆ15æ—¥å›½åŠ¡...
2018-10-27 23:40:30,017 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:30,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:30,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:30,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:30,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :431373
2018-10-27 23:40:30,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:30,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:30,027 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/3/2/art_12_89661.html>
None
2018-10-27 23:40:30,028 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:30,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5332:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬615å· ã€Šæµ·æ´‹è§‚æµ‹é¢„æŠ¥ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2012å¹´2æœˆ...
2018-10-27 23:40:30,087 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:30,089 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:30,089 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:30,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:30,091 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :467149
2018-10-27 23:40:30,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:30,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:30,098 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/3/8/art_12_89662.html>
None
2018-10-27 23:40:30,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:30,175 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7512:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬701å· ã€ŠåŒ»ç–—çº çº·é¢„é˜²å’Œå¤„ç†æ¡ä¾‹ã€‹å·²ç»2018å¹´6æœˆ...
2018-10-27 23:40:30,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:30,203 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:30,204 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:30,204 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:30,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :515023
2018-10-27 23:40:30,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:30,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:30,217 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2018/8/31/art_12_209099.html>
None
2018-10-27 23:40:33,056 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:33] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:33,231 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:33,237 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:33,237 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:33,238 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:33,244 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:33,245 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:33,245 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "16", "value": ["1", "6"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:33,282 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:33,283 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:33,283 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:33,313 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:33,314 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:35,315 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:35,322 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19361
2018-10-27 23:40:35,323 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:35,325 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2004/4/20/art_12_89527.html', '/art/2004/3/18/art_12_89526.html', '/art/2004/2/4/art_12_89525.html', '/art/2004/2/2/art_12_89524.html', '/art/2004/1/20/art_12_89523.html', '/art/2004/1/12/art_12_89522.html', '/art/2004/1/5/art_12_89521.html', '/art/2003/10/31/art_12_89520.html', '/art/2003/9/1/art_12_89519.html', '/art/2003/8/26/art_12_89518.html', '/art/2003/8/19/art_12_89517.html', '/art/2003/8/1/art_12_89516.html', '/art/2003/7/30/art_12_89515.html', '/art/2003/7/14/art_12_89514.html', '/art/2003/7/7/art_12_89513.html']
2018-10-27 23:40:35,328 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/5/8/art_12_89664.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:35,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:35,403 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 13182:  ï¼ˆ2002å¹´9æœˆ7æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬362å·å…¬å¸ƒ æ ¹æ®2012å¹´11æœˆ...
2018-10-27 23:40:35,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:35,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:35,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:35,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:35,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :603512
2018-10-27 23:40:35,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:35,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:35,428 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89677.html>
None
2018-10-27 23:40:35,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:35,480 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7401:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬620å· ã€Šå¯¹å¤–åŠ³åŠ¡åˆä½œç®¡ç†æ¡ä¾‹ã€‹å·²ç»2012å¹´5æœˆ...
2018-10-27 23:40:35,496 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:35,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:35,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:35,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:35,502 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :653767
2018-10-27 23:40:35,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:35,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:35,511 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/6/11/art_12_89665.html>
None
2018-10-27 23:40:35,512 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:35,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 9823:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬595å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆéŸ³åƒåˆ¶å“ç®¡ç†æ¡ä¾‹ã€‰çš„å†³å®šã€‹...
2018-10-27 23:40:35,603 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:35,608 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:35,608 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:35,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:35,611 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :719535
2018-10-27 23:40:35,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:35,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:35,626 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/3/23/art_12_89646.html>
None
2018-10-27 23:40:36,159 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:38,637 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:38,647 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:38,648 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:38,648 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:38,656 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:38,656 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:38,657 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "17", "value": ["1", "7"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:38,701 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:38,701 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:38,702 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:38,739 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:38,740 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:39,259 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:40,742 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:40,748 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19595
2018-10-27 23:40:40,749 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:40,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2003/6/23/art_12_89512.html', '/art/2003/6/23/art_12_89511.html', '/art/2003/6/5/art_12_89510.html', '/art/2003/5/30/art_12_89509.html', '/art/2003/5/13/art_12_89508.html', '/art/2003/5/8/art_12_89507.html', '/art/2003/5/7/art_12_89506.html', '/art/2003/3/21/art_12_89505.html', '/art/2003/3/21/art_12_89504.html', '/art/2003/3/21/art_12_89503.html', '/art/2003/3/21/art_12_89502.html', '/art/2003/3/21/art_12_89501.html', '/art/2003/3/21/art_12_89500.html', '/art/2003/3/21/art_12_89499.html', '/art/2003/3/21/art_12_89498.html']
2018-10-27 23:40:40,755 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/7/19/art_12_89631.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:40,757 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89616.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:40,760 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89617.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:40,763 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/4/10/art_12_89663.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:42,349 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:43,778 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:43,788 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:43,791 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:43,791 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:43,801 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:43,802 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:43,803 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "18", "value": ["1", "8"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:43,855 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:43,855 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:43,856 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:43,901 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:43,902 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:45,460 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:45,904 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:45,910 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 19415
2018-10-27 23:40:45,911 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:45,914 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2003/3/21/art_12_89497.html', '/art/2003/3/21/art_12_89496.html', '/art/2003/3/21/art_12_89495.html', '/art/2003/3/21/art_12_89494.html', '/art/2003/3/21/art_12_89493.html', '/art/2003/3/21/art_12_89492.html', '/art/2003/3/21/art_12_89491.html', '/art/2003/3/21/art_12_89490.html', '/art/2003/3/21/art_12_89489.html', '/art/2003/3/21/art_12_89488.html', '/art/2003/3/21/art_12_89487.html', '/art/2003/3/21/art_12_89486.html', '/art/2003/3/21/art_12_89485.html', '/art/2003/3/21/art_12_89484.html', '/art/2003/3/21/art_12_89483.html']
2018-10-27 23:40:45,918 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89601.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:45,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:45,956 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2403:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬619å· ã€Šå¥³èŒå·¥åŠ³åŠ¨ä¿æŠ¤ç‰¹åˆ«è§„å®šã€‹å·²ç»2012å¹´4...
2018-10-27 23:40:45,979 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:45,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:45,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:45,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:45,986 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :736412
2018-10-27 23:40:45,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:45,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:45,997 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/5/8/art_12_89664.html>
None
2018-10-27 23:40:48,578 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:48] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:49,007 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:49,016 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:49,016 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:49,017 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:49,024 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:49,025 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:49,025 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "19", "value": ["1", "9"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:49,063 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:49,064 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:49,064 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:49,095 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:49,096 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:51,098 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:51,104 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 18116
2018-10-27 23:40:51,105 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:51,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['/art/2003/3/21/art_12_89482.html', '/art/2003/3/20/art_12_89481.html', '/art/2003/3/18/art_12_89480.html', '/art/2003/2/20/art_12_89479.html', '/art/2003/2/20/art_12_89478.html', '/art/2003/2/20/art_12_89477.html', '/art/2003/2/14/art_12_89476.html']
2018-10-27 23:40:51,110 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89618.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:51,112 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89602.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:51,114 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89620.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:51,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:51,162 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4469:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬577å· ã€Šè‡ªç„¶ç¾å®³æ•‘åŠ©æ¡ä¾‹ã€‹å·²ç»2010å¹´6æœˆ30...
2018-10-27 23:40:51,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:51,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:51,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:51,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:51,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :767131
2018-10-27 23:40:51,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:51,200 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:51,200 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/7/19/art_12_89631.html>
None
2018-10-27 23:40:51,200 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:51,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3644:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬533å· ã€Šä¸­åäººæ°‘å…±å’Œå›½ç•œç¦½é—ä¼ èµ„æºè¿›å‡ºå¢ƒå’Œå¯¹å¤–åˆ...
2018-10-27 23:40:51,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:51,262 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:51,262 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:51,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:51,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :791734
2018-10-27 23:40:51,275 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:51,275 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:51,275 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89616.html>
None
2018-10-27 23:40:51,276 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:51,317 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3874:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬534å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå¤–å•†æŠ•èµ„ç”µä¿¡ä¼ä¸šç®¡...
2018-10-27 23:40:51,338 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:51,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:51,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:51,345 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:51,347 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :817158
2018-10-27 23:40:51,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:51,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:51,363 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89617.html>
None
2018-10-27 23:40:51,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:51,432 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7201:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬617å· ã€Šæ ¡è½¦å®‰å…¨ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2012å¹´3æœˆ28...
2018-10-27 23:40:51,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:51,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:51,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:51,472 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:51,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :865644
2018-10-27 23:40:51,488 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:51,488 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:51,489 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/4/10/art_12_89663.html>
None
2018-10-27 23:40:51,706 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:54,493 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element {"using": "xpath", "value": "//*[@id=\"1648\"]/table/tbody/tr/td/table//input[@type='text']", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:54,500 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element HTTP/1.1" 200 102
2018-10-27 23:40:54,501 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:54,501 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear {"id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:54,508 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/clear HTTP/1.1" 200 72
2018-10-27 23:40:54,508 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:54,509 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "19", "value": ["1", "9"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:54,547 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:54,548 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:54,548 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value {"text": "\ue007", "value": ["\ue007"], "id": "0.5086743821693631-1", "sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:54,576 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "POST /session/12d3dea3df62f9a9d9382f9d0ad32463/element/0.5086743821693631-1/value HTTP/1.1" 200 72
2018-10-27 23:40:54,576 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:54,826 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:56,577 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/source {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:56,585 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "GET /session/12d3dea3df62f9a9d9382f9d0ad32463/source HTTP/1.1" 200 18116
2018-10-27 23:40:56,586 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:56,587 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: DELETE http://127.0.0.1:58792/session/12d3dea3df62f9a9d9382f9d0ad32463/window {"sessionId": "12d3dea3df62f9a9d9382f9d0ad32463"}
2018-10-27 23:40:56,693 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:58792 "DELETE /session/12d3dea3df62f9a9d9382f9d0ad32463/window HTTP/1.1" 200 70
2018-10-27 23:40:56,694 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:40:56,699 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89619.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:56,702 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/12/26/art_12_89572.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:56,705 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/1/4/art_12_89573.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:56,709 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/5/8/art_12_89574.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:56,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:56,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3351:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬545å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½èˆªé“...
2018-10-27 23:40:56,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:56,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:56,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:56,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:56,809 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :892105
2018-10-27 23:40:56,829 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:56,830 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:56,830 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89601.html>
None
2018-10-27 23:40:56,831 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 36 pages (at 26 pages/min), scraped 27 items (at 20 items/min)
2018-10-27 23:40:56,833 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:56,892 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4451:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬535å· ã€Šä¸­åäººæ°‘å…±å’Œå›½åŠ³åŠ¨åˆåŒæ³•å®æ–½æ¡ä¾‹ã€‹å·²ç»2...
2018-10-27 23:40:56,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:56,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:56,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:56,933 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:56,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :922400
2018-10-27 23:40:56,950 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:56,951 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:56,951 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89618.html>
None
2018-10-27 23:40:56,952 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:56,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 274:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬546å· 1951å¹´8æœˆ8æ—¥æ”¿åŠ¡é™¢å…¬å¸ƒçš„ã€ŠåŸå¸‚æˆ¿åœ°äº§...
2018-10-27 23:40:57,002 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:57,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:57,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:57,008 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:57,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :924761
2018-10-27 23:40:57,024 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:57,025 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:57,025 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89602.html>
None
2018-10-27 23:40:57,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:57,067 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 498:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬548å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå›½åŠ¡é™¢å¯¹ç¡®éœ€ä¿ç•™çš„...
2018-10-27 23:40:57,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:57,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:57,105 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:57,105 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:57,111 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :928687
2018-10-27 23:40:57,131 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:57,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:57,133 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89620.html>
None
2018-10-27 23:40:57,151 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:57,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 8982:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬536å· ã€Šä¹³å“è´¨é‡å®‰å…¨ç›‘ç£ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2008å¹´...
2018-10-27 23:40:57,267 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:57,274 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:57,275 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:57,275 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:57,281 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :988204
2018-10-27 23:40:57,309 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:57,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:57,312 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89619.html>
None
2018-10-27 23:40:57,314 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:57,434 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:57,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:57,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:57,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:57,442 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :988976
2018-10-27 23:40:57,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:57,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:57,456 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/12/26/art_12_89572.html>
None
2018-10-27 23:40:57,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:57,605 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:57,608 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:57,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:57,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:57,612 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :989740
2018-10-27 23:40:57,626 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:57,627 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:57,627 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/1/4/art_12_89573.html>
None
2018-10-27 23:40:57,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:57,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:57,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:57,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:57,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:57,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :990510
2018-10-27 23:40:57,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:57,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:57,835 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/5/8/art_12_89574.html>
None
2018-10-27 23:40:57,949 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:40:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:40:59,097 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/4/20/art_12_89527.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:59,101 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89559.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:59,104 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/6/23/art_12_89512.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:59,106 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/7/7/art_12_89513.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:59,108 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/7/30/art_12_89515.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:59,146 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/7/14/art_12_89514.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:40:59,201 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:59,303 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:59,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:59,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:59,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:59,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :991341
2018-10-27 23:40:59,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:59,335 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:59,336 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/4/20/art_12_89527.html>
None
2018-10-27 23:40:59,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:59,512 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:59,515 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:59,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:59,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:59,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :992172
2018-10-27 23:40:59,535 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:59,537 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:59,539 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89559.html>
None
2018-10-27 23:40:59,541 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:59,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:59,670 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:59,670 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:59,670 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:59,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :992967
2018-10-27 23:40:59,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:59,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:59,688 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/6/23/art_12_89512.html>
None
2018-10-27 23:40:59,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:59,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:59,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:59,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:59,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:59,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :993737
2018-10-27 23:40:59,810 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:59,810 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:59,811 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/7/7/art_12_89513.html>
None
2018-10-27 23:40:59,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:40:59,926 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:40:59,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:40:59,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:40:59,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:40:59,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :994466
2018-10-27 23:40:59,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:40:59,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:40:59,946 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/7/30/art_12_89515.html>
None
2018-10-27 23:40:59,947 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:00,038 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:00,042 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:00,043 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:00,043 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:00,046 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :995207
2018-10-27 23:41:00,077 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:00,078 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:00,078 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/7/14/art_12_89514.html>
None
2018-10-27 23:41:00,099 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89558.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:00,201 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:00,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:00,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:00,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:00,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:00,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :995948
2018-10-27 23:41:00,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:00,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:00,381 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89558.html>
None
2018-10-27 23:41:01,087 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89557.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:01,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:01,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:01,267 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:01,267 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:01,267 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:01,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :996695
2018-10-27 23:41:01,283 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:01,283 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:01,283 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89557.html>
None
2018-10-27 23:41:01,538 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89497.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:01,574 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89482.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:01,597 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89484.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:01,600 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89483.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:01,603 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/2/20/art_12_89477.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:01,605 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/2/14/art_12_89476.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:01,640 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:01,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.Section1 of length 13290:  ï¼ˆ2002å¹´8æœˆ4æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬360å·å…¬å¸ƒ è‡ª2002å¹´9æœˆ15...
2018-10-27 23:41:01,779 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:01,790 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:01,790 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:01,791 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:01,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1086682
2018-10-27 23:41:01,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:01,826 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:01,826 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89497.html>
None
2018-10-27 23:41:01,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:01,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:01,964 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:01,964 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:01,965 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:01,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1087411
2018-10-27 23:41:01,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:01,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:01,998 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89482.html>
None
2018-10-27 23:41:01,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:02,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:02,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:02,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:02,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:02,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1088152
2018-10-27 23:41:02,126 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:02,126 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:02,127 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89484.html>
None
2018-10-27 23:41:02,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:02,221 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:02,224 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:02,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:02,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:02,232 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1088893
2018-10-27 23:41:02,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:02,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:02,273 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89483.html>
None
2018-10-27 23:41:02,273 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:02,452 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:02,457 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:02,458 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:02,458 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:02,460 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1089634
2018-10-27 23:41:02,492 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:02,492 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:02,493 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/2/20/art_12_89477.html>
None
2018-10-27 23:41:02,493 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:02,629 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:02,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:02,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:02,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:02,640 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1090363
2018-10-27 23:41:02,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:02,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:02,664 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/2/14/art_12_89476.html>
None
2018-10-27 23:41:02,670 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/2/20/art_12_89478.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:02,772 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:02,914 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:02,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:02,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:02,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:02,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1091104
2018-10-27 23:41:02,955 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:02,955 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:02,955 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/2/20/art_12_89478.html>
None
2018-10-27 23:41:04,011 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/18/art_12_89480.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:04,073 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89486.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:04,103 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89485.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:04,111 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89488.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:04,122 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/20/art_12_89481.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:04,126 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89487.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:04,131 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:04,340 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.Section1 of length 14183:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬ï¼“ï¼—ï¼“å· ã€Šç‰¹ç§è®¾å¤‡å®‰å…¨ç›‘å¯Ÿæ¡ä¾‹ã€‹å·²ç»ï¼’ï¼ï¼ï¼“å¹´ï¼’æœˆï¼‘...
2018-10-27 23:41:04,377 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:04,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:04,383 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:04,383 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:04,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1197668
2018-10-27 23:41:04,402 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:04,403 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:04,403 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/18/art_12_89480.html>
None
2018-10-27 23:41:04,409 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:04,656 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.Section1 of length 14814:  ï¼ˆ2002å¹´1æœˆ9æ—¥å›½åŠ¡é™¢ç¬¬52æ¬¡å¸¸åŠ¡ä¼šè®®é€šè¿‡ 2002å¹´1æœˆ26æ—¥ä¸­åäººæ°‘å…±...
2018-10-27 23:41:04,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:04,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:04,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:04,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:04,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1300835
2018-10-27 23:41:04,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:04,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:04,743 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89486.html>
None
2018-10-27 23:41:04,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:04,832 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:04,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:04,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:04,841 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:04,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1301576
2018-10-27 23:41:04,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:04,879 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:04,879 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89485.html>
None
2018-10-27 23:41:04,881 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:05,139 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:05,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:05,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:05,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:05,153 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1302383
2018-10-27 23:41:05,178 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:05,179 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:05,179 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89488.html>
None
2018-10-27 23:41:05,180 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:05,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:05,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:05,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:05,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:05,309 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1303154
2018-10-27 23:41:05,326 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:05,327 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:05,327 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/20/art_12_89481.html>
None
2018-10-27 23:41:05,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:05,531 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:05,536 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:05,537 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:05,537 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:05,540 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1303895
2018-10-27 23:41:05,560 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:05,560 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:05,561 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89487.html>
None
2018-10-27 23:41:05,575 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89489.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:05,677 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:05,896 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.Section1 of length 10139:  ï¼ˆ2002å¹´2æœˆ20æ—¥å›½åŠ¡é™¢ç¬¬55æ¬¡å¸¸åŠ¡ä¼šè®®é€šè¿‡ 2002å¹´4æœˆ4æ—¥ä¸­åäººæ°‘å…±...
2018-10-27 23:41:05,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:05,951 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:05,952 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:05,952 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:05,958 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1376012
2018-10-27 23:41:05,990 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:05,990 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:05,991 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89489.html>
None
2018-10-27 23:41:06,440 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89490.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:06,493 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89491.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:06,518 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89492.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:06,539 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89493.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:06,542 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:06,626 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:06,631 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:06,632 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:06,632 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:06,635 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1376783
2018-10-27 23:41:06,658 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:06,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:06,659 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89490.html>
None
2018-10-27 23:41:06,662 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89495.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:06,670 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89494.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:06,677 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:06,832 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:06,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:06,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:06,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:06,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1377548
2018-10-27 23:41:06,863 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:06,864 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:06,865 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89491.html>
None
2018-10-27 23:41:06,865 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:06,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:06,979 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:06,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:06,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:06,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1378295
2018-10-27 23:41:07,020 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:07,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:07,021 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89492.html>
None
2018-10-27 23:41:07,022 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:07,103 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:07,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:07,113 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:07,113 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:07,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1379072
2018-10-27 23:41:07,164 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:07,166 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:07,166 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89493.html>
None
2018-10-27 23:41:07,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:07,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:07,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:07,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:07,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:07,289 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1379825
2018-10-27 23:41:07,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:07,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:07,308 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89495.html>
None
2018-10-27 23:41:07,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:07,409 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.Section1 of length 11851:  ï¼ˆ2002å¹´6æœˆ19æ—¥å›½åŠ¡é™¢ç¬¬60æ¬¡å¸¸åŠ¡ä¼šè®®é€šè¿‡ 2002å¹´6æœˆ28æ—¥ä¸­åäººæ°‘...
2018-10-27 23:41:07,454 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:07,459 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:07,460 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:07,460 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:07,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1460402
2018-10-27 23:41:07,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:07,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:07,495 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89494.html>
None
2018-10-27 23:41:18,568 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/2/20/art_12_89479.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:18,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:18,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:18,768 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:18,768 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:18,768 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:18,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1461149
2018-10-27 23:41:18,791 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:18,792 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:18,792 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/2/20/art_12_89479.html>
None
2018-10-27 23:41:35,602 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89496.html via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-27 23:41:36,450 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89498.html via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-27 23:41:36,506 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89499.html via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-27 23:41:36,530 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89500.html via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-27 23:41:36,555 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89501.html via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-27 23:41:36,757 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89502.html via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-27 23:41:37,193 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89503.html via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-27 23:41:38,066 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89505.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:38,168 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:38,375 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.Section1 of length 23418:  ï¼ˆ2002å¹´12æœˆ28æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬368å·å…¬å¸ƒ è‡ª2003å¹´2æœˆ...
2018-10-27 23:41:38,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:38,442 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:38,442 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:38,443 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:38,452 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1625775
2018-10-27 23:41:38,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:38,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:38,489 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89505.html>
None
2018-10-27 23:41:38,624 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/5/7/art_12_89506.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:38,686 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/5/8/art_12_89507.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:38,718 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/5/13/art_12_89508.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:38,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:38,892 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:38,904 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:38,904 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:38,904 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:38,907 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1626491
2018-10-27 23:41:38,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:38,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:38,932 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/5/7/art_12_89506.html>
None
2018-10-27 23:41:38,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:39,035 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:39,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:39,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:39,046 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:39,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1627243
2018-10-27 23:41:39,096 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:39,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:39,097 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/5/8/art_12_89507.html>
None
2018-10-27 23:41:39,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:39,248 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:39,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:39,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:39,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:39,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1628008
2018-10-27 23:41:39,298 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:39,298 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:39,299 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/5/13/art_12_89508.html>
None
2018-10-27 23:41:39,302 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/6/5/art_12_89510.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:39,308 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/5/30/art_12_89509.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:39,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:39,527 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:39,535 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:39,535 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:39,536 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:39,539 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1628784
2018-10-27 23:41:39,563 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:39,563 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:39,564 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/6/5/art_12_89510.html>
None
2018-10-27 23:41:39,569 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/6/23/art_12_89511.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:39,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:39,675 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:39,681 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:39,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:39,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:39,685 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1629585
2018-10-27 23:41:39,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:39,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:39,705 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/5/30/art_12_89509.html>
None
2018-10-27 23:41:39,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:39,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:39,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:39,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:39,876 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:39,883 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1630302
2018-10-27 23:41:39,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:39,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:39,918 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/6/23/art_12_89511.html>
None
2018-10-27 23:41:40,429 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/8/1/art_12_89516.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:40,532 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:40,629 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:40,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:40,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:40,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:40,638 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1631018
2018-10-27 23:41:40,660 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:40,661 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:40,661 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/8/1/art_12_89516.html>
None
2018-10-27 23:41:41,068 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89499.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:41,071 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89496.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:41,075 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89498.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:41,080 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89504.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:41,171 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:41,288 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:41,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:41,294 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:41,294 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:41,300 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1631735
2018-10-27 23:41:41,332 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:41,332 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:41,333 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89499.html>
None
2018-10-27 23:41:41,339 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:41,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:41,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:41,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:41,430 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:41,432 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1632476
2018-10-27 23:41:41,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:41,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:41,453 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89496.html>
None
2018-10-27 23:41:41,454 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:41,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:41,535 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:41,535 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:41,535 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:41,538 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1633295
2018-10-27 23:41:41,564 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:41,565 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:41,565 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89498.html>
None
2018-10-27 23:41:41,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:41,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.Section1 of length 14231:  ï¼ˆ2002å¹´9æœˆ7æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬362å·å…¬å¸ƒ è‡ª2002å¹´10æœˆ1...
2018-10-27 23:41:41,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:41,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:41,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:41,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:41,772 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1734222
2018-10-27 23:41:41,811 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:41,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:41,812 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89504.html>
None
2018-10-27 23:41:41,815 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89500.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:41,819 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89501.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:41,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:42,063 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:42,068 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:42,068 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:42,069 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:42,075 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1735113
2018-10-27 23:41:42,103 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:42,103 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:42,104 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89500.html>
None
2018-10-27 23:41:42,107 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89502.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:42,110 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:42,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:42,268 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:42,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:42,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:42,275 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1735950
2018-10-27 23:41:42,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:42,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:42,302 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89501.html>
None
2018-10-27 23:41:42,304 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:42,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:42,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:42,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:42,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:42,397 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1736679
2018-10-27 23:41:42,422 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:42,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:42,423 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89502.html>
None
2018-10-27 23:41:50,106 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89503.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:50,210 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:50,303 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:50,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:50,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:50,309 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:50,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1737450
2018-10-27 23:41:50,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:50,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:50,333 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/3/21/art_12_89503.html>
None
2018-10-27 23:41:50,405 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/8/26/art_12_89518.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:50,427 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/8/19/art_12_89517.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:50,472 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/9/1/art_12_89519.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:50,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:50,624 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:50,630 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:50,631 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:50,631 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:50,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1738205
2018-10-27 23:41:50,669 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:50,670 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:50,670 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/8/26/art_12_89518.html>
None
2018-10-27 23:41:50,676 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2003/10/31/art_12_89520.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:50,677 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:50,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:50,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:50,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:50,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:50,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1738922
2018-10-27 23:41:50,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:50,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:50,785 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/8/19/art_12_89517.html>
None
2018-10-27 23:41:50,786 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:50,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:50,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:50,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:50,925 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:50,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1739656
2018-10-27 23:41:50,962 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:50,962 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:50,963 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/9/1/art_12_89519.html>
None
2018-10-27 23:41:50,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:51,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:51,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:51,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:51,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:51,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1740416
2018-10-27 23:41:51,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:51,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:51,189 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2003/10/31/art_12_89520.html>
None
2018-10-27 23:41:51,192 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/1/20/art_12_89523.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:51,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:51,433 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:51,440 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:51,440 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:51,441 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:51,444 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1741151
2018-10-27 23:41:51,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:51,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:51,469 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/1/20/art_12_89523.html>
None
2018-10-27 23:41:53,154 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/4/20/art_12_89529.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:53,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:53,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:53,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:53,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:53,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:53,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1741976
2018-10-27 23:41:53,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:53,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:53,386 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/4/20/art_12_89529.html>
None
2018-10-27 23:41:55,514 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 87 pages (at 51 pages/min), scraped 85 items (at 58 items/min)
2018-10-27 23:41:55,552 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/5/8/art_12_89531.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:55,654 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:55,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:55,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:55,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:55,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:55,822 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1742764
2018-10-27 23:41:55,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:55,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:55,851 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/5/8/art_12_89531.html>
None
2018-10-27 23:41:57,544 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/4/20/art_12_89528.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:57,646 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:57,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:57,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:57,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:57,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:57,772 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1743589
2018-10-27 23:41:57,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:57,802 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:57,802 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/4/20/art_12_89528.html>
None
2018-10-27 23:41:57,908 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/1/5/art_12_89521.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:57,914 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/5/17/art_12_89532.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:57,929 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/1/12/art_12_89522.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:57,944 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/5/8/art_12_89530.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:58,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:58,147 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:58,151 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:58,152 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:58,152 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:58,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1744371
2018-10-27 23:41:58,182 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:58,182 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:58,183 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/1/5/art_12_89521.html>
None
2018-10-27 23:41:58,185 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/3/18/art_12_89526.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:58,188 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/2/4/art_12_89525.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:58,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:58,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:58,378 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:58,378 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:58,379 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:58,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1745088
2018-10-27 23:41:58,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:58,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:58,425 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/5/17/art_12_89532.html>
None
2018-10-27 23:41:58,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:58,535 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:58,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:58,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:58,546 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:58,554 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1745829
2018-10-27 23:41:58,598 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:58,598 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:58,598 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/1/12/art_12_89522.html>
None
2018-10-27 23:41:58,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:58,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:58,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:58,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:58,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:58,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1746551
2018-10-27 23:41:58,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:58,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:58,774 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/5/8/art_12_89530.html>
None
2018-10-27 23:41:58,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:58,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:58,925 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:58,925 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:58,925 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:58,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1747340
2018-10-27 23:41:58,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:58,955 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:58,955 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/3/18/art_12_89526.html>
None
2018-10-27 23:41:58,956 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:59,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:59,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:59,101 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:59,101 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:59,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1748056
2018-10-27 23:41:59,154 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:59,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:59,155 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/2/4/art_12_89525.html>
None
2018-10-27 23:41:59,158 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/2/2/art_12_89524.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:41:59,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:41:59,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:41:59,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:41:59,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:41:59,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:41:59,433 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1748796
2018-10-27 23:41:59,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:41:59,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:41:59,475 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/2/2/art_12_89524.html>
None
2018-10-27 23:41:59,921 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89533.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:00,023 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:00,147 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:00,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:00,157 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:00,157 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:00,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1749681
2018-10-27 23:42:00,185 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:00,185 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:00,186 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89533.html>
None
2018-10-27 23:42:00,188 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89537.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:00,190 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89534.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:00,196 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89536.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:00,199 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89535.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:00,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:00,403 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:00,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:00,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:00,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:00,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1750494
2018-10-27 23:42:00,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:00,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:00,468 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89537.html>
None
2018-10-27 23:42:00,472 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:00,623 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:00,635 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:00,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:00,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:00,642 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1751223
2018-10-27 23:42:00,686 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:00,687 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:00,687 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89534.html>
None
2018-10-27 23:42:00,693 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/6/4/art_12_89539.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:00,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:00,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:00,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:00,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:00,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:00,869 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1751988
2018-10-27 23:42:00,920 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:00,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:00,922 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89536.html>
None
2018-10-27 23:42:00,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:01,141 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:01,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:01,149 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:01,149 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:01,153 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1752741
2018-10-27 23:42:01,181 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:01,181 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:01,182 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/5/24/art_12_89535.html>
None
2018-10-27 23:42:01,187 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/5/27/art_12_89538.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:01,192 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:01,285 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:01,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:01,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:01,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:01,299 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1753469
2018-10-27 23:42:01,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:01,336 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:01,339 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/6/4/art_12_89539.html>
None
2018-10-27 23:42:01,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:01,521 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:01,532 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:01,532 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:01,532 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:01,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1754228
2018-10-27 23:42:01,587 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:01,587 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:01,588 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/5/27/art_12_89538.html>
None
2018-10-27 23:42:01,591 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/6/9/art_12_89540.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:01,694 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:01,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:01,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:01,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:01,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:01,859 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1754986
2018-10-27 23:42:01,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:01,909 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:01,909 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/6/9/art_12_89540.html>
None
2018-10-27 23:42:02,122 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/6/30/art_12_89541.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:02,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:02,316 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:02,321 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:02,322 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:02,322 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:02,326 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1755787
2018-10-27 23:42:02,351 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:02,351 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:02,352 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/6/30/art_12_89541.html>
None
2018-10-27 23:42:02,575 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/11/5/art_12_89545.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:02,580 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/7/6/art_12_89542.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:02,617 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/8/16/art_12_89544.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:02,678 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:02,833 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:02,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:02,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:02,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:02,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1756516
2018-10-27 23:42:02,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:02,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:02,875 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/11/5/art_12_89545.html>
None
2018-10-27 23:42:02,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:02,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:02,980 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:02,980 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:02,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:02,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1757244
2018-10-27 23:42:03,005 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:03,005 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:03,006 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/7/6/art_12_89542.html>
None
2018-10-27 23:42:03,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:03,478 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.Section1 of length 68216:  ï¼ˆ2004å¹´6æœˆ29æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬412å·å‘å¸ƒ è‡ª2004å¹´7æœˆ1...
2018-10-27 23:42:03,586 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:03,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:03,602 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:03,602 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:03,607 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2224555
2018-10-27 23:42:03,658 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:03,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:03,659 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/8/16/art_12_89544.html>
None
2018-10-27 23:42:03,662 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/11/5/art_12_89547.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:03,667 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/7/30/art_12_89543.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:03,669 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/11/5/art_12_89546.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:03,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:03,896 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:03,903 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:03,903 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:03,903 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:03,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2225332
2018-10-27 23:42:03,938 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:03,938 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:03,939 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/11/5/art_12_89547.html>
None
2018-10-27 23:42:03,942 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:04,036 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:04,044 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:04,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:04,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:04,048 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2226157
2018-10-27 23:42:04,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:04,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:04,076 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/7/30/art_12_89543.html>
None
2018-10-27 23:42:04,077 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:04,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:04,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:04,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:04,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:04,198 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2226874
2018-10-27 23:42:04,226 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:04,227 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:04,227 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/11/5/art_12_89546.html>
None
2018-10-27 23:42:04,229 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2004/11/5/art_12_89548.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:04,330 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:04,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:04,441 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:04,441 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:04,442 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:04,447 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2227657
2018-10-27 23:42:04,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:04,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:04,501 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2004/11/5/art_12_89548.html>
None
2018-10-27 23:42:04,504 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89549.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:04,607 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:04,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:04,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:04,726 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:04,726 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:04,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2228422
2018-10-27 23:42:04,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:04,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:04,758 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89549.html>
None
2018-10-27 23:42:04,974 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89551.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:04,988 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89550.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:05,014 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89552.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:05,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:05,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:05,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:05,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:05,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:05,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2229199
2018-10-27 23:42:05,241 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:05,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:05,242 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89551.html>
None
2018-10-27 23:42:05,246 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:05,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:05,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:05,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:05,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:05,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2229982
2018-10-27 23:42:05,421 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:05,422 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:05,422 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89550.html>
None
2018-10-27 23:42:05,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:05,472 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7264:  ï¼ˆ2004å¹´8æœˆ18æ—¥å›½åŠ¡é™¢ç¬¬61æ¬¡å¸¸åŠ¡ä¼šè®®é€šè¿‡ 2004å¹´9æœˆ13æ—¥ä¸­åäººæ°‘...
2018-10-27 23:42:05,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:05,531 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:05,531 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:05,531 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:05,535 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2275822
2018-10-27 23:42:05,561 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:05,561 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:05,561 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89552.html>
None
2018-10-27 23:42:06,047 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89553.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:06,050 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89554.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:06,055 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89555.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:06,149 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:06,252 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:06,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:06,261 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:06,261 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:06,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2276563
2018-10-27 23:42:06,300 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:06,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:06,301 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89553.html>
None
2018-10-27 23:42:06,305 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:06,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:06,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:06,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:06,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:06,430 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2277280
2018-10-27 23:42:06,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:06,462 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:06,462 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89554.html>
None
2018-10-27 23:42:06,462 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:06,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:06,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:06,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:06,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:06,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2278057
2018-10-27 23:42:06,810 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:06,810 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:06,811 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89555.html>
None
2018-10-27 23:42:09,615 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89562.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:09,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:09,818 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:09,826 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:09,827 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:09,827 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:09,832 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2278798
2018-10-27 23:42:09,863 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:09,863 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:09,864 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89562.html>
None
2018-10-27 23:42:10,036 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89561.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:10,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:10,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:10,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:10,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:10,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:10,248 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2279587
2018-10-27 23:42:10,283 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:10,283 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:10,283 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89561.html>
None
2018-10-27 23:42:10,500 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89563.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:10,602 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:10,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:10,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:10,804 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:10,804 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:10,810 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2280412
2018-10-27 23:42:10,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:10,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:10,848 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89563.html>
None
2018-10-27 23:42:10,944 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89564.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:10,985 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89566.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:11,025 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89565.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:11,046 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:11,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:11,152 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:11,153 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:11,153 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:11,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2281207
2018-10-27 23:42:11,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:11,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:11,187 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89564.html>
None
2018-10-27 23:42:11,191 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:11,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:11,343 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:11,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:11,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:11,350 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2281967
2018-10-27 23:42:11,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:11,389 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:11,389 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89566.html>
None
2018-10-27 23:42:11,390 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:11,513 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:11,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:11,524 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:11,524 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:11,530 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2282756
2018-10-27 23:42:11,570 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:11,571 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:11,571 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89565.html>
None
2018-10-27 23:42:11,962 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89567.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:12,064 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:12,207 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:12,215 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:12,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:12,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:12,221 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2283504
2018-10-27 23:42:12,255 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:12,256 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:12,256 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89567.html>
None
2018-10-27 23:42:12,404 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89568.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:12,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:12,652 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:12,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:12,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:12,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:12,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2284252
2018-10-27 23:42:12,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:12,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:12,708 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89568.html>
None
2018-10-27 23:42:12,712 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89569.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:12,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:12,952 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:12,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:12,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:12,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:12,965 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2284994
2018-10-27 23:42:12,994 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:12,994 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:12,994 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89569.html>
None
2018-10-27 23:42:12,997 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89560.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:13,099 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:13,220 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:13,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:13,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:13,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:13,232 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2285747
2018-10-27 23:42:13,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:13,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:13,259 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89560.html>
None
2018-10-27 23:42:34,026 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89571.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:34,030 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/5/22/art_12_89577.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:34,034 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/5/8/art_12_89575.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:34,129 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:34,218 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:34,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:34,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:34,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:34,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2286501
2018-10-27 23:42:34,262 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:34,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:34,263 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89571.html>
None
2018-10-27 23:42:34,264 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89556.html via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-27 23:42:34,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:34,374 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:34,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:34,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:34,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:34,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2287308
2018-10-27 23:42:34,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:34,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:34,426 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/5/22/art_12_89577.html>
None
2018-10-27 23:42:34,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:34,558 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:34,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:34,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:34,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:34,572 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2288072
2018-10-27 23:42:34,604 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:34,605 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:34,605 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/5/8/art_12_89575.html>
None
2018-10-27 23:42:39,514 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/5/8/art_12_89576.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:39,536 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/5/24/art_12_89578.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:39,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:39,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:39,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:39,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:39,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:39,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2288854
2018-10-27 23:42:39,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:39,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:39,771 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/5/8/art_12_89576.html>
None
2018-10-27 23:42:39,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:39,894 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:39,902 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:39,902 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:39,902 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:39,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2289607
2018-10-27 23:42:39,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:39,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:39,946 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/5/24/art_12_89578.html>
None
2018-10-27 23:42:40,141 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89570.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:40,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:40,377 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:40,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:40,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:40,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:40,392 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2290403
2018-10-27 23:42:40,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:40,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:40,428 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/10/17/art_12_89570.html>
None
2018-10-27 23:42:40,559 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/12/28/art_12_89583.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:40,661 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:40,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:40,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:40,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:40,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:40,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2291169
2018-10-27 23:42:40,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:40,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:40,807 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/12/28/art_12_89583.html>
None
2018-10-27 23:42:41,019 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/7/31/art_12_89579.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:41,122 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:41,226 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:41,232 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:41,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:41,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:41,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2291898
2018-10-27 23:42:41,265 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:41,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:41,266 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/7/31/art_12_89579.html>
None
2018-10-27 23:42:41,896 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/8/25/art_12_206076.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:41,914 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2007/7/22/art_12_89584.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:41,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:42,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:42,176 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:42,176 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:42,176 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:42,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2292694
2018-10-27 23:42:42,215 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:42,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:42,216 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/8/25/art_12_206076.html>
None
2018-10-27 23:42:42,219 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:42,341 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:42,347 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:42,348 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:42,348 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:42,353 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2293453
2018-10-27 23:42:42,392 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:42,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:42,393 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2007/7/22/art_12_89584.html>
None
2018-10-27 23:42:42,515 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2007/7/22/art_12_89585.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:42,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:42,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:42,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:42,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:42,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:42,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2294236
2018-10-27 23:42:42,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:42,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:42,775 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2007/7/22/art_12_89585.html>
None
2018-10-27 23:42:42,921 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2007/9/22/art_12_89586.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:43,024 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:43,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:43,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:43,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:43,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:43,150 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2294995
2018-10-27 23:42:43,181 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:43,182 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:43,182 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2007/9/22/art_12_89586.html>
None
2018-10-27 23:42:43,406 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2007/10/15/art_12_89587.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:43,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:43,612 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:43,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:43,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:43,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:43,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2295851
2018-10-27 23:42:43,657 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:43,657 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:43,657 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2007/10/15/art_12_89587.html>
None
2018-10-27 23:42:44,115 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/1/14/art_12_89589.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:44,133 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2007/10/30/art_12_89588.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:44,218 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:44,339 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:44,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:44,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:44,353 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:44,359 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2296604
2018-10-27 23:42:44,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:44,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:44,394 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/1/14/art_12_89589.html>
None
2018-10-27 23:42:44,397 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:44,536 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:44,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:44,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:44,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:44,548 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2297364
2018-10-27 23:42:44,577 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:44,577 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:44,578 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2007/10/30/art_12_89588.html>
None
2018-10-27 23:42:44,921 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89556.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:45,024 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:45,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:45,139 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:45,140 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:45,140 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:45,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2298093
2018-10-27 23:42:45,175 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:45,176 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:45,176 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2005/4/27/art_12_89556.html>
None
2018-10-27 23:42:45,180 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/3/24/art_12_89590.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:45,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:45,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:45,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:45,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:45,430 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:45,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2298870
2018-10-27 23:42:45,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:45,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:45,467 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/3/24/art_12_89590.html>
None
2018-10-27 23:42:45,635 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/8/7/art_12_89591.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:45,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:45,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:45,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:45,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:45,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:45,866 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2299628
2018-10-27 23:42:45,894 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:45,894 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:45,894 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/8/7/art_12_89591.html>
None
2018-10-27 23:42:46,497 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/8/11/art_12_89592.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:46,510 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/8/12/art_12_89593.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:46,571 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/10/8/art_12_89581.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:46,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:46,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:46,726 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:46,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:46,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:46,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2300363
2018-10-27 23:42:46,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:46,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:46,769 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/8/11/art_12_89592.html>
None
2018-10-27 23:42:46,772 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/10/24/art_12_89582.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:46,775 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2006/9/30/art_12_89580.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:46,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:46,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:46,893 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:46,893 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:46,894 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:46,897 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2301092
2018-10-27 23:42:46,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:46,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:46,928 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/8/12/art_12_89593.html>
None
2018-10-27 23:42:46,928 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:47,072 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:47,083 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:47,083 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:47,083 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:47,092 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2301905
2018-10-27 23:42:47,129 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:47,130 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:47,130 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/10/8/art_12_89581.html>
None
2018-10-27 23:42:47,133 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/8/12/art_12_89594.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:47,140 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:47,252 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:47,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:47,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:47,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:47,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2302623
2018-10-27 23:42:47,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:47,296 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:47,296 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/10/24/art_12_89582.html>
None
2018-10-27 23:42:47,296 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:47,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:47,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:47,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:47,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:47,442 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2303346
2018-10-27 23:42:47,479 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:47,479 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:47,479 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2006/9/30/art_12_89580.html>
None
2018-10-27 23:42:47,483 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:47,591 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:47,598 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:47,598 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:47,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:47,603 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2304075
2018-10-27 23:42:47,637 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:47,637 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:47,637 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/8/12/art_12_89594.html>
None
2018-10-27 23:42:47,640 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/9/16/art_12_89595.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:47,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:47,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:47,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:47,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:47,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:47,853 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2304828
2018-10-27 23:42:47,887 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:47,887 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:47,887 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/9/16/art_12_89595.html>
None
2018-10-27 23:42:48,000 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/11/28/art_12_89596.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:48,102 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:48,202 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:48,208 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:48,208 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:48,209 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:48,214 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2305594
2018-10-27 23:42:48,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:48,246 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:48,246 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/11/28/art_12_89596.html>
None
2018-10-27 23:42:48,864 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/11/28/art_12_89597.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:48,896 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2008/11/28/art_12_89598.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:48,922 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89599.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:48,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:49,072 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:49,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:49,080 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:49,080 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:49,084 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2306360
2018-10-27 23:42:49,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:49,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:49,118 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/11/28/art_12_89597.html>
None
2018-10-27 23:42:49,120 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89600.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:49,122 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89603.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:49,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:49,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:49,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:49,244 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:49,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:49,253 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2307126
2018-10-27 23:42:49,289 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:49,289 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:49,289 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2008/11/28/art_12_89598.html>
None
2018-10-27 23:42:49,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:49,342 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3523:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬543å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½å…¬è·¯...
2018-10-27 23:42:49,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:49,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:49,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:49,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:49,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2334930
2018-10-27 23:42:49,447 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:49,448 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:49,448 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89599.html>
None
2018-10-27 23:42:49,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:49,504 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3411:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬544å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½æ°´è·¯...
2018-10-27 23:42:49,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:49,572 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:49,573 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:49,573 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:49,578 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2361766
2018-10-27 23:42:49,615 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:49,615 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:49,616 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89600.html>
None
2018-10-27 23:42:49,617 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:49,652 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2340:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ ä¸­åäººæ°‘å…±å’Œå›½ä¸­å¤®å†›äº‹å§”å‘˜ä¼šä»¤ ï¼ˆç¬¬ï¼•ï¼”ï¼—å·ï¼‰ ç°å…¬å¸ƒã€Š...
2018-10-27 23:42:49,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:49,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:49,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:49,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:49,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2377859
2018-10-27 23:42:49,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:49,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:49,766 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/1/20/art_12_89603.html>
None
2018-10-27 23:42:49,768 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89604.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:49,870 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:49,963 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3623:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬518å· ç°å…¬å¸ƒã€ŠåœŸåœ°è°ƒæŸ¥æ¡ä¾‹ã€‹ï¼Œè‡ªå…¬å¸ƒä¹‹æ—¥èµ·æ–½è¡Œã€‚...
2018-10-27 23:42:50,040 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:50,049 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:50,049 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:50,050 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:50,056 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2403571
2018-10-27 23:42:50,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:50,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:50,091 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89604.html>
None
2018-10-27 23:42:50,093 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89605.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:50,195 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:50,250 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6391:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬519å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½ä¸ªäºº...
2018-10-27 23:42:50,314 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:50,325 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:50,325 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:50,326 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:50,330 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2446657
2018-10-27 23:42:50,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:50,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:50,370 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89605.html>
None
2018-10-27 23:42:50,382 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89606.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:50,484 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:50,557 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 14011:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬522å· ã€Šè¯åˆ¸å…¬å¸ç›‘ç£ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2008å¹´4æœˆ...
2018-10-27 23:42:50,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:50,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:50,629 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:50,629 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:50,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2540518
2018-10-27 23:42:50,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:50,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:50,668 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89606.html>
None
2018-10-27 23:42:51,075 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89607.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:51,089 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89608.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:51,116 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89609.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:51,177 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:51,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 8283:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬523å· ã€Šè¯åˆ¸å…¬å¸é£é™©å¤„ç½®æ¡ä¾‹ã€‹å·²ç»2008å¹´4æœˆ...
2018-10-27 23:42:51,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:51,305 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:51,305 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:51,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:51,313 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2596728
2018-10-27 23:42:51,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:51,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:51,363 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89607.html>
None
2018-10-27 23:42:51,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:51,414 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4377:  ä¸­ å äºº æ°‘ å…± å’Œ å›½ å›½ åŠ¡ é™¢ ä»¤ ç¬¬521å· ä¸­åäººæ°‘å…±å’Œå›½ä¸­å¤®å†›äº‹...
2018-10-27 23:42:51,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:51,484 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:51,484 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:51,484 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:51,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2626295
2018-10-27 23:42:51,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:51,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:51,526 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89608.html>
None
2018-10-27 23:42:51,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:51,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4229:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬520å· ç°å…¬å¸ƒã€Šåœ°è´¨å‹˜æŸ¥èµ„è´¨ç®¡ç†æ¡ä¾‹ã€‹ï¼Œè‡ª2008...
2018-10-27 23:42:51,661 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:51,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:51,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:51,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:51,677 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2655156
2018-10-27 23:42:51,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:51,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:51,712 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89609.html>
None
2018-10-27 23:42:51,714 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89610.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:51,717 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89611.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:51,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:51,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6490:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬524å· ã€Šå†å²æ–‡åŒ–ååŸåé•‡åæ‘ä¿æŠ¤æ¡ä¾‹ã€‹å·²ç»200...
2018-10-27 23:42:51,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:51,940 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:51,940 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:51,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:51,949 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2699316
2018-10-27 23:42:51,986 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:51,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:51,987 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89610.html>
None
2018-10-27 23:42:51,989 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:52,034 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4679:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬525å· ã€Šç”ŸçŒªå± å®°ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2007å¹´12æœˆ1...
2018-10-27 23:42:52,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:52,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:52,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:52,108 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:52,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2730469
2018-10-27 23:42:52,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:52,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:52,146 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89611.html>
None
2018-10-27 23:42:52,149 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89612.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:52,252 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:52,325 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 10291:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬526å· ã€Šæ±¶å·åœ°éœ‡ç¾åæ¢å¤é‡å»ºæ¡ä¾‹ã€‹å·²ç»2008å¹´...
2018-10-27 23:42:52,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:52,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:52,420 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:52,420 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:52,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2798871
2018-10-27 23:42:52,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:52,476 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:52,476 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89612.html>
None
2018-10-27 23:42:52,479 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89613.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:52,552 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89614.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:52,581 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:52,627 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4967:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬527å· ã€Šå¯¹å¤–æ‰¿åŒ…å·¥ç¨‹ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2008å¹´5æœˆ...
2018-10-27 23:42:52,697 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:52,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:52,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:52,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:52,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2831116
2018-10-27 23:42:52,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:52,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:52,747 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89613.html>
None
2018-10-27 23:42:52,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:52,807 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 9922:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬528å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆè¥ä¸šæ€§æ¼”å‡ºç®¡ç†æ¡ä¾‹...
2018-10-27 23:42:52,871 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:52,884 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:52,884 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:52,885 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:52,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2896481
2018-10-27 23:42:52,937 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:52,938 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:52,938 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89614.html>
None
2018-10-27 23:42:53,495 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89615.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:53,500 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/7/24/art_12_89622.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:53,528 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89621.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:53,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:53,632 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 633:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬529å· ã€Šå›½åŠ¡é™¢å…³äºç»è¥è€…é›†ä¸­ç”³æŠ¥æ ‡å‡†çš„è§„å®šã€‹å·²ç»...
2018-10-27 23:42:53,695 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:53,706 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:53,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:53,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:53,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2901395
2018-10-27 23:42:53,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:53,748 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:53,748 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89615.html>
None
2018-10-27 23:42:53,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:53,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 8916:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬557å· ã€Šä¸­åäººæ°‘å…±å’Œå›½é£Ÿå“å®‰å…¨æ³•å®æ–½æ¡ä¾‹ã€‹å·²ç»2...
2018-10-27 23:42:53,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:53,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:53,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:53,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:53,873 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2956144
2018-10-27 23:42:53,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:53,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:53,914 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/7/24/art_12_89622.html>
None
2018-10-27 23:42:53,914 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:54,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 22622:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬549å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆç‰¹ç§è®¾å¤‡å®‰å…¨ç›‘å¯Ÿæ¡ä¾‹ã€‰çš„...
2018-10-27 23:42:54,106 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:54,122 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:54,122 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:54,123 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:54,128 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3103825
2018-10-27 23:42:54,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:54,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:54,170 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/2/11/art_12_89621.html>
None
2018-10-27 23:42:54,172 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/11/18/art_12_89624.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:54,180 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/10/20/art_12_89623.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:54,274 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:54,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2631:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬ï¼•ï¼–ï¼–å· ã€Šå¹¿æ’­ç”µå°ç”µè§†å°æ’­æ”¾å½•éŸ³åˆ¶å“æ”¯ä»˜æŠ¥é…¬æš‚è¡ŒåŠ...
2018-10-27 23:42:54,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:54,436 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:54,436 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:54,436 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:54,441 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3121889
2018-10-27 23:42:54,478 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:54,478 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:54,479 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/11/18/art_12_89624.html>
None
2018-10-27 23:42:54,481 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:54,531 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7161:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬564å· ã€Šä¿å®‰æœåŠ¡ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2009å¹´9æœˆ28...
2018-10-27 23:42:54,587 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:54,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:54,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:54,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:54,605 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3170762
2018-10-27 23:42:54,652 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:54,653 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:54,653 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/10/20/art_12_89623.html>
None
2018-10-27 23:42:54,656 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2009/12/14/art_12_89625.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:54,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:54,796 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 1367:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬567å· ã€Šå¤–å›½ä¼ä¸šæˆ–è€…ä¸ªäººåœ¨ä¸­å›½å¢ƒå†…è®¾ç«‹åˆä¼™ä¼ä¸šç®¡...
2018-10-27 23:42:54,864 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:54,880 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:54,880 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:54,881 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:54,893 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3180308
2018-10-27 23:42:54,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:54,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:54,941 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2009/12/14/art_12_89625.html>
None
2018-10-27 23:42:54,944 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/4/19/art_12_89627.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:55,008 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/3/30/art_12_89626.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:55,048 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:55,106 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6485:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬573å· ã€Šæ¶ˆè€—è‡­æ°§å±‚ç‰©è´¨ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2010å¹´3...
2018-10-27 23:42:55,175 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:55,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:55,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:55,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:55,192 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3223689
2018-10-27 23:42:55,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:55,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:55,243 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/4/19/art_12_89627.html>
None
2018-10-27 23:42:55,246 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:55,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4834:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬572å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½çŸ¥è¯†äº§æƒæµ·...
2018-10-27 23:42:55,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:55,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:55,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:55,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:55,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3256618
2018-10-27 23:42:55,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:55,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:55,417 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/3/30/art_12_89626.html>
None
2018-10-27 23:42:55,513 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 179 pages (at 92 pages/min), scraped 177 items (at 92 items/min)
2018-10-27 23:42:58,978 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/4/29/art_12_89628.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:58,982 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/5/31/art_12_89630.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:59,053 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/9/13/art_12_89633.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:59,057 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/9/2/art_12_89632.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:42:59,081 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:59,170 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 14889:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬574å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½å›½å¢ƒå«ç”Ÿæ£€...
2018-10-27 23:42:59,255 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:59,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:59,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:59,273 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:59,280 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3356166
2018-10-27 23:42:59,332 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:59,332 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:59,333 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/4/29/art_12_89628.html>
None
2018-10-27 23:42:59,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:59,407 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3685:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬576å· ã€Šå…¨å›½äººå£æ™®æŸ¥æ¡ä¾‹ã€‹å·²ç»2010å¹´5æœˆ12...
2018-10-27 23:42:59,481 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:59,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:59,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:59,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:59,502 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3381917
2018-10-27 23:42:59,570 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:59,570 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:59,571 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/5/31/art_12_89630.html>
None
2018-10-27 23:42:59,571 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:59,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7135:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬580å· ã€Šå¤ç”Ÿç‰©åŒ–çŸ³ä¿æŠ¤æ¡ä¾‹ã€‹å·²ç»2010å¹´8æœˆ2...
2018-10-27 23:42:59,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:59,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:59,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:59,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:59,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3429233
2018-10-27 23:42:59,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:42:59,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:42:59,783 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/9/13/art_12_89633.html>
None
2018-10-27 23:42:59,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:42:59,826 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5183:  ä¸­ å äºº æ°‘ å…± å’Œ å›½ å›½ åŠ¡ é™¢ ä»¤ ä¸­åäººæ°‘å…±å’Œå›½ä¸­å¤®å†›äº‹å§”å‘˜ä¼š ç¬¬5...
2018-10-27 23:42:59,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:42:59,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:42:59,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:42:59,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:42:59,942 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3464986
2018-10-27 23:43:00,005 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:00,005 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:00,006 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/9/2/art_12_89632.html>
None
2018-10-27 23:43:00,009 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/4/29/art_12_89629.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:00,011 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/9/20/art_12_89634.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:00,022 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/11/26/art_12_89635.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:00,049 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/12/13/art_12_89636.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:00,111 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:00,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6725:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬575å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½å¤–å›½äººå…¥å¢ƒ...
2018-10-27 23:43:00,255 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:00,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:00,270 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:00,270 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:00,276 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3509766
2018-10-27 23:43:00,323 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:00,324 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:00,324 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/4/29/art_12_89629.html>
None
2018-10-27 23:43:00,328 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:00,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3180:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬581å· ã€Šä¸­åäººæ°‘å…±å’Œå›½æµ·å…³äº‹åŠ¡æ‹…ä¿æ¡ä¾‹ã€‹å·²ç»20...
2018-10-27 23:43:00,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:00,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:00,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:00,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:00,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3532052
2018-10-27 23:43:00,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:00,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:00,518 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/9/20/art_12_89634.html>
None
2018-10-27 23:43:00,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:00,580 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7859:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬583å· ã€ŠåŸé•‡ç‡ƒæ°”ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2010å¹´10æœˆ1...
2018-10-27 23:43:00,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:00,681 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:00,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:00,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:00,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3583979
2018-10-27 23:43:00,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:00,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:00,737 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/11/26/art_12_89635.html>
None
2018-10-27 23:43:00,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:00,788 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5427:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬585å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä»·æ ¼è¿æ³•è¡Œä¸ºè¡Œæ”¿å¤„ç½šè§„å®š...
2018-10-27 23:43:00,870 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:00,883 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:00,884 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:00,884 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:00,893 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3620161
2018-10-27 23:43:00,943 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:00,943 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:00,943 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/12/13/art_12_89636.html>
None
2018-10-27 23:43:01,400 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/12/27/art_12_89638.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:01,415 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2010/12/24/art_12_89637.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:01,433 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/1/17/art_12_89639.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:01,456 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/1/21/art_12_89640.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:01,502 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:01,555 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7984:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬587å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½å‘ç¥¨ç®¡ç†åŠ...
2018-10-27 23:43:01,643 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:01,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:01,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:01,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:01,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3674795
2018-10-27 23:43:01,729 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:01,729 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:01,729 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/12/27/art_12_89638.html>
None
2018-10-27 23:43:01,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:01,802 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 13059:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬586å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå·¥ä¼¤ä¿é™©æ¡ä¾‹ã€‰çš„å†³å®šã€‹å·²...
2018-10-27 23:43:01,880 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:01,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:01,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:01,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:01,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3761985
2018-10-27 23:43:01,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:01,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:01,988 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2010/12/24/art_12_89637.html>
None
2018-10-27 23:43:01,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:02,049 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 9665:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬588å· ã€Šå›½åŠ¡é™¢å…³äºåºŸæ­¢å’Œä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹...
2018-10-27 23:43:02,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:02,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:02,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:02,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:02,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3825422
2018-10-27 23:43:02,221 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:02,221 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:02,222 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/1/17/art_12_89639.html>
None
2018-10-27 23:43:02,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:02,251 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 1983:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬ï¼•ï¼˜ï¼™å· ã€Šå›½å®¶èµ”å¿è´¹ç”¨ç®¡ç†æ¡ä¾‹ã€‹å·²ç»ï¼’ï¼ï¼‘ï¼å¹´ï¼‘ï¼’...
2018-10-27 23:43:02,336 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:02,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:02,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:02,353 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:02,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3839185
2018-10-27 23:43:02,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:02,414 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:02,414 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/1/21/art_12_89640.html>
None
2018-10-27 23:43:02,416 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/1/24/art_12_89641.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:02,426 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/3/13/art_12_89642.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:02,447 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/3/13/art_12_89643.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:02,451 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/3/15/art_12_89644.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:02,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:02,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4405:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬590å· ã€Šå›½æœ‰åœŸåœ°ä¸Šæˆ¿å±‹å¾æ”¶ä¸è¡¥å¿æ¡ä¾‹ã€‹å·²ç»201...
2018-10-27 23:43:02,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:02,660 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:02,660 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:02,660 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:02,668 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3869355
2018-10-27 23:43:02,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:02,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:02,723 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/1/24/art_12_89641.html>
None
2018-10-27 23:43:02,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:02,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 20855:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬591å· ã€Šå±é™©åŒ–å­¦å“å®‰å…¨ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2011å¹´2æœˆ...
2018-10-27 23:43:02,905 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:02,920 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:02,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:02,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:02,928 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4006871
2018-10-27 23:43:02,990 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:02,991 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:02,991 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/3/13/art_12_89642.html>
None
2018-10-27 23:43:02,991 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:03,037 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5782:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬592å· ã€ŠåœŸåœ°å¤å¦æ¡ä¾‹ã€‹å·²ç»2011å¹´2æœˆ22æ—¥å›½åŠ¡...
2018-10-27 23:43:03,122 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:03,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:03,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:03,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:03,144 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4046080
2018-10-27 23:43:03,203 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:03,204 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:03,204 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/3/13/art_12_89643.html>
None
2018-10-27 23:43:03,204 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:03,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 9755:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬593å· ã€Šå…¬è·¯å®‰å…¨ä¿æŠ¤æ¡ä¾‹ã€‹å·²ç»2011å¹´2æœˆ16...
2018-10-27 23:43:03,340 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:03,355 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:03,356 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:03,356 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:03,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4111499
2018-10-27 23:43:03,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:03,430 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:03,430 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/3/15/art_12_89644.html>
None
2018-10-27 23:43:03,640 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/3/23/art_12_89645.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:03,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:03,823 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 15842:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬594å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå‡ºç‰ˆç®¡ç†æ¡ä¾‹ã€‰çš„å†³å®šã€‹å·²ç»...
2018-10-27 23:43:03,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:03,939 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:03,940 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:03,940 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:03,952 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4217786
2018-10-27 23:43:04,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:04,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:04,015 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/3/23/art_12_89645.html>
None
2018-10-27 23:43:04,018 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/7/28/art_12_89649.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:04,021 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/4/29/art_12_89647.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:04,120 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:04,179 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4552:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬601å· ã€Šçƒˆå£«è¤’æ‰¬æ¡ä¾‹ã€‹å·²ç»2011å¹´7æœˆ20æ—¥å›½...
2018-10-27 23:43:04,298 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:04,315 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:04,316 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:04,316 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:04,327 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4248709
2018-10-27 23:43:04,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:04,395 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:04,395 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/7/28/art_12_89649.html>
None
2018-10-27 23:43:04,398 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:04,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2639:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬596å· ã€Šä¸ªä½“å·¥å•†æˆ·æ¡ä¾‹ã€‹å·²ç»2011å¹´3æœˆ30æ—¥...
2018-10-27 23:43:04,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:04,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:04,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:04,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:04,557 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4267049
2018-10-27 23:43:04,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:04,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:04,626 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/4/29/art_12_89647.html>
None
2018-10-27 23:43:04,628 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/9/8/art_12_89651.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:04,633 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/8/1/art_12_89650.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:04,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:04,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2313:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬603å· ã€Šå…¬å®‰æœºå…³ç£å¯Ÿæ¡ä¾‹ã€‹å·²ç»2011å¹´8æœˆ24...
2018-10-27 23:43:04,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:04,962 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:04,964 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:04,965 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:04,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4283347
2018-10-27 23:43:05,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:05,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:05,099 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/9/8/art_12_89651.html>
None
2018-10-27 23:43:05,101 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/10/11/art_12_89653.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:05,104 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/7/28/art_12_89648.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:05,110 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/10/11/art_12_89652.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:05,111 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:05,165 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7229:  ï¼ˆï¼’ï¼ï¼ï¼”å¹´ï¼˜æœˆï¼‘æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ã€ä¸­åäººæ°‘å…±å’Œå›½ä¸­å¤®å†›äº‹å§”å‘˜ä¼šä»¤ç¬¬ï¼”ï¼‘...
2018-10-27 23:43:05,268 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:05,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:05,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:05,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:05,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4332177
2018-10-27 23:43:05,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:05,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:05,353 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/8/1/art_12_89650.html>
None
2018-10-27 23:43:05,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:05,395 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4306:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬606å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½å¯¹å¤–åˆä½œå¼€...
2018-10-27 23:43:05,488 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:05,503 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:05,503 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:05,504 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:05,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4360812
2018-10-27 23:43:05,577 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:05,577 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:05,578 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/10/11/art_12_89653.html>
None
2018-10-27 23:43:05,578 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:05,627 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6126:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬600å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½ä¸ªäºº...
2018-10-27 23:43:05,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:05,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:05,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:05,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:05,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4402088
2018-10-27 23:43:05,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:05,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:05,838 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/7/28/art_12_89648.html>
None
2018-10-27 23:43:05,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:05,942 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>table.MsoNormalTable of length 222:  ç¨ ç›® ç¨ ç‡ ä¸€ã€åŸæ²¹ é”€å”®é¢çš„5%-10% äºŒã€å¤©ç„¶æ°” é”€å”®é¢çš„5%-10...
2018-10-27 23:43:05,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>table.MsoNormalTable of length 222:  ç¨ ç›® ç¨ ç‡ ä¸€ã€åŸæ²¹ é”€å”®é¢çš„5%-10% äºŒã€å¤©ç„¶æ°” é”€å”®é¢çš„5%-10...
2018-10-27 23:43:05,945 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 222:  ç¨ ç›® ç¨ ç‡ ä¸€ã€åŸæ²¹ é”€å”®é¢çš„5%-10% äºŒã€å¤©ç„¶æ°” é”€å”®é¢çš„5%-10...
2018-10-27 23:43:05,945 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{02} of length 222:  ç¨ ç›® ç¨ ç‡ ä¸€ã€åŸæ²¹ é”€å”®é¢çš„5%-10% äºŒã€å¤©ç„¶æ°” é”€å”®é¢çš„5%-10...
2018-10-27 23:43:05,947 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{03}>#zoom of length 2857:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬605å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½èµ„æºç¨æš‚è¡Œæ¡...
2018-10-27 23:43:06,114 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:06,143 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:06,144 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:06,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:06,165 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4431506
2018-10-27 23:43:06,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:06,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:06,246 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/10/11/art_12_89652.html>
None
2018-10-27 23:43:06,248 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/10/11/art_12_89654.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:06,349 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:06,395 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3846:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬607å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½å¯¹å¤–åˆä½œå¼€...
2018-10-27 23:43:06,480 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:06,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:06,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:06,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:06,510 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4457267
2018-10-27 23:43:06,580 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:06,581 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:06,581 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/10/11/art_12_89654.html>
None
2018-10-27 23:43:06,584 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/10/31/art_12_89655.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:06,590 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/11/16/art_12_89656.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:06,686 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:06,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6631:  ä¸­ å äºº æ°‘ å…± å’Œ å›½ å›½ åŠ¡ é™¢ ä»¤ ç¬¬608å· ä¸­åäººæ°‘å…±å’Œå›½ä¸­å¤®å†›äº‹...
2018-10-27 23:43:06,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:06,857 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:06,858 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:06,858 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:06,869 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4502409
2018-10-27 23:43:06,958 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:06,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:06,959 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/10/31/art_12_89655.html>
None
2018-10-27 23:43:06,962 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:07,042 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 11616:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬609å· ã€Šé¥²æ–™å’Œé¥²æ–™æ·»åŠ å‰‚ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2011å¹´...
2018-10-27 23:43:07,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:07,185 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:07,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:07,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:07,211 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4578144
2018-10-27 23:43:07,296 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:07,297 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:07,297 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/11/16/art_12_89656.html>
None
2018-10-27 23:43:07,299 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/12/12/art_12_89658.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:07,304 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/12/12/art_12_89657.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:07,402 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:07,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3069:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬611å· ã€Šä¸­åäººæ°‘å…±å’Œå›½è½¦èˆ¹ç¨æ³•å®æ–½æ¡ä¾‹ã€‹å·²ç»20...
2018-10-27 23:43:07,642 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:07,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:07,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:07,668 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:07,685 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4599259
2018-10-27 23:43:07,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:07,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:07,776 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/12/12/art_12_89658.html>
None
2018-10-27 23:43:07,779 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/6/19/art_12_89666.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:07,785 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/12/30/art_12_89659.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:07,788 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2011/12/30/art_12_89660.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:07,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:07,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>table.MsoNormalTable of length 274:  ç¨ ç›®ï¼ˆæŒ‰èˆ¹èˆ¶å‡€å¨ä½åˆ’åˆ†ï¼‰ ç¨ ç‡ï¼ˆå…ƒ/å‡€å¨ï¼‰ å¤‡ æ³¨ æ™®é€šç¨ç‡ ï¼ˆæŒ‰æ‰§ç…§æœŸé™...
2018-10-27 23:43:07,853 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 274:  ç¨ ç›®ï¼ˆæŒ‰èˆ¹èˆ¶å‡€å¨ä½åˆ’åˆ†ï¼‰ ç¨ ç‡ï¼ˆå…ƒ/å‡€å¨ï¼‰ å¤‡ æ³¨ æ™®é€šç¨ç‡ ï¼ˆæŒ‰æ‰§ç…§æœŸé™...
2018-10-27 23:43:07,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 2866:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬610å· ã€Šä¸­åäººæ°‘å…±å’Œå›½èˆ¹èˆ¶å¨ç¨æš‚è¡Œæ¡ä¾‹ã€‹å·²ç»20...
2018-10-27 23:43:07,963 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:07,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:07,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:07,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:07,992 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4625096
2018-10-27 23:43:08,064 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:08,064 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:08,064 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/12/12/art_12_89657.html>
None
2018-10-27 23:43:08,071 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:08,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5718:  å›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ŠæœºåŠ¨è½¦äº¤é€šäº‹æ•…è´£ä»»å¼ºåˆ¶ä¿é™©æ¡ä¾‹ã€‹çš„å†³å®š æ–°åç¤¾åŒ—äº¬ï¼”æœˆï¼“ï¼æ—¥ç”µ...
2018-10-27 23:43:08,221 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:08,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:08,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:08,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:08,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4664396
2018-10-27 23:43:08,314 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:08,314 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:08,315 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/6/19/art_12_89666.html>
None
2018-10-27 23:43:08,315 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:08,372 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7728:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬612å· ã€Šæ”¾å°„æ€§åºŸç‰©å®‰å…¨ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2011å¹´1...
2018-10-27 23:43:08,457 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:08,479 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:08,479 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:08,480 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:08,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4715371
2018-10-27 23:43:08,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:08,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:08,577 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/12/30/art_12_89659.html>
None
2018-10-27 23:43:08,577 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:08,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 12262:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬613å· ã€Šä¸­åäººæ°‘å…±å’Œå›½æ‹›æ ‡æŠ•æ ‡æ³•å®æ–½æ¡ä¾‹ã€‹å·²ç»2...
2018-10-27 23:43:08,796 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:08,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:08,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:08,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:08,828 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4797846
2018-10-27 23:43:08,892 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:08,892 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:08,893 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2011/12/30/art_12_89660.html>
None
2018-10-27 23:43:08,895 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/7/11/art_12_89667.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:08,949 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/9/7/art_12_89668.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:08,991 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/9/18/art_12_89669.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:08,996 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:09,032 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2552:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬622å· ã€Šæ— éšœç¢ç¯å¢ƒå»ºè®¾æ¡ä¾‹ã€‹å·²ç»2012å¹´6æœˆ1...
2018-10-27 23:43:09,142 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:09,159 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:09,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:09,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:09,170 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4815923
2018-10-27 23:43:09,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:09,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:09,228 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/7/11/art_12_89667.html>
None
2018-10-27 23:43:09,231 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:09,273 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3909:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬623å· ã€Šæ°”è±¡è®¾æ–½å’Œæ°”è±¡æ¢æµ‹ç¯å¢ƒä¿æŠ¤æ¡ä¾‹ã€‹å·²ç»20...
2018-10-27 23:43:09,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:09,399 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:09,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:09,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:09,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4842410
2018-10-27 23:43:09,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:09,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:09,509 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/9/7/art_12_89668.html>
None
2018-10-27 23:43:09,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:09,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3233:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬ï¼–ï¼’ï¼”å· ã€Šæ•™è‚²ç£å¯¼æ¡ä¾‹ã€‹å·²ç»ï¼’ï¼ï¼‘ï¼’å¹´ï¼˜æœˆï¼’ï¼™æ—¥å›½...
2018-10-27 23:43:09,656 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:09,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:09,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:09,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:09,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4865415
2018-10-27 23:43:09,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:09,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:09,747 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/9/18/art_12_89669.html>
None
2018-10-27 23:43:09,749 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/10/23/art_12_89670.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:09,751 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/10/31/art_12_89671.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:09,851 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:09,895 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5889:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬625å· ã€Šå›½å†…æ°´è·¯è¿è¾“ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2012å¹´9æœˆ...
2018-10-27 23:43:10,001 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:10,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:10,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:10,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:10,028 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4904782
2018-10-27 23:43:10,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:10,101 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:10,101 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/10/23/art_12_89670.html>
None
2018-10-27 23:43:10,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:10,144 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3367:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬626å· ã€Šç¼ºé™·æ±½è½¦äº§å“å¬å›ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2012å¹´...
2018-10-27 23:43:10,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:10,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:10,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:10,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:10,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4928136
2018-10-27 23:43:10,343 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:10,343 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:10,343 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/10/31/art_12_89671.html>
None
2018-10-27 23:43:10,346 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/11/6/art_12_89672.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:10,443 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/11/19/art_12_89673.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:10,448 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:10,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 17803:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬627å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆæœŸè´§äº¤æ˜“ç®¡ç†æ¡ä¾‹ã€‰çš„å†³å®š...
2018-10-27 23:43:10,658 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:10,678 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:10,678 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:10,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:10,690 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5048440
2018-10-27 23:43:10,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:10,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:10,761 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/11/6/art_12_89672.html>
None
2018-10-27 23:43:10,763 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/11/19/art_12_89674.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:10,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:10,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 885:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬628å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹å’ŒåºŸæ­¢éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„...
2018-10-27 23:43:10,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:10,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:10,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:10,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:10,943 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5054715
2018-10-27 23:43:11,017 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:11,017 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:11,017 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/11/19/art_12_89673.html>
None
2018-10-27 23:43:11,020 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:11,066 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3939:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬629å· ã€Šå†œä¸šä¿é™©æ¡ä¾‹ã€‹å·²ç»2012å¹´10æœˆ24æ—¥...
2018-10-27 23:43:11,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:11,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:11,206 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:11,206 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:11,221 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5081639
2018-10-27 23:43:11,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:11,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:11,292 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/11/19/art_12_89674.html>
None
2018-10-27 23:43:11,351 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89675.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:11,448 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89678.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:11,452 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:11,496 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4079:  ï¼ˆä¸€ä¹ä¹ä¸€å¹´äº”æœˆå…­æ—¥å›½åŠ¡é™¢æ‰¹å‡† ä¸€ä¹ä¹ä¸€å¹´ä¸ƒæœˆäºŒåäºŒæ—¥å›½å®¶å·¥å•†è¡Œæ”¿ç®¡ç†å±€ä»¤ç¬¬ä¸ƒ...
2018-10-27 23:43:11,596 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:11,617 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:11,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:11,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:11,629 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5109480
2018-10-27 23:43:11,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:11,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:11,705 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89675.html>
None
2018-10-27 23:43:11,708 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89679.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:11,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:11,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 8660:  ï¼ˆ2004å¹´4æœˆ14æ—¥å›½åŠ¡é™¢ç¬¬48æ¬¡å¸¸åŠ¡ä¼šè®®é€šè¿‡ 2004å¹´4æœˆ30æ—¥ä¸­åäººæ°‘...
2018-10-27 23:43:11,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:11,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:11,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:11,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:11,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5167864
2018-10-27 23:43:11,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:11,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:11,985 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89678.html>
None
2018-10-27 23:43:11,989 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:12,035 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4676:  ï¼ˆ2007å¹´6æœˆ27æ—¥å›½åŠ¡é™¢ç¬¬182æ¬¡å¸¸åŠ¡ä¼šè®®é€šè¿‡ 2007å¹´7æœˆ11æ—¥ä¸­åäºº...
2018-10-27 23:43:12,571 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:12,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:12,602 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:12,602 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:12,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5199092
2018-10-27 23:43:12,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:12,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:12,768 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2012/11/23/art_12_89679.html>
None
2018-10-27 23:43:12,771 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/1/6/art_12_89680.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:12,774 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/1/30/art_12_89682.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:12,776 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/1/6/art_12_89681.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:12,873 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:12,937 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3939:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬629å· ã€Šå†œä¸šä¿é™©æ¡ä¾‹ã€‹å·²ç»2012å¹´10æœˆ24æ—¥...
2018-10-27 23:43:13,195 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:13,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:13,230 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:13,230 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:13,249 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5226011
2018-10-27 23:43:13,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:13,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:13,381 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/1/6/art_12_89680.html>
None
2018-10-27 23:43:13,384 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/2/16/art_12_89683.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:13,386 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/2/16/art_12_89684.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:13,392 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:13,449 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6403:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬631å· ã€Šå¾ä¿¡ä¸šç®¡ç†æ¡ä¾‹ã€‹å·²ç»2012å¹´12æœˆ26...
2018-10-27 23:43:13,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:13,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:13,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:13,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:13,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5269641
2018-10-27 23:43:13,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:13,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:13,911 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/1/30/art_12_89682.html>
None
2018-10-27 23:43:13,911 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:13,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5957:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬630å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆæœºåŠ¨è½¦äº¤é€šäº‹æ•…è´£ä»»...
2018-10-27 23:43:14,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:14,178 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:14,179 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:14,179 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:14,197 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5309927
2018-10-27 23:43:14,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:14,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:14,272 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/1/6/art_12_89681.html>
None
2018-10-27 23:43:14,276 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:14,321 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4567:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬632å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆè®¡ç®—æœºè½¯ä»¶ä¿æŠ¤æ¡ä¾‹ã€‰çš„å†³...
2018-10-27 23:43:14,434 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:14,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:14,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:14,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:14,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5340829
2018-10-27 23:43:14,556 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:14,557 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:14,557 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/2/16/art_12_89683.html>
None
2018-10-27 23:43:14,557 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:14,602 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 27: å›½åŠ¡é™¢å…³äºä¿®æ”¹ã€Šä¸­åäººæ°‘å…±å’Œå›½è‘—ä½œæƒæ³•å®æ–½æ¡ä¾‹ã€‹çš„å†³å®š
2018-10-27 23:43:14,603 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 3873:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬633å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½è‘—ä½œæƒæ³•å®...
2018-10-27 23:43:14,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:14,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:14,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:14,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:14,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5366997
2018-10-27 23:43:14,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:14,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:14,862 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/2/16/art_12_89684.html>
None
2018-10-27 23:43:14,994 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/7/23/art_12_89688.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:15,020 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/8/1/art_12_89689.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:15,046 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/9/6/art_12_89690.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:15,099 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:15,168 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6431:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬637å· ã€Šä¸­åäººæ°‘å…±å’Œå›½å¤–å›½äººå…¥å¢ƒå‡ºå¢ƒç®¡ç†æ¡ä¾‹ã€‹å·²...
2018-10-27 23:43:15,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:15,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:15,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:15,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:15,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5410711
2018-10-27 23:43:15,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:15,567 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:15,568 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/7/23/art_12_89688.html>
None
2018-10-27 23:43:15,571 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/6/9/art_12_89687.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:15,574 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/2/16/art_12_89685.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:15,589 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:15,635 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3958:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬638å· ã€Šå›½åŠ¡é™¢å…³äºåºŸæ­¢å’Œä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹...
2018-10-27 23:43:15,832 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:15,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:15,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:15,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:15,879 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5437977
2018-10-27 23:43:15,958 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:15,958 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:15,958 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/8/1/art_12_89689.html>
None
2018-10-27 23:43:15,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:16,025 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 12923:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬639å· ã€Šé“è·¯å®‰å…¨ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2013å¹´7æœˆ24æ—¥...
2018-10-27 23:43:16,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:16,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:16,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:16,170 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:16,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5523952
2018-10-27 23:43:16,268 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:16,268 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:16,268 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/9/6/art_12_89690.html>
None
2018-10-27 23:43:16,270 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/9/17/art_12_89691.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:16,272 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/2/16/art_12_89686.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:16,280 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/10/17/art_12_89692.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:16,281 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:16,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4829:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬636å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½å¤–èµ„...
2018-10-27 23:43:16,440 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:16,465 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:16,465 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:16,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:16,487 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5557754
2018-10-27 23:43:16,595 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:16,595 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:16,597 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/6/9/art_12_89687.html>
None
2018-10-27 23:43:16,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:16,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5546:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬634å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¿¡æ¯ç½‘ç»œä¼ æ’­æƒä¿æŠ¤æ¡ä¾‹ã€‰...
2018-10-27 23:43:16,826 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:16,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:16,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:16,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:16,858 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5594533
2018-10-27 23:43:16,957 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:16,957 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:16,957 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/2/16/art_12_89685.html>
None
2018-10-27 23:43:16,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:17,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4705:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬640å· ã€Šé•¿æ±Ÿä¸‰å³¡æ°´åˆ©æ¢çº½å®‰å…¨ä¿å«æ¡ä¾‹ã€‹å·²ç»201...
2018-10-27 23:43:17,149 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:17,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:17,173 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:17,173 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:17,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5626591
2018-10-27 23:43:17,270 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:17,270 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:17,270 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/9/17/art_12_89691.html>
None
2018-10-27 23:43:17,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:17,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 28: å›½åŠ¡é™¢å…³äºä¿®æ”¹ã€Šä¸­åäººæ°‘å…±å’Œå›½æ¤ç‰©æ–°å“ç§ä¿æŠ¤æ¡ä¾‹ã€‹çš„å†³å®š
2018-10-27 23:43:17,321 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 5475:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬635å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½æ¤ç‰©æ–°å“ç§...
2018-10-27 23:43:17,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:17,449 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:17,450 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:17,450 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:17,463 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5663559
2018-10-27 23:43:17,539 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:17,539 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:17,539 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/2/16/art_12_89686.html>
None
2018-10-27 23:43:17,540 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:17,595 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 9637:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬641å· ã€ŠåŸé•‡æ’æ°´ä¸æ±¡æ°´å¤„ç†æ¡ä¾‹ã€‹å·²ç»2013å¹´9...
2018-10-27 23:43:17,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:17,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:17,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:17,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:17,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5726925
2018-10-27 23:43:17,828 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:17,828 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:17,829 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/10/17/art_12_89692.html>
None
2018-10-27 23:43:17,831 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/11/27/art_12_89693.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:17,833 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/11/27/art_12_89694.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:17,835 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/12/12/art_12_89695.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:17,933 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:17,975 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2731:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬642å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå›½é™…æ”¶æ”¯ç»Ÿè®¡ç”³æŠ¥åŠ...
2018-10-27 23:43:18,089 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:18,110 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:18,111 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:18,111 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:18,130 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5745526
2018-10-27 23:43:18,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:18,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:18,230 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/11/27/art_12_89693.html>
None
2018-10-27 23:43:18,232 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2013/12/19/art_12_89696.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:18,234 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/2/7/art_12_89697.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:18,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:18,285 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4815:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬643å· ã€Šç•œç¦½è§„æ¨¡å…»æ®–æ±¡æŸ“é˜²æ²»æ¡ä¾‹ã€‹å·²ç»2013å¹´...
2018-10-27 23:43:18,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:18,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:18,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:18,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:18,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5777626
2018-10-27 23:43:18,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:18,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:18,516 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/11/27/art_12_89694.html>
None
2018-10-27 23:43:18,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:18,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 900:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬644å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå…¨å›½å¹´èŠ‚åŠçºªå¿µæ—¥æ”¾...
2018-10-27 23:43:18,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:18,685 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:18,685 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:18,686 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:18,699 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5784235
2018-10-27 23:43:18,776 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:18,776 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:18,776 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/12/12/art_12_89695.html>
None
2018-10-27 23:43:18,785 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/2/28/art_12_89698.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:18,788 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/2/28/art_12_89699.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:18,788 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:18,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2750:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬645å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹å·²ç»2...
2018-10-27 23:43:18,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:18,945 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:18,945 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:18,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:18,958 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5802932
2018-10-27 23:43:19,033 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:19,034 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:19,034 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2013/12/19/art_12_89696.html>
None
2018-10-27 23:43:19,034 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:19,083 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6181:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬646å· ç°å…¬å¸ƒã€Šä¸­åäººæ°‘å…±å’Œå›½ä¿å®ˆå›½å®¶ç§˜å¯†æ³•å®æ–½æ¡...
2018-10-27 23:43:19,212 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:19,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:19,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:19,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:19,246 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5844606
2018-10-27 23:43:19,328 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:19,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:19,329 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/2/7/art_12_89697.html>
None
2018-10-27 23:43:19,335 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:19,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7709:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬647å· ã€Šå—æ°´åŒ—è°ƒå·¥ç¨‹ä¾›ç”¨æ°´ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2014...
2018-10-27 23:43:19,502 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:19,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:19,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:19,524 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:19,537 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5896267
2018-10-27 23:43:19,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:19,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:19,618 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/2/28/art_12_89698.html>
None
2018-10-27 23:43:19,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:19,683 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6606:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬649å· ç°å…¬å¸ƒã€Šç¤¾ä¼šæ•‘åŠ©æš‚è¡ŒåŠæ³•ã€‹ï¼Œè‡ª2014å¹´5...
2018-10-27 23:43:19,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:19,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:19,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:19,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:19,832 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5945390
2018-10-27 23:43:19,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:19,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:19,918 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/2/28/art_12_89699.html>
None
2018-10-27 23:43:19,920 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/3/3/art_12_89700.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:19,992 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/3/31/art_12_89701.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:20,009 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/5/15/art_12_89703.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:20,013 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/5/14/art_12_89702.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:20,022 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:20,060 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3058:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬648å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºåºŸæ­¢å’Œä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„...
2018-10-27 23:43:20,206 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:20,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:20,230 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:20,230 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:20,246 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5967429
2018-10-27 23:43:20,328 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:20,328 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:20,328 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/3/3/art_12_89700.html>
None
2018-10-27 23:43:20,332 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:20,397 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 51:  æ€»ç† æå…‹å¼º 2014å¹´3æœˆ7æ—¥
2018-10-27 23:43:20,399 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 14326:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬650å· ã€ŠåŒ»ç–—å™¨æ¢°ç›‘ç£ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2014å¹´2æœˆ...
2018-10-27 23:43:20,520 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:20,542 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:20,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:20,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:20,553 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6054791
2018-10-27 23:43:20,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:20,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:20,634 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/3/31/art_12_89701.html>
None
2018-10-27 23:43:20,635 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:20,681 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3040:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬652å· ã€Šäº‹ä¸šå•ä½äººäº‹ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2014å¹´2æœˆ...
2018-10-27 23:43:20,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:20,821 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:20,821 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:20,821 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:20,832 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6078099
2018-10-27 23:43:20,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:20,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:20,927 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/5/15/art_12_89703.html>
None
2018-10-27 23:43:20,928 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:20,995 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 73: ä¸­åäººæ°‘å…±å’Œå›½å•†æ ‡æ³•å®æ–½æ¡ä¾‹ ï¼ˆ2002å¹´8æœˆ3æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬358...
2018-10-27 23:43:20,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 13734:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬651å· ç°å…¬å¸ƒä¿®è®¢åçš„ã€Šä¸­åäººæ°‘å…±å’Œå›½å•†æ ‡æ³•å®æ–½æ¡...
2018-10-27 23:43:21,121 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:21,147 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:21,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:21,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:21,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6169047
2018-10-27 23:43:21,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:21,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:21,258 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/5/14/art_12_89702.html>
None
2018-10-27 23:43:21,260 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/8/25/art_12_89704.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:21,262 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/8/25/art_12_89705.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:21,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:21,407 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3857:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬653å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹å·²ç»2...
2018-10-27 23:43:21,531 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:21,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:21,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:21,563 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:21,581 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6194771
2018-10-27 23:43:21,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:21,683 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:21,683 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/8/25/art_12_89704.html>
None
2018-10-27 23:43:21,686 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/12/22/art_12_89707.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:21,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:21,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3259:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬654å· ã€Šä¼ä¸šä¿¡æ¯å…¬ç¤ºæš‚è¡Œæ¡ä¾‹ã€‹å·²ç»2014å¹´7æœˆ...
2018-10-27 23:43:21,869 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:21,894 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:21,895 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:21,895 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:21,911 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6217286
2018-10-27 23:43:21,995 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:21,995 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:21,995 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/8/25/art_12_89705.html>
None
2018-10-27 23:43:21,998 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/11/6/art_12_89706.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:22,001 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:22,042 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4092:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬656å· ç°å…¬å¸ƒã€Šä¸åŠ¨äº§ç™»è®°æš‚è¡Œæ¡ä¾‹ã€‹ï¼Œè‡ª2015å¹´...
2018-10-27 23:43:22,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:22,215 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:22,215 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:22,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:22,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6246646
2018-10-27 23:43:22,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:22,330 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:22,330 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/12/22/art_12_89707.html>
None
2018-10-27 23:43:22,332 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:22,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3874:  å›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®š ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬653å· ã€Šå›½åŠ¡é™¢...
2018-10-27 23:43:22,512 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:22,534 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:22,534 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:22,534 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:22,546 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6272483
2018-10-27 23:43:22,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:22,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:22,646 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/11/6/art_12_89706.html>
None
2018-10-27 23:43:22,649 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2015/4/1/art_12_89711.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:22,653 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2015/3/2/art_12_89710.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:22,663 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2015/2/27/art_12_89709.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:22,666 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2014/12/22/art_12_89708.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:22,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:22,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3363:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬660å· ã€Šå­˜æ¬¾ä¿é™©æ¡ä¾‹ã€‹å·²ç»2014å¹´10æœˆ29æ—¥...
2018-10-27 23:43:22,949 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:22,973 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:22,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:22,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:22,990 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6296021
2018-10-27 23:43:23,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:23,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:23,079 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2015/4/1/art_12_89711.html>
None
2018-10-27 23:43:23,083 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:23,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4596:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬659å· ã€Šåšç‰©é¦†æ¡ä¾‹ã€‹å·²ç»2015å¹´1æœˆ14æ—¥å›½åŠ¡...
2018-10-27 23:43:23,275 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:23,296 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:23,296 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:23,297 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:23,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6327914
2018-10-27 23:43:23,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:23,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:23,416 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2015/3/2/art_12_89710.html>
None
2018-10-27 23:43:23,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:23,491 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 25: ä¸­åäººæ°‘å…±å’Œå›½æ”¿åºœé‡‡è´­æ³•å®æ–½æ¡ä¾‹ ç¬¬ä¸€ç«  æ€» åˆ™
2018-10-27 23:43:23,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 10873:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬658å· ã€Šä¸­åäººæ°‘å…±å’Œå›½æ”¿åºœé‡‡è´­æ³•å®æ–½æ¡ä¾‹ã€‹å·²ç»2...
2018-10-27 23:43:23,681 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:23,721 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:23,721 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:23,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:23,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6401441
2018-10-27 23:43:23,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:23,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:23,891 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2015/2/27/art_12_89709.html>
None
2018-10-27 23:43:23,891 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:23,962 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 131: ä¸­åäººæ°‘å…±å’Œå›½å¤–èµ„é“¶è¡Œç®¡ç†æ¡ä¾‹ ï¼ˆ2006å¹´11æœˆ11æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬...
2018-10-27 23:43:23,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 9616:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬657å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­åäººæ°‘å…±å’Œå›½å¤–èµ„...
2018-10-27 23:43:24,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:24,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:24,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:24,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:24,196 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6467371
2018-10-27 23:43:24,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:24,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:24,279 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2014/12/22/art_12_89708.html>
None
2018-10-27 23:43:24,281 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2015/12/14/art_12_89714.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:24,283 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2015/6/19/art_12_89712.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:24,284 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2015/6/24/art_12_89713.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:24,347 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2015/12/14/art_12_89715.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:24,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:24,519 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3190:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬663å· ã€Šå±…ä½è¯æš‚è¡Œæ¡ä¾‹ã€‹å·²ç»2015å¹´10æœˆ21...
2018-10-27 23:43:24,708 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:24,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:24,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:24,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:24,776 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6489105
2018-10-27 23:43:24,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:24,909 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:24,909 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2015/12/14/art_12_89714.html>
None
2018-10-27 23:43:24,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:24,965 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 26: å›½åŠ¡é™¢å…³äºä¿®æ”¹ã€Šä¸­å›½å…¬æ°‘å¾€æ¥å°æ¹¾åœ°åŒºç®¡ç†åŠæ³•ã€‹çš„å†³å®š
2018-10-27 23:43:24,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 4612:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬661å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆä¸­å›½å…¬æ°‘å¾€æ¥å°æ¹¾åœ°...
2018-10-27 23:43:25,095 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:25,120 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:25,121 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:25,121 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:25,136 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6521581
2018-10-27 23:43:25,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:25,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:25,235 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2015/6/19/art_12_89712.html>
None
2018-10-27 23:43:25,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:25,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4739:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬662å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå»ºè®¾å·¥ç¨‹å‹˜å¯Ÿè®¾è®¡ç®¡...
2018-10-27 23:43:25,532 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:25,552 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:25,552 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:25,552 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:25,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6554007
2018-10-27 23:43:25,649 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:25,649 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:25,650 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2015/6/24/art_12_89713.html>
None
2018-10-27 23:43:25,650 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:25,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 6244:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬664å· ã€Šåœ°å›¾ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2015å¹´11æœˆ11æ—¥...
2018-10-27 23:43:25,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:25,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:25,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:25,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:25,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6596507
2018-10-27 23:43:26,053 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:26,053 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:26,053 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2015/12/14/art_12_89715.html>
None
2018-10-27 23:43:26,055 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2016/3/29/art_12_89717.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:26,057 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2016/6/3/art_12_89719.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:26,065 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2016/4/26/art_12_89718.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:26,067 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2016/3/2/art_12_89716.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:26,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:26,615 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 2987:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬667å· ã€Šå…¨å›½ç¤¾ä¼šä¿éšœåŸºé‡‘æ¡ä¾‹ã€‹å·²ç»2016å¹´2æœˆ...
2018-10-27 23:43:26,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:26,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:26,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:26,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:26,777 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6617133
2018-10-27 23:43:26,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:26,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:26,861 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2016/3/29/art_12_89717.html>
None
2018-10-27 23:43:26,864 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:27,280 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5326:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬669å· ã€Šå†œç”°æ°´åˆ©æ¡ä¾‹ã€‹å·²ç»2016å¹´4æœˆ27æ—¥å›½...
2018-10-27 23:43:27,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:27,524 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:27,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:27,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:27,538 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6653448
2018-10-27 23:43:27,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:27,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:27,625 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2016/6/3/art_12_89719.html>
None
2018-10-27 23:43:27,626 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:27,694 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 16054:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬668å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆç–«è‹—æµé€šå’Œé¢„é˜²æ¥ç§ç®¡ç†æ¡...
2018-10-27 23:43:27,811 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:27,833 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:27,833 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:27,833 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:27,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6758391
2018-10-27 23:43:27,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:27,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:27,935 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2016/4/26/art_12_89718.html>
None
2018-10-27 23:43:27,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:28,003 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 17296:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬666å· ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹å·²ç»2...
2018-10-27 23:43:28,125 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:28,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:28,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:28,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:28,159 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6872124
2018-10-27 23:43:28,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:28,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:28,237 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2016/3/2/art_12_89716.html>
None
2018-10-27 23:43:28,239 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2016/7/6/art_12_89720.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:28,241 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2016/12/14/art_12_89722.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:28,247 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/2/24/art_12_89723.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:28,249 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2016/11/28/art_12_89721.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:28,342 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:28,389 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 25: å›½åŠ¡é™¢å…³äºä¿®æ”¹ã€Šä¸­åäººæ°‘å…±å’Œå›½æµ·å…³ç¨½æŸ¥æ¡ä¾‹ã€‹çš„å†³å®š
2018-10-27 23:43:28,390 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 5599:  å›½åŠ¡é™¢å…³äºä¿®æ”¹ã€Šä¸­åäººæ°‘å…±å’Œå›½æµ·å…³ç¨½æŸ¥æ¡ä¾‹ã€‹çš„å†³å®š å›½åŠ¡é™¢å†³å®šå¯¹ã€Šä¸­åäººæ°‘å…±å’Œ...
2018-10-27 23:43:28,521 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:28,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:28,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:28,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:28,558 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6912770
2018-10-27 23:43:28,646 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:28,646 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:28,646 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2016/7/6/art_12_89720.html>
None
2018-10-27 23:43:28,650 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:28,685 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3069:  ç¬¬ä¸€æ¡ ä¸ºäº†è§„èŒƒæ”¿åºœå¯¹ä¼ä¸šæŠ•èµ„é¡¹ç›®çš„æ ¸å‡†å’Œå¤‡æ¡ˆè¡Œä¸ºï¼ŒåŠ å¿«è½¬å˜æ”¿åºœçš„æŠ•èµ„ç®¡ç†èŒèƒ½...
2018-10-27 23:43:28,809 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:28,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:28,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:28,832 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:28,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6935151
2018-10-27 23:43:28,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:28,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:28,924 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2016/12/14/art_12_89722.html>
None
2018-10-27 23:43:28,925 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:28,976 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 100:  æ®‹ç–¾äººæ•™è‚²æ¡ä¾‹ ï¼ˆ1994å¹´8æœˆ23æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬161å·å‘å¸ƒ æ ¹...
2018-10-27 23:43:28,978 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{02}>#zoom of length 7208:  ã€Šæ®‹ç–¾äººæ•™è‚²æ¡ä¾‹ã€‹å·²ç»2017å¹´1æœˆ11æ—¥å›½åŠ¡é™¢ç¬¬161æ¬¡å¸¸åŠ¡ä¼šè®®ä¿®è®¢é€šè¿‡ï¼Œç°...
2018-10-27 23:43:29,099 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:29,120 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:29,121 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:29,121 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:29,136 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6987716
2018-10-27 23:43:29,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:29,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:29,222 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/2/24/art_12_89723.html>
None
2018-10-27 23:43:29,223 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:29,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 9934:  ï¼ˆ1993å¹´9æœˆ11æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ã€ä¸­åäººæ°‘å…±å’Œå›½ä¸­å¤®å†›äº‹å§”å‘˜ä¼šä»¤ç¬¬1...
2018-10-27 23:43:29,410 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:29,433 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:29,433 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:29,433 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:29,444 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7057506
2018-10-27 23:43:29,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:29,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:29,529 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2016/11/28/art_12_89721.html>
None
2018-10-27 23:43:29,604 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/4/5/art_12_89726.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:29,616 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/5/3/art_12_89727.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:29,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:29,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 33: çš„å†³å®šã€‹ä¿®è®¢ 2017å¹´2æœˆ8æ—¥å›½åŠ¡é™¢ç¬¬164æ¬¡å¸¸åŠ¡ä¼šè®®ä¿®è®¢é€šè¿‡ï¼‰
2018-10-27 23:43:29,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{02} of length 29: æ ¹æ®2001å¹´11æœˆ29æ—¥ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå†œè¯ç®¡ç†æ¡ä¾‹ã€‰
2018-10-27 23:43:29,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{03} of length 28: ï¼ˆ1997å¹´5æœˆ8æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬216å·å‘å¸ƒ
2018-10-27 23:43:29,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{04}>#zoom of length 11428:  ã€Šå†œè¯ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2017å¹´2æœˆ8æ—¥å›½åŠ¡é™¢ç¬¬164æ¬¡å¸¸åŠ¡ä¼šè®®ä¿®è®¢é€šè¿‡ï¼Œç°å°†ä¿®...
2018-10-27 23:43:29,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:29,969 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:29,969 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:29,969 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:29,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7140898
2018-10-27 23:43:30,067 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:30,068 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:30,068 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/4/5/art_12_89726.html>
None
2018-10-27 23:43:30,070 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/2/28/art_12_89724.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:30,074 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/3/22/art_12_89725.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:30,075 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:30,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{01} of length 172: ï¼ˆ2006å¹´7æœˆ7æ—¥ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬471å·å…¬ å¸ƒ æ ¹æ®2013å¹´7æœˆ1...
2018-10-27 23:43:30,133 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing #zoom>div{02} of length 34:  å›½åŠ¡é™¢å…³äºä¿®æ”¹ã€Šå¤§ä¸­å‹æ°´åˆ©æ°´ç”µå·¥ç¨‹å»ºè®¾å¾åœ°è¡¥å¿å’Œç§»æ°‘å®‰ç½®æ¡ä¾‹ã€‹çš„å†³å®š
2018-10-27 23:43:30,135 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{03}>#zoom of length 9126:  ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå¤§ä¸­å‹æ°´åˆ©æ°´ç”µå·¥ç¨‹å»ºè®¾å¾åœ°è¡¥å¿å’Œç§»æ°‘å®‰ç½®æ¡ä¾‹ã€‰çš„å†³å®šã€‹...
2018-10-27 23:43:30,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:30,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:30,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:30,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:30,299 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7206495
2018-10-27 23:43:30,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:30,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:30,388 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/5/3/art_12_89727.html>
None
2018-10-27 23:43:30,391 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:30,433 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4753:  ã€Šæ®‹ç–¾é¢„é˜²å’Œæ®‹ç–¾äººåº·å¤æ¡ä¾‹ã€‹å·²ç»2017å¹´1æœˆ11æ—¥å›½åŠ¡é™¢ç¬¬161æ¬¡å¸¸åŠ¡ä¼šè®®é€š...
2018-10-27 23:43:30,565 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:30,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:30,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:30,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:30,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7241179
2018-10-27 23:43:30,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:30,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:30,689 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/2/28/art_12_89724.html>
None
2018-10-27 23:43:30,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:30,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 8514:  ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹å’ŒåºŸæ­¢éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹ï¼Œè‡ªå…¬å¸ƒä¹‹æ—¥èµ·æ–½è¡Œã€‚ æ€»ç† æ...
2018-10-27 23:43:30,865 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:30,887 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:30,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:30,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:30,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7294237
2018-10-27 23:43:30,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:30,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:30,988 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/3/22/art_12_89725.html>
None
2018-10-27 23:43:30,990 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/8/21/art_12_206018.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:30,992 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/6/20/art_12_205442.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:30,996 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/8/2/art_12_205857.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:31,001 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/5/22/art_12_89728.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:31,092 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:31,136 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5699:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬683å· ã€Šèèµ„æ‹…ä¿å…¬å¸ç›‘ç£ç®¡ç†æ¡ä¾‹ã€‹å·²ç»2017å¹´...
2018-10-27 23:43:31,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:31,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:31,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:31,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:31,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7329440
2018-10-27 23:43:31,398 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:31,398 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:31,398 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/8/21/art_12_206018.html>
None
2018-10-27 23:43:31,401 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:31,445 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 5893:  ä¸­åäººæ°‘å…±å’Œå›½ç»Ÿè®¡æ³•å®æ–½æ¡ä¾‹ ç¬¬ä¸€ç«  æ€» åˆ™ ç¬¬ä¸€æ¡ æ ¹æ®ã€Šä¸­åäººæ°‘å…±å’Œå›½ç»Ÿè®¡...
2018-10-27 23:43:31,590 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:31,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:31,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:31,617 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:31,632 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7365891
2018-10-27 23:43:31,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:31,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:31,744 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/6/20/art_12_205442.html>
None
2018-10-27 23:43:31,744 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:31,792 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 7370:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬682å·ã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆå»ºè®¾é¡¹ç›®ç¯å¢ƒä¿æŠ¤ç®¡ç†æ¡ä¾‹ã€‰çš„...
2018-10-27 23:43:31,933 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:31,958 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:31,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:31,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:31,976 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7411059
2018-10-27 23:43:32,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:32,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:32,079 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/8/2/art_12_205857.html>
None
2018-10-27 23:43:32,080 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:32,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 16667:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬680å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹ã€ˆåŒ»ç–—å™¨æ¢°ç›‘ç£ç®¡ç†æ¡...
2018-10-27 23:43:32,447 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:32,473 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:32,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:32,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:32,492 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7537850
2018-10-27 23:43:32,590 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:32,590 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:32,591 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/5/22/art_12_89728.html>
None
2018-10-27 23:43:32,592 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/8/23/art_12_206046.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:32,594 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/9/6/art_12_206160.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:32,597 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/10/24/art_12_206461.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:32,606 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.chinalaw.gov.cn/art/2017/9/7/art_12_206178.html via http://localhost:8050/execute> (referer: None)
2018-10-27 23:43:32,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:32,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 1577:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬684å·ç°å…¬å¸ƒã€Šæ— è¯æ— ç…§ç»è¥æŸ¥å¤„åŠæ³•ã€‹ï¼Œè‡ª2017å¹´1...
2018-10-27 23:43:32,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:32,903 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:32,903 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:32,904 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:32,920 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7547798
2018-10-27 23:43:33,020 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:33,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:33,021 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/8/23/art_12_206046.html>
None
2018-10-27 23:43:33,025 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:33,064 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 3956:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬685å· ã€Šå¿—æ„¿æœåŠ¡æ¡ä¾‹ã€‹å·²ç»2017å¹´6æœˆ7æ—¥å›½åŠ¡é™¢...
2018-10-27 23:43:33,211 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:33,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:33,241 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:33,241 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:33,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7572421
2018-10-27 23:43:33,356 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:33,357 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:33,357 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/9/6/art_12_206160.html>
None
2018-10-27 23:43:33,357 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:33,399 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 4008:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬687å· ç°å…¬å¸ƒã€Šå›½åŠ¡é™¢å…³äºä¿®æ”¹éƒ¨åˆ†è¡Œæ”¿æ³•è§„çš„å†³å®šã€‹ï¼Œ...
2018-10-27 23:43:33,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:33,596 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:33,596 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:33,597 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:33,611 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7597322
2018-10-27 23:43:33,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:33,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:33,736 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/10/24/art_12_206461.html>
None
2018-10-27 23:43:33,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:43:33,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#zoom of length 10059:  ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ç¬¬686å· ã€Šå®—æ•™äº‹åŠ¡æ¡ä¾‹ã€‹å·²ç»2017å¹´6æœˆ14æ—¥å›½åŠ¡...
2018-10-27 23:43:33,957 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:43:33,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:43:33,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:43:33,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:84894
2018-10-27 23:43:33,999 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7659080
2018-10-27 23:43:34,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:43:34,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:43:34,127 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.chinalaw.gov.cn/art/2017/9/7/art_12_206178.html>
None
2018-10-27 23:43:34,132 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (finished)
2018-10-27 23:43:34,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-27 23:43:34,297 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-27 23:43:34,298 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 288681,
 'downloader/request_count': 286,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 285,
 'downloader/response_bytes': 17981488,
 'downloader/response_count': 286,
 'downloader/response_status_count/200': 278,
 'downloader/response_status_count/504': 8,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 10, 27, 15, 43, 34, 184816),
 'item_scraped_count': 276,
 'log_count/DEBUG': 2015,
 'log_count/ERROR': 1,
 'log_count/INFO': 1402,
 'memusage/max': 128163840,
 'memusage/startup': 63729664,
 'request_depth_max': 1,
 'response_received_count': 278,
 'retry/count': 8,
 'retry/reason_count/504 Gateway Time-out': 8,
 'scheduler/dequeued': 563,
 'scheduler/dequeued/memory': 563,
 'scheduler/enqueued': 563,
 'scheduler/enqueued/memory': 563,
 'spider_exceptions/FileNotFoundError': 1,
 'splash/execute/request_count': 277,
 'splash/execute/response_count/200': 277,
 'splash/execute/response_count/504': 8,
 'start_time': datetime.datetime(2018, 10, 27, 15, 38, 55, 513754)}
2018-10-27 23:43:34,298 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (finished)
2018-10-27 23:44:58,446 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:yes
2018-10-27 23:44:58,591 - /Users/tian/zaluan/ScrapyA/app/views.py[line:409] - DEBUG: viewså…³é—­äº†
2018-10-27 23:45:01,720 - /Users/tian/zaluan/ScrapyA/app/views.py[line:411] - INFO: æ•°æ®ä¿å­˜ååˆ é™¤ç¼“å­˜
2018-10-27 23:45:01,720 - /Users/tian/zaluan/ScrapyA/app/views.py[line:412] - INFO: å±…ç„¶å…³é—­äº†
2018-10-27 23:45:01,723 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:01] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-27 23:45:01,730 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:01] "[37mGET /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:04,793 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:04] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:07,835 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:07] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:10,881 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:10] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:13,926 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:13] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:16,962 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:16] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:20,002 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:20] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:23,049 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:23] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:26,095 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:26] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:29,132 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:29] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:32,169 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:32] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:35,212 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:35] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:38,249 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:38] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:41,288 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:41] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:44,331 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:44] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:47,372 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:47] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:50,412 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:50] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:53,456 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:53] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:56,499 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:56] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:45:59,538 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:45:59] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:02,582 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:02] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:05,625 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:05] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:08,668 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:08] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:11,712 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:11] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:14,753 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:14] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:17,796 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:17] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:20,835 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:20] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:23,883 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:23] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:26,930 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:26] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:29,972 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:29] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:33,009 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:33] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:36,050 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:36] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:39,091 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:39] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:42,134 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:42] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:45,178 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:45] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:48,217 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:48] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:51,265 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:51] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:54,308 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:54] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:46:57,353 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:46:57] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:47:00,395 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:47:00] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:47:03,435 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:47:03] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:47:06,477 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:47:06] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:47:09,518 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:47:09] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:47:12,710 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:47:12] "[37mPOST /results%3Fid%3D84894 HTTP/1.1[0m" 200 -
2018-10-27 23:48:13,269 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-27 23:48:15,595 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:48:15] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-27 23:48:23,203 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:48:23] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-27 23:49:20,839 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:20] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-27 23:49:20,993 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:20] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:21,103 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-27 23:49:21,127 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-27 23:49:21,132 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-27 23:49:21,162 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-27 23:49:21,195 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-27 23:49:21,255 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-27 23:49:21,257 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-27 23:49:21,286 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-27 23:49:21,287 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-27 23:49:21,293 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:49:21,294 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-27 23:49:23,727 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/ via http://localhost:8050/execute> (referer: None)
2018-10-27 23:49:23,956 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180730_958950.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:23,966 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180817_962585.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:23,975 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180718_956825.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:23,984 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965491.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,006 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201809/t20180921_969161.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,008 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201809/t20180928_970202.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,017 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/czxw/201809/t20180911_967162.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,022 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965486.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,023 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181026_974422.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,034 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181017_972566.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,051 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/ggtz/201810/t20181022_973300.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,053 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181011_971778.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,060 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:49:24,101 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:49:24,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:49:24,116 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing .G_left.left.m20>.content of length 425:  è´¢æ”¿éƒ¨ç§¯ææ¨è¿›å…¬è½¦æ”¹é©è´¢æ”¿é…å¥—åˆ¶åº¦å»ºè®¾ ä¸ºæ·±å…¥è´¯å½»è½å®å…šä¸­å¤®ã€å›½åŠ¡é™¢å…³äºç§‘å­¦åˆ¶...
2018-10-27 23:49:24,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing .GcW>.G_left.left.m20 of length 425:  è´¢æ”¿éƒ¨ç§¯ææ¨è¿›å…¬è½¦æ”¹é©è´¢æ”¿é…å¥—åˆ¶åº¦å»ºè®¾ ä¸ºæ·±å…¥è´¯å½»è½å®å…šä¸­å¤®ã€å›½åŠ¡é™¢å…³äºç§‘å­¦åˆ¶...
2018-10-27 23:49:24,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing body>.GcW of length 425:  è´¢æ”¿éƒ¨ç§¯ææ¨è¿›å…¬è½¦æ”¹é©è´¢æ”¿é…å¥—åˆ¶åº¦å»ºè®¾ ä¸ºæ·±å…¥è´¯å½»è½å®å…šä¸­å¤®ã€å›½åŠ¡é™¢å…³äºç§‘å­¦åˆ¶...
2018-10-27 23:49:24,122 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:24,123 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:24,123 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:24,123 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:24,124 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :3926
2018-10-27 23:49:24,124 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:24,125 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:24,125 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180730_958950.htm>
None
2018-10-27 23:49:24,126 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcjd/201808/t20180817_962607.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
2018-10-27 23:49:24,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,150 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:24] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:24,176 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1302:  ç¨³æŠ•èµ„è¡¥çŸ­æ¿ åœ°æ–¹æ”¿åºœä¸“é¡¹å€ºåˆ¸é«˜æ•ˆå‘è¡Œ 8æœˆ14æ—¥ï¼Œè´¢æ”¿éƒ¨å‘å¸ƒã€Šå…³äºåšå¥½åœ°æ–¹æ”¿...
2018-10-27 23:49:24,181 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:24,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:24,185 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:24,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:24,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :12085
2018-10-27 23:49:24,188 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:24,188 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:24,189 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180817_962585.htm>
None
2018-10-27 23:49:24,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 702:  å…³äºè¿›ä¸€æ­¥æ‰©å¤§å°å‹å¾®åˆ©ä¼ä¸šæ‰€å¾—ç¨ä¼˜æƒ æ”¿ç­–èŒƒå›´çš„é€šçŸ¥ è´¢ç¨ã€”2018ã€•77å· å„...
2018-10-27 23:49:24,238 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:24,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:24,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:24,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:24,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :16522
2018-10-27 23:49:24,241 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:24,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:24,242 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180718_956825.htm>
None
2018-10-27 23:49:24,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,300 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 8536:  æ•™è‚²éƒ¨ è´¢æ”¿éƒ¨ å›½å®¶å‘å±•æ”¹é©å§”å°å‘ã€Šå…³äºé«˜ç­‰å­¦æ ¡åŠ å¿«â€œåŒä¸€æµâ€å»ºè®¾çš„æŒ‡å¯¼æ„è§ã€‹...
2018-10-27 23:49:24,304 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:24,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:24,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:24,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:24,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :68634
2018-10-27 23:49:24,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:24,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:24,312 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965491.htm>
None
2018-10-27 23:49:24,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 5363:  ä¸­å…±ä¸­å¤®åŠå…¬å… å›½åŠ¡é™¢åŠå…¬å…å°å‘ã€Šå…³äºåŠ å¼ºå›½æœ‰ä¼ä¸šèµ„äº§è´Ÿå€ºçº¦æŸçš„æŒ‡å¯¼æ„è§ã€‹ è¿‘...
2018-10-27 23:49:24,356 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:24,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:24,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:24,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:24,359 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :101434
2018-10-27 23:49:24,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:24,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:24,361 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201809/t20180921_969161.htm>
None
2018-10-27 23:49:24,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,404 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 4963:  ï¼ˆå—æƒå‘å¸ƒï¼‰ä¸­å…±ä¸­å¤® å›½åŠ¡é™¢å…³äºå…¨é¢å®æ–½é¢„ç®—ç»©æ•ˆç®¡ç†çš„æ„è§ æ–°åç¤¾åŒ—äº¬9æœˆ25...
2018-10-27 23:49:24,411 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:24,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:24,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:24,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:24,414 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :132286
2018-10-27 23:49:24,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:24,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:24,419 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201809/t20180928_970202.htm>
None
2018-10-27 23:49:24,420 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,481 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing .content>.Custom_UnionStyle of length 4739:  ç²¤åºœã€”2018ã€•79å· å„åœ°çº§ä»¥ä¸Šå¸‚äººæ°‘æ”¿åºœï¼Œå„å¿ï¼ˆå¸‚ã€åŒºï¼‰äººæ°‘æ”¿åºœï¼Œçœæ”¿åºœå„...
2018-10-27 23:49:24,483 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 4801:  å¹¿ä¸œçœäººæ°‘æ”¿åºœå…³äºå°å‘å¹¿ä¸œçœé™ä½åˆ¶é€ ä¸šä¼ä¸šæˆæœ¬æ”¯æŒå®ä½“ç»æµå‘å±•è‹¥å¹²æ”¿ç­–æªæ–½ï¼ˆä¿®...
2018-10-27 23:49:24,491 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:49:24,571 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/czxw/201809/P020180911544338596055.doc HTTP/1.1" 200 63488
2018-10-27 23:49:24,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/czxw/201809/t20180911_967162.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:49:24_P020180911544338596055.doc'
2018-10-27 23:49:24,724 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,759 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 697:  è´¢æ”¿éƒ¨å†³å®šå®è¡Œåœ°æ–¹æ”¿åºœå€ºåˆ¸å…¬å¼€æ‰¿é”€åˆ¶åº¦ ä¸ºè¿›ä¸€æ­¥å®Œå–„åœ°æ–¹æ”¿åºœå€ºåˆ¸å‘è¡Œæ–¹å¼ï¼Œæé«˜...
2018-10-27 23:49:24,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:24,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:24,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:24,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:24,768 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :136908
2018-10-27 23:49:24,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:24,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:24,771 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965486.htm>
None
2018-10-27 23:49:24,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1839:  å››éƒ¨é—¨å°å‘é€šçŸ¥è¦æ±‚è¿›ä¸€æ­¥åšå¥½åˆ›ä¸šæ‹…ä¿è´·æ¬¾è´´æ¯æ”¿ç­–ç›‘æµ‹åˆ†æå·¥ä½œ å…³äºè¿›ä¸€æ­¥åšå¥½åˆ›...
2018-10-27 23:49:24,811 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:24,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:24,813 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:24,813 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:24,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :149330
2018-10-27 23:49:24,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:24,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:24,816 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181026_974422.htm>
None
2018-10-27 23:49:24,826 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,859 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 584:  å»äº§èƒ½å’Œè°ƒç»“æ„æˆ¿äº§ç¨ã€åŸé•‡åœŸåœ°ä½¿ç”¨ç¨æ”¿ç­–æ˜ç¡® å…³äºå»äº§èƒ½å’Œè°ƒç»“æ„æˆ¿äº§ç¨ åŸé•‡åœŸ...
2018-10-27 23:49:24,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:24,870 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:24,870 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:24,870 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:24,871 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :153291
2018-10-27 23:49:24,874 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:24,874 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:24,874 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181017_972566.htm>
None
2018-10-27 23:49:24,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:24,907 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 71:  è´¢æ”¿éƒ¨å…³äºå°å‘ã€Šå·¥ä¸šä¼ä¸šç»“æ„è°ƒæ•´ä¸“é¡¹å¥–è¡¥èµ„é‡‘ç®¡ç†åŠæ³•ã€‹çš„é€šçŸ¥ é™„ä»¶ä¸‹è½½ï¼š è´¢æ”¿...
2018-10-27 23:49:24,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 71:  è´¢æ”¿éƒ¨å…³äºå°å‘ã€Šå·¥ä¸šä¼ä¸šç»“æ„è°ƒæ•´ä¸“é¡¹å¥–è¡¥èµ„é‡‘ç®¡ç†åŠæ³•ã€‹çš„é€šçŸ¥ é™„ä»¶ä¸‹è½½ï¼š è´¢æ”¿...
2018-10-27 23:49:24,920 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:49:24,986 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/ggtz/201810/P020181022364957361682.pdf HTTP/1.1" 200 616767
2018-10-27 23:49:25,419 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/ggtz/201810/t20181022_973300.htm> (referer: http://www.gdczt.gov.cn/zwgk/zcfg/)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:49:24_P020181022364957361682.pdf'
2018-10-27 23:49:25,420 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:25,462 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1006:  è´¢æ”¿éƒ¨å‡ºå°è´¢æ”¿ç³»ç»Ÿè´¯å½»è½å®å®æ–½ä¹¡æ‘æŒ¯å…´æˆ˜ç•¥çš„æ„è§ 9æœˆ27æ—¥ï¼Œè´¢æ”¿éƒ¨å°å‘ã€Šè´¢æ”¿...
2018-10-27 23:49:25,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:25,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:25,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:25,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:25,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :159682
2018-10-27 23:49:25,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:25,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:25,475 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181011_971778.htm>
None
2018-10-27 23:49:25,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:49:25,510 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1999:  ä¸­å¤®è´¢æ”¿å‡ºå°ä¿è´¹è¡¥è´´æ”¿ç­–æ”¯æŒåˆ¶ç§äº§ä¸šå‘å±• ä¸ºè´¯å½»è½å®ä¹ è¿‘å¹³æ€»ä¹¦è®°è§†å¯Ÿæµ·å—æœŸé—´å…³...
2018-10-27 23:49:25,519 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:49:25,521 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:49:25,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:49:25,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:49:25,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :171878
2018-10-27 23:49:25,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:49:25,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:49:25,527 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcjd/201808/t20180817_962607.htm>
None
2018-10-27 23:49:27,247 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:27] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:30,330 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:30] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:33,650 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:33] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:36,747 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:39,836 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:42,923 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:46,012 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:46] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:49,764 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:49] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:53,866 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://www.gdczt.gov.cn/zwgk/zcfg/ via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-27 23:49:53,962 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:53] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:49:57,499 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:49:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:00,991 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:00] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:04,225 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:04] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:07,807 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:07] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:11,597 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:11] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:14,693 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:14] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:17,789 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:17] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:20,886 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:20] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:21,294 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 14 pages (at 14 pages/min), scraped 11 items (at 11 items/min)
2018-10-27 23:50:21,684 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/ via http://localhost:8050/execute> (referer: None)
2018-10-27 23:50:21,793 - /anaconda3/lib/python3.6/site-packages/scrapy/dupefilters.py[line:70] - DEBUG: Filtered duplicate request: <GET http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180817_962585.htm> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-27 23:50:21,799 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (finished)
2018-10-27 23:50:21,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-27 23:50:21,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-27 23:50:21,806 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8977,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 13,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 375727,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 15,
 'downloader/response_status_count/504': 1,
 'dupefilter/filtered': 14,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 10, 27, 15, 50, 21, 801340),
 'item_scraped_count': 11,
 'log_count/DEBUG': 88,
 'log_count/ERROR': 2,
 'log_count/INFO': 66,
 'memusage/max': 80097280,
 'memusage/startup': 64184320,
 'request_depth_max': 2,
 'response_received_count': 15,
 'retry/count': 1,
 'retry/reason_count/504 Gateway Time-out': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'spider_exceptions/FileNotFoundError': 2,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'splash/execute/response_count/504': 1,
 'start_time': datetime.datetime(2018, 10, 27, 15, 49, 21, 293428)}
2018-10-27 23:50:21,806 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (finished)
2018-10-27 23:50:23,978 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:23] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:26,318 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:nosw
2018-10-27 23:50:26,318 - /Users/tian/zaluan/ScrapyA/app/views.py[line:374] - INFO: nosw
2018-10-27 23:50:27,092 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:27] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:28,324 - /Users/tian/zaluan/ScrapyA/app/views.py[line:391] - INFO: userinfo in crawling:{}
2018-10-27 23:50:28,343 - /Users/tian/zaluan/ScrapyA/app/views.py[line:393] - INFO: before
2018-10-27 23:50:28,344 - /Users/tian/zaluan/ScrapyA/app/views.py[line:394] - INFO: after:open
2018-10-27 23:50:30,193 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:30] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:33,277 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:33] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:33,349 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:33] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-27 23:50:33,537 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-27 23:50:33,553 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-27 23:50:33,561 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-27 23:50:33,595 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-27 23:50:33,627 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-27 23:50:34,672 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": []}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": []}}}
2018-10-27 23:50:34,673 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): 127.0.0.1:62667
2018-10-27 23:50:36,177 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session HTTP/1.1" 200 903
2018-10-27 23:50:36,180 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:36,182 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:80] - INFO: é¡µç æ‰€åœ¨çš„xpath://*[@id="hlw"]/div[2]/div/div/div
2018-10-27 23:50:36,218 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-27 23:50:36,221 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-27 23:50:36,250 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-27 23:50:36,250 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-27 23:50:36,258 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:50:36,259 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-27 23:50:36,355 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:36,384 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/> (referer: None)
2018-10-27 23:50:36,488 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/url {"url": "http://www.gdczt.gov.cn/zwgk/zcfg/", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:37,387 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/url HTTP/1.1" 200 72
2018-10-27 23:50:37,388 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:37,388 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/source {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:37,395 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/source HTTP/1.1" 200 22752
2018-10-27 23:50:37,396 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:37,399 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['./201810/t20181026_974422.htm', '../ggtz/201810/t20181022_973300.htm', './201810/t20181017_972566.htm', './201810/t20181011_971778.htm', './201809/t20180928_970202.htm', './201809/t20180921_969161.htm', '../czxw/201809/t20180911_967162.htm', './201808/t20180831_965491.htm', './201808/t20180831_965486.htm', './201808/t20180817_962585.htm', '../zcjd/201808/t20180817_962607.htm', './201807/t20180730_958950.htm', './201807/t20180718_956825.htm']
2018-10-27 23:50:39,440 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:40,408 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:40,425 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:40,425 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:40,927 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:40,938 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:40,939 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:41,440 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:41,451 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:41,451 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:41,953 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:41,960 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:41,960 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:42,462 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:42,473 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:42,473 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:42,526 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:42,975 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:42,986 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:42,986 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:43,488 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:43,498 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:43,499 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:44,000 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:44,009 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:44,009 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:44,510 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:44,518 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:44,518 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:45,020 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:45,027 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:45,027 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:45,528 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:45,535 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:45,536 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:45,608 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:46,036 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:46,043 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:46,044 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:46,545 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:46,555 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:46,556 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:47,057 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:47,068 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:47,068 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:47,570 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:47,581 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:47,581 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:48,083 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:48,094 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:48,095 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:48,596 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:48,606 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:48,607 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:48,707 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:48] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:49,109 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:49,119 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:49,120 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:49,621 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:49,629 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:49,630 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:50,132 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:50,141 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:50,142 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:50,643 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:50,653 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:50,654 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:51,154 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:51,166 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:51,166 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:51,668 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:51,678 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:51,679 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:51,808 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:52,180 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:52,191 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:52,191 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:52,692 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:52,702 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:52,703 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:53,205 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:53,215 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:53,215 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:53,717 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:53,727 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:53,728 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:54,229 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:54,238 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:54,238 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:54,740 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:54,747 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:54,747 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:54,894 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:55,248 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:55,255 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:55,256 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:55,756 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:55,763 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:55,764 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:56,265 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:56,272 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:56,273 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:56,774 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:56,784 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:56,785 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:57,286 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:57,297 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:57,298 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:57,799 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:57,809 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:57,810 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:57,978 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:50:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:50:58,311 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:58,321 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:58,322 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:58,823 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:58,833 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:58,833 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:59,335 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:59,345 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:59,345 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:50:59,847 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:50:59,857 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:50:59,858 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:00,359 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:00,375 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 391
2018-10-27 23:51:00,375 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:00,877 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:146] - DEBUG: the error is Message: 

2018-10-27 23:51:00,878 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:00,892 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:00,893 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:01,059 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:01] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:01,394 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:01,404 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:01,404 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:01,906 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:01,916 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:01,917 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:02,418 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:02,428 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:02,428 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:02,929 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:02,939 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:02,940 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:03,441 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:03,451 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:03,452 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:03,953 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:03,964 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:03,965 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:04,144 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:04] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:04,466 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:04,475 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:04,476 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:04,978 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:04,985 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:04,985 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:05,486 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:05,493 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:05,494 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:05,995 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:06,002 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:06,002 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:06,502 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:06,509 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:06,509 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:07,010 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:07,017 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:07,018 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:07,233 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:07] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:07,519 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:07,529 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:07,530 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:08,032 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:08,041 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:08,042 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:08,543 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:08,553 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:08,553 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:09,054 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:09,064 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:09,064 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:09,566 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:09,576 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:09,576 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:10,078 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:10,086 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:10,087 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:10,334 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:10] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:10,588 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:10,598 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:10,599 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:11,100 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:11,110 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:11,110 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:11,612 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:11,624 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:11,625 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:12,127 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:12,136 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:12,137 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:12,637 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:12,647 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:12,647 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:13,149 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:13,158 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:13,159 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:13,428 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:13] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:13,661 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:13,671 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:13,671 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:14,173 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:14,183 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:14,183 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:14,685 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:14,695 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:14,695 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:15,196 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:15,206 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:15,206 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:15,707 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:15,713 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:15,714 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:16,214 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:16,221 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:16,221 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:16,515 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:16] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:16,723 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:16,729 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:16,730 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:17,231 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:17,239 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:17,239 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:17,740 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:17,746 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:17,747 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:18,248 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:18,258 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:18,258 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:18,759 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:18,769 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:18,769 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:19,271 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:19,280 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:19,281 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:19,596 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:19] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:19,782 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:19,792 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:19,793 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:20,294 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:20,305 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:20,306 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:20,807 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div//input[@type='text']", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:20,814 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 379
2018-10-27 23:51:20,815 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:21,316 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:157] - DEBUG: again the error is Message: 

2018-10-27 23:51:21,316 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:158] - DEBUG: æ²¡æ‰¾åˆ°æ–¹æ¡†
2018-10-27 23:51:21,317 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[1]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:21,330 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 102
2018-10-27 23:51:21,331 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:21,331 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.9647250325608812-1/displayed {"id": "0.9647250325608812-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:21,343 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.9647250325608812-1/displayed HTTP/1.1" 200 72
2018-10-27 23:51:21,343 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:21,344 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.9647250325608812-1/enabled {"id": "0.9647250325608812-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:21,351 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.9647250325608812-1/enabled HTTP/1.1" 200 72
2018-10-27 23:51:21,352 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:21,352 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.9647250325608812-1/click {"id": "0.9647250325608812-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:21,511 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element/0.9647250325608812-1/click HTTP/1.1" 200 72
2018-10-27 23:51:21,512 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:22,680 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:22] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:23,514 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/source {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:23,522 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/source HTTP/1.1" 200 32388
2018-10-27 23:51:23,523 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:23,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['./201807/t20180718_956824.htm', './201808/t20180831_965465.htm', './201807/t20180705_954534.htm', './201806/t20180619_947358.htm', './201806/t20180619_947356.htm', './201806/t20180612_946465.htm', './201806/t20180601_944966.htm', './201806/t20180601_944967.htm', './201805/t20180522_942788.htm', './201805/t20180522_942769.htm', './201805/t20180522_942729.htm', './201805/t20180515_941346.htm', './201805/t20180515_941293.htm']
2018-10-27 23:51:25,783 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:25] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:26,551 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[3]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:26,562 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 102
2018-10-27 23:51:26,563 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:26,563 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.9079063029674876-1/displayed {"id": "0.9079063029674876-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:26,573 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.9079063029674876-1/displayed HTTP/1.1" 200 72
2018-10-27 23:51:26,574 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:26,574 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.9079063029674876-1/enabled {"id": "0.9079063029674876-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:26,581 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.9079063029674876-1/enabled HTTP/1.1" 200 72
2018-10-27 23:51:26,582 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:26,582 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.9079063029674876-1/click {"id": "0.9079063029674876-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:26,721 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element/0.9079063029674876-1/click HTTP/1.1" 200 72
2018-10-27 23:51:26,722 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:28,723 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/source {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:28,732 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/source HTTP/1.1" 200 32915
2018-10-27 23:51:28,734 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:28,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['./201803/t20180309_929440.htm', './201802/P020180224614200045529.pdf', './201802/P020180223425589013889.pdf', './201802/t20180213_926523.htm', './201802/P020180205601525385946.pdf', './201801/P020180118679581018441.pdf', './201801/t20180115_920030.htm', './201801/t20180109_918743.htm', './201711/P020171127641634064752.pdf', './201711/P020171114642478908793.pdf', './201711/P020171114642262451374.pdf', './201710/t20171030_897432.htm', './201710/t20171019_895400.htm']
2018-10-27 23:51:28,874 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:28] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:31,749 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[4]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:31,764 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 103
2018-10-27 23:51:31,764 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:31,765 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.09563070973644883-1/displayed {"id": "0.09563070973644883-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:31,776 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.09563070973644883-1/displayed HTTP/1.1" 200 72
2018-10-27 23:51:31,777 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:31,777 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.09563070973644883-1/enabled {"id": "0.09563070973644883-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:31,785 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.09563070973644883-1/enabled HTTP/1.1" 200 72
2018-10-27 23:51:31,785 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:31,786 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.09563070973644883-1/click {"id": "0.09563070973644883-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:31,933 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element/0.09563070973644883-1/click HTTP/1.1" 200 72
2018-10-27 23:51:31,935 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:31,986 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:31] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:33,936 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/source {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:33,947 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/source HTTP/1.1" 200 33026
2018-10-27 23:51:33,948 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:33,951 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['./201709/t20170930_893074.htm', './201709/P020170929677970825942.pdf', './201709/P020170904694508419350.pdf', './201708/P020170803373431458125.pdf', './201707/P020170718647484878881.pdf', './201707/P020170718646950433670.pdf', './201707/P020170712585976584017.pdf', './201707/P020170703679291800352.pdf', './201707/P020170703679118075377.pdf', './201706/P020170628648468426136.pdf', './201706/P020170627639698344257.pdf', './201706/P020170627639474849446.pdf', './201706/P020170620647637524553.pdf']
2018-10-27 23:51:35,077 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:35] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:36,959 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[5]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:36,970 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 102
2018-10-27 23:51:36,971 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:36,971 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.6735504373030601-1/displayed {"id": "0.6735504373030601-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:36,981 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.6735504373030601-1/displayed HTTP/1.1" 200 72
2018-10-27 23:51:36,982 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:36,982 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.6735504373030601-1/enabled {"id": "0.6735504373030601-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:36,989 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.6735504373030601-1/enabled HTTP/1.1" 200 72
2018-10-27 23:51:36,990 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:36,990 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.6735504373030601-1/click {"id": "0.6735504373030601-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:37,136 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element/0.6735504373030601-1/click HTTP/1.1" 200 72
2018-10-27 23:51:37,136 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:38,158 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:38] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:39,138 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/source {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:39,143 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/source HTTP/1.1" 200 33321
2018-10-27 23:51:39,144 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:39,147 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['./201706/t20170615_846624.htm', './201705/P020170524669031042242.pdf', './201705/P020170524668641165961.pdf', './201705/P020170524668314261592.pdf', './201705/P020170524667901329055.pdf', './201705/P020170524667264540231.pdf', './201705/P020170524666762262464.pdf', './201704/P020170417640753117881.pdf', './201704/P020170410587543449441.pdf', './201703/P020170327581681945068.pdf', './201703/P020170306594252129672.pdf', './201702/P020170216612639683465.pdf', './201702/P020170206637943497513.pdf']
2018-10-27 23:51:39,150 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181026_974422.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:39,152 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:51:41,243 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:41] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:42,158 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[6]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:42,173 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 104
2018-10-27 23:51:42,173 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:42,173 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.013416027901284933-1/displayed {"id": "0.013416027901284933-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:42,185 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.013416027901284933-1/displayed HTTP/1.1" 200 72
2018-10-27 23:51:42,185 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:42,186 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.013416027901284933-1/enabled {"id": "0.013416027901284933-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:42,193 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.013416027901284933-1/enabled HTTP/1.1" 200 72
2018-10-27 23:51:42,194 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:42,194 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.013416027901284933-1/click {"id": "0.013416027901284933-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:42,333 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element/0.013416027901284933-1/click HTTP/1.1" 200 72
2018-10-27 23:51:42,334 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:44,333 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:44] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:44,334 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/source {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:44,342 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/source HTTP/1.1" 200 33281
2018-10-27 23:51:44,343 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:44,347 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['./201702/P020170216611417204433.pdf', './201701/P020170111524066718354.pdf', './201701/P020170106612985047352.pdf', './201701/P020170106611272064877.pdf', './201612/P020161230604621132401.pdf', './201612/P020161221619198728147.pdf', './201612/P020161220566672884739.pdf', './201702/P020170216609506150623.pdf', './201612/P020161216631009333461.pdf', './201612/P020161216629497630774.pdf', './201701/P020170124633498458626.pdf', './201702/P020170216600737261894.pdf', './201702/P020170216598691051938.pdf']
2018-10-27 23:51:44,351 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcjd/201808/t20180817_962607.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:44,353 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180730_958950.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:44,356 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180817_962585.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:44,360 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180718_956825.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:44,363 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965486.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:44,367 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180718_956824.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:47,381 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[7]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:47,396 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 102
2018-10-27 23:51:47,399 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:47,401 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.7076092512414924-1/displayed {"id": "0.7076092512414924-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:47,422 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.7076092512414924-1/displayed HTTP/1.1" 200 72
2018-10-27 23:51:47,423 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:47,424 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.7076092512414924-1/enabled {"id": "0.7076092512414924-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:47,428 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:47] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:47,433 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.7076092512414924-1/enabled HTTP/1.1" 200 72
2018-10-27 23:51:47,434 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:47,436 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.7076092512414924-1/click {"id": "0.7076092512414924-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:47,618 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element/0.7076092512414924-1/click HTTP/1.1" 200 72
2018-10-27 23:51:47,620 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:49,620 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/source {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:49,625 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/source HTTP/1.1" 200 32926
2018-10-27 23:51:49,626 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:49,629 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['./201702/P020170216607732677258.pdf', './201611/t20161123_806392.htm', './201702/P020170216597044160867.pdf', './201611/P020161102596335539113.pdf', './201610/P020161025612918506487.pdf', './201702/P020170216592045991806.pdf', './201610/P020170216547777046646.pdf', './201610/P020170216547169831506.pdf', './201610/P020170216543386227080.pdf', './201610/P020161018637080239723.pdf', './201610/P020161018636061901239.pdf', './201702/P020170216589607037301.pdf', './201609/t20160906_791925.htm']
2018-10-27 23:51:49,633 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965491.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:49,635 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/czxw/201809/t20180911_967162.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:49,638 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:51:49,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1839:  å››éƒ¨é—¨å°å‘é€šçŸ¥è¦æ±‚è¿›ä¸€æ­¥åšå¥½åˆ›ä¸šæ‹…ä¿è´·æ¬¾è´´æ¯æ”¿ç­–ç›‘æµ‹åˆ†æå·¥ä½œ å…³äºè¿›ä¸€æ­¥åšå¥½åˆ›...
2018-10-27 23:51:49,692 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:51:49,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:51:49,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:51:49,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:51:49,694 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :13109
2018-10-27 23:51:49,694 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:51:49,695 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:51:49,695 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181026_974422.htm>
None
2018-10-27 23:51:50,542 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:50] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:52,705 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[8]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:52,720 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 102
2018-10-27 23:51:52,720 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:52,721 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.9020539095864444-1/displayed {"id": "0.9020539095864444-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:52,732 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.9020539095864444-1/displayed HTTP/1.1" 200 72
2018-10-27 23:51:52,733 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:52,733 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.9020539095864444-1/enabled {"id": "0.9020539095864444-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:52,741 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/element/0.9020539095864444-1/enabled HTTP/1.1" 200 72
2018-10-27 23:51:52,741 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:52,742 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element/0.9020539095864444-1/click {"id": "0.9020539095864444-1", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:52,883 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element/0.9020539095864444-1/click HTTP/1.1" 200 72
2018-10-27 23:51:52,883 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:54,113 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:54,885 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/source {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:54,894 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/source HTTP/1.1" 200 31901
2018-10-27 23:51:54,895 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:54,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['./201608/t20160808_786399.htm', './201607/t20160725_783714.htm', './201609/t20160905_791787.htm', './201606/t20160627_777747.htm', './201606/t20160627_777746.htm', './201606/t20160627_777745.htm', './201606/t20160627_777744.htm', './201606/t20160627_777743.htm', './201606/t20160627_777742.htm']
2018-10-27 23:51:54,902 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201809/t20180921_969161.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:54,904 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201809/t20180928_970202.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:54,906 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181011_971778.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:54,908 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181017_972566.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:54,910 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/ggtz/201810/t20181022_973300.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:54,912 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201803/t20180309_929440.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:51:54,920 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:51:55,046 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1999:  ä¸­å¤®è´¢æ”¿å‡ºå°ä¿è´¹è¡¥è´´æ”¿ç­–æ”¯æŒåˆ¶ç§äº§ä¸šå‘å±• ä¸ºè´¯å½»è½å®ä¹ è¿‘å¹³æ€»ä¹¦è®°è§†å¯Ÿæµ·å—æœŸé—´å…³...
2018-10-27 23:51:55,050 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:51:55,050 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:51:55,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:51:55,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:51:55,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :25305
2018-10-27 23:51:55,052 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:51:55,053 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:51:55,053 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcjd/201808/t20180817_962607.htm>
None
2018-10-27 23:51:55,053 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:51:55,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:51:55,135 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:51:55,152 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:51:55,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing .G_left.left.m20>.content of length 425:  è´¢æ”¿éƒ¨ç§¯ææ¨è¿›å…¬è½¦æ”¹é©è´¢æ”¿é…å¥—åˆ¶åº¦å»ºè®¾ ä¸ºæ·±å…¥è´¯å½»è½å®å…šä¸­å¤®ã€å›½åŠ¡é™¢å…³äºç§‘å­¦åˆ¶...
2018-10-27 23:51:55,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing .GcW>.G_left.left.m20 of length 425:  è´¢æ”¿éƒ¨ç§¯ææ¨è¿›å…¬è½¦æ”¹é©è´¢æ”¿é…å¥—åˆ¶åº¦å»ºè®¾ ä¸ºæ·±å…¥è´¯å½»è½å®å…šä¸­å¤®ã€å›½åŠ¡é™¢å…³äºç§‘å­¦åˆ¶...
2018-10-27 23:51:55,162 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing body>.GcW of length 425:  è´¢æ”¿éƒ¨ç§¯ææ¨è¿›å…¬è½¦æ”¹é©è´¢æ”¿é…å¥—åˆ¶åº¦å»ºè®¾ ä¸ºæ·±å…¥è´¯å½»è½å®å…šä¸­å¤®ã€å›½åŠ¡é™¢å…³äºç§‘å­¦åˆ¶...
2018-10-27 23:51:55,167 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:51:55,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:51:55,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:51:55,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:51:55,170 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :28546
2018-10-27 23:51:55,171 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:51:55,171 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:51:55,171 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180730_958950.htm>
None
2018-10-27 23:51:55,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:51:55,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1302:  ç¨³æŠ•èµ„è¡¥çŸ­æ¿ åœ°æ–¹æ”¿åºœä¸“é¡¹å€ºåˆ¸é«˜æ•ˆå‘è¡Œ 8æœˆ14æ—¥ï¼Œè´¢æ”¿éƒ¨å‘å¸ƒã€Šå…³äºåšå¥½åœ°æ–¹æ”¿...
2018-10-27 23:51:55,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:51:55,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:51:55,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:51:55,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:51:55,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :36705
2018-10-27 23:51:55,238 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:51:55,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:51:55,239 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180817_962585.htm>
None
2018-10-27 23:51:55,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:51:55,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 702:  å…³äºè¿›ä¸€æ­¥æ‰©å¤§å°å‹å¾®åˆ©ä¼ä¸šæ‰€å¾—ç¨ä¼˜æƒ æ”¿ç­–èŒƒå›´çš„é€šçŸ¥ è´¢ç¨ã€”2018ã€•77å· å„...
2018-10-27 23:51:55,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:51:55,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:51:55,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:51:55,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:51:55,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :41142
2018-10-27 23:51:55,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:51:55,313 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:51:55,313 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180718_956825.htm>
None
2018-10-27 23:51:55,313 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:51:55,408 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 697:  è´¢æ”¿éƒ¨å†³å®šå®è¡Œåœ°æ–¹æ”¿åºœå€ºåˆ¸å…¬å¼€æ‰¿é”€åˆ¶åº¦ ä¸ºè¿›ä¸€æ­¥å®Œå–„åœ°æ–¹æ”¿åºœå€ºåˆ¸å‘è¡Œæ–¹å¼ï¼Œæé«˜...
2018-10-27 23:51:55,414 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:51:55,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:51:55,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:51:55,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:51:55,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :45764
2018-10-27 23:51:55,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:51:55,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:51:55,419 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965486.htm>
None
2018-10-27 23:51:55,420 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:51:55,493 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 461:  å…³äºå»¶é•¿é«˜æ–°æŠ€æœ¯ä¼ä¸šå’Œç§‘æŠ€å‹ä¸­å°ä¼ä¸šäºæŸç»“è½¬å¹´é™çš„é€šçŸ¥ è´¢ç¨ã€”2018ã€•76å·...
2018-10-27 23:51:55,497 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:51:55,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:51:55,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:51:55,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:51:55,499 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :48842
2018-10-27 23:51:55,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:51:55,501 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:51:55,501 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180718_956824.htm>
None
2018-10-27 23:51:57,683 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:51:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:51:58,513 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:58,526 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:51:58,527 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:59,028 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:59,035 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:51:59,036 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:51:59,536 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:51:59,545 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:51:59,545 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:00,046 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:00,053 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:00,053 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:00,555 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:00,562 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:00,562 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:01,064 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:01,074 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:01,075 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:01,255 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:52:01] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:52:01,576 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:01,586 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:01,586 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:02,088 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:02,098 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:02,099 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:02,600 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:02,610 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:02,611 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:03,112 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:03,122 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:03,122 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:03,624 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:03,634 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:03,635 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:04,136 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:04,145 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:04,145 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:04,647 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:04,656 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:04,657 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:04,915 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:52:04] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:52:05,159 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:05,168 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:05,169 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:05,670 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:05,679 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:05,680 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:06,181 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:06,191 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:06,192 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:06,693 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:06,702 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:06,713 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:07,215 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:07,225 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:07,226 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:07,727 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:07,737 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:07,738 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:08,010 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:52:08] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:52:08,238 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:08,249 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:08,250 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:08,750 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:08,757 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:08,757 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:09,258 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:09,264 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:09,265 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:09,765 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:09,772 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:09,773 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:10,273 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:10,280 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:10,281 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:10,782 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:10,788 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:10,789 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:11,124 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:52:11] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:52:11,290 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:11,300 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:11,301 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:11,802 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:11,812 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:11,812 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:12,314 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:12,324 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:12,324 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:12,826 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:12,835 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:12,836 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:13,337 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:13,348 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:13,348 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:13,850 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:13,860 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:13,860 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:14,217 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:52:14] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:52:14,362 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:14,371 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:14,372 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:14,873 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:14,883 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:14,884 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:15,385 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:15,396 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:15,396 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:15,897 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:15,907 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:15,907 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:16,408 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:16,418 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:16,418 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:16,920 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:16,931 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:16,931 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:17,305 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:52:17] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:52:17,433 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:17,443 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:17,443 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:17,945 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:17,954 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:17,955 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:18,456 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/element {"using": "xpath", "value": "//*[@id=\"hlw\"]/div[2]/div/div/div/a[9]", "sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:18,466 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "POST /session/655e2cb31cf2916b9d128e4052de679d/element HTTP/1.1" 200 363
2018-10-27 23:52:18,467 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:18,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:186] - INFO: Message: 

2018-10-27 23:52:18,969 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/source {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:18,977 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "GET /session/655e2cb31cf2916b9d128e4052de679d/source HTTP/1.1" 200 31901
2018-10-27 23:52:18,978 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:18,980 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: DELETE http://127.0.0.1:62667/session/655e2cb31cf2916b9d128e4052de679d/window {"sessionId": "655e2cb31cf2916b9d128e4052de679d"}
2018-10-27 23:52:19,066 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:62667 "DELETE /session/655e2cb31cf2916b9d128e4052de679d/window HTTP/1.1" 200 70
2018-10-27 23:52:19,067 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:52:19,070 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180515_941293.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:19,073 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201706/t20170615_846624.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:19,091 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:19,143 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 8536:  æ•™è‚²éƒ¨ è´¢æ”¿éƒ¨ å›½å®¶å‘å±•æ”¹é©å§”å°å‘ã€Šå…³äºé«˜ç­‰å­¦æ ¡åŠ å¿«â€œåŒä¸€æµâ€å»ºè®¾çš„æŒ‡å¯¼æ„è§ã€‹...
2018-10-27 23:52:19,147 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:19,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:19,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:19,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:19,149 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :100954
2018-10-27 23:52:19,151 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:19,151 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:19,151 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965491.htm>
None
2018-10-27 23:52:19,152 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:19,210 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing .content>.Custom_UnionStyle of length 4739:  ç²¤åºœã€”2018ã€•79å· å„åœ°çº§ä»¥ä¸Šå¸‚äººæ°‘æ”¿åºœï¼Œå„å¿ï¼ˆå¸‚ã€åŒºï¼‰äººæ°‘æ”¿åºœï¼Œçœæ”¿åºœå„...
2018-10-27 23:52:19,212 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 4801:  å¹¿ä¸œçœäººæ°‘æ”¿åºœå…³äºå°å‘å¹¿ä¸œçœé™ä½åˆ¶é€ ä¸šä¼ä¸šæˆæœ¬æ”¯æŒå®ä½“ç»æµå‘å±•è‹¥å¹²æ”¿ç­–æªæ–½ï¼ˆä¿®...
2018-10-27 23:52:19,216 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:19,294 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/czxw/201809/P020180911544338596055.doc HTTP/1.1" 200 63488
2018-10-27 23:52:19,384 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/czxw/201809/t20180911_967162.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:19_P020180911544338596055.doc'
2018-10-27 23:52:19,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:19,441 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 5363:  ä¸­å…±ä¸­å¤®åŠå…¬å… å›½åŠ¡é™¢åŠå…¬å…å°å‘ã€Šå…³äºåŠ å¼ºå›½æœ‰ä¼ä¸šèµ„äº§è´Ÿå€ºçº¦æŸçš„æŒ‡å¯¼æ„è§ã€‹ è¿‘...
2018-10-27 23:52:19,449 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:19,450 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:19,451 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:19,451 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:19,452 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :133754
2018-10-27 23:52:19,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:19,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:19,456 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201809/t20180921_969161.htm>
None
2018-10-27 23:52:19,457 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:19,531 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 4963:  ï¼ˆå—æƒå‘å¸ƒï¼‰ä¸­å…±ä¸­å¤® å›½åŠ¡é™¢å…³äºå…¨é¢å®æ–½é¢„ç®—ç»©æ•ˆç®¡ç†çš„æ„è§ æ–°åç¤¾åŒ—äº¬9æœˆ25...
2018-10-27 23:52:19,541 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:19,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:19,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:19,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:19,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :164606
2018-10-27 23:52:19,548 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:19,548 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:19,548 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201809/t20180928_970202.htm>
None
2018-10-27 23:52:19,549 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:19,592 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1006:  è´¢æ”¿éƒ¨å‡ºå°è´¢æ”¿ç³»ç»Ÿè´¯å½»è½å®å®æ–½ä¹¡æ‘æŒ¯å…´æˆ˜ç•¥çš„æ„è§ 9æœˆ27æ—¥ï¼Œè´¢æ”¿éƒ¨å°å‘ã€Šè´¢æ”¿...
2018-10-27 23:52:19,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:19,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:19,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:19,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:19,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :170997
2018-10-27 23:52:19,604 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:19,604 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:19,605 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181011_971778.htm>
None
2018-10-27 23:52:19,605 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:19,647 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 584:  å»äº§èƒ½å’Œè°ƒç»“æ„æˆ¿äº§ç¨ã€åŸé•‡åœŸåœ°ä½¿ç”¨ç¨æ”¿ç­–æ˜ç¡® å…³äºå»äº§èƒ½å’Œè°ƒç»“æ„æˆ¿äº§ç¨ åŸé•‡åœŸ...
2018-10-27 23:52:19,657 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:19,661 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:19,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:19,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:19,664 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :174958
2018-10-27 23:52:19,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:19,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:19,674 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201810/t20181017_972566.htm>
None
2018-10-27 23:52:19,674 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:19,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 71:  è´¢æ”¿éƒ¨å…³äºå°å‘ã€Šå·¥ä¸šä¼ä¸šç»“æ„è°ƒæ•´ä¸“é¡¹å¥–è¡¥èµ„é‡‘ç®¡ç†åŠæ³•ã€‹çš„é€šçŸ¥ é™„ä»¶ä¸‹è½½ï¼š è´¢æ”¿...
2018-10-27 23:52:19,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 71:  è´¢æ”¿éƒ¨å…³äºå°å‘ã€Šå·¥ä¸šä¼ä¸šç»“æ„è°ƒæ•´ä¸“é¡¹å¥–è¡¥èµ„é‡‘ç®¡ç†åŠæ³•ã€‹çš„é€šçŸ¥ é™„ä»¶ä¸‹è½½ï¼š è´¢æ”¿...
2018-10-27 23:52:19,766 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:19,841 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/ggtz/201810/P020181022364957361682.pdf HTTP/1.1" 200 616767
2018-10-27 23:52:20,301 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/ggtz/201810/t20181022_973300.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:19_P020181022364957361682.pdf'
2018-10-27 23:52:20,302 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:20,340 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1156:  å…³äºå°å‘ã€Šå¹¿ä¸œçœå•†å“å‚¨å¤‡ç®¡ç†å…¬å¸åŠå…¶ç›´å±åº“äº«å—ç¨æ”¶ä¼˜æƒ æ”¿ç­–åå•å‘å¸ƒç¨‹åºç®¡ç†åŠæ³•...
2018-10-27 23:52:20,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:20,347 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:20,347 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:20,348 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:20,349 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :182243
2018-10-27 23:52:20,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:20,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:20,352 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201803/t20180309_929440.htm>
None
2018-10-27 23:52:20,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:20,391 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:52:20] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:52:20,407 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 387:  å…³äºè®¾å¤‡ å™¨å…·æ‰£é™¤æœ‰å…³ä¼ä¸šæ‰€å¾—ç¨æ”¿ç­–çš„é€šçŸ¥ è´¢ç¨ã€”2018ã€•54å· å„çœã€è‡ªæ²»...
2018-10-27 23:52:20,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:20,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:20,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:20,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:20,421 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :184783
2018-10-27 23:52:20,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:20,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:20,426 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180515_941293.htm>
None
2018-10-27 23:52:20,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:20,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 284:  å…³äºå…¬å¸ƒå¹¿ä¸œçœçœçº§ç¬¬åä¸€æ‰¹è·å¾—éè¥åˆ©ç»„ç»‡å…ç¨èµ„æ ¼å•ä½åå•çš„é€šçŸ¥ å„åœ°çº§ä»¥ä¸Šå¸‚è´¢...
2018-10-27 23:52:20,471 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:20,546 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /ztjj/szgl/sszc/201706/P020171026549147027396.doc HTTP/1.1" 200 36864
2018-10-27 23:52:20,649 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201706/t20170615_846624.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:20_P020171026549147027396.doc'
2018-10-27 23:52:21,101 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201703/P020170306594252129672.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:21,104 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216611417204433.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:21,106 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170206637943497513.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:21,107 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216612639683465.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:21,109 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201703/P020170327581681945068.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:21,110 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201704/P020170410587543449441.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:21,203 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:21,217 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:21,217 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:21,218 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:21,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:21,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:21,230 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:21,230 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:21,231 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :185154
2018-10-27 23:52:21,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:21,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:21,235 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201703/P020170306594252129672.pdf>
None
2018-10-27 23:52:21,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:21,252 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:21,252 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:21,253 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:21,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:21,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:21,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:21,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:21,267 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :185525
2018-10-27 23:52:21,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:21,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:21,272 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216611417204433.pdf>
None
2018-10-27 23:52:21,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:21,281 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:21,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:21,283 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:21,288 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:21,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:21,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:21,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:21,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :185896
2018-10-27 23:52:21,296 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:21,297 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:21,297 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170206637943497513.pdf>
None
2018-10-27 23:52:21,298 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:21,318 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:21,318 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:21,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:21,337 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:21,339 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:21,340 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:21,342 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:21,343 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :186267
2018-10-27 23:52:21,347 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:21,348 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:21,348 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216612639683465.pdf>
None
2018-10-27 23:52:21,349 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:21,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:21,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:21,365 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:21,375 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:21,378 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:21,379 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:21,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:21,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :186638
2018-10-27 23:52:21,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:21,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:21,387 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201703/P020170327581681945068.pdf>
None
2018-10-27 23:52:21,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:21,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:21,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:21,406 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:21,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:21,422 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:21,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:21,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:21,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :187009
2018-10-27 23:52:21,431 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:21,432 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:21,432 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201704/P020170410587543449441.pdf>
None
2018-10-27 23:52:21,585 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216598691051938.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:21,595 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216607732677258.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:21,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:21,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:21,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:21,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:21,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:21,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:21,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:21,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:21,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :187380
2018-10-27 23:52:21,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:21,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:21,720 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216598691051938.pdf>
None
2018-10-27 23:52:21,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:21,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:21,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:21,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:21,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:21,744 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:21,744 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:21,744 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:21,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :187751
2018-10-27 23:52:21,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:21,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:21,750 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216607732677258.pdf>
None
2018-10-27 23:52:23,169 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201609/t20160906_791925.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:23,173 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201608/t20160808_786399.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:23,176 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020170216543386227080.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:23,201 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020161018636061901239.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:23,204 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020161018637080239723.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:23,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:23,317 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1346:  è½¬å‘è´¢æ”¿éƒ¨ å›½å®¶ç¨åŠ¡æ€»å±€ å‘å±•æ”¹é©å§” å·¥ä¸šå’Œä¿¡æ¯åŒ–éƒ¨å…³äºè½¯ä»¶å’Œé›†æˆç”µè·¯äº§ä¸šä¼ä¸š...
2018-10-27 23:52:23,327 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:23,328 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:23,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:23,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:23,330 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :196344
2018-10-27 23:52:23,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:23,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:23,334 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201609/t20160906_791925.htm>
None
2018-10-27 23:52:23,339 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:23,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1390:  è½¬å‘è´¢æ”¿éƒ¨ å›½å®¶ç¨åŠ¡æ€»å±€ å‘å±•æ”¹é©å§” å·¥ä¸šå’Œä¿¡æ¯åŒ–éƒ¨å…³äºè½¯ä»¶å’Œé›†æˆç”µè·¯äº§ä¸šä¼ä¸š...
2018-10-27 23:52:23,386 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:23,459 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/zcfg/201608/P020160808564231216265.pdf HTTP/1.1" 200 957406
2018-10-27 23:52:23,728 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:52:23] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:52:24,181 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201608/t20160808_786399.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:23_P020160808564231216265.pdf'
2018-10-27 23:52:24,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:24,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:24,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:24,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:24,203 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:24,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:24,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:24,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:24,206 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :196715
2018-10-27 23:52:24,210 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:24,210 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:24,211 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020170216543386227080.pdf>
None
2018-10-27 23:52:24,211 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:24,221 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:24,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:24,223 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:24,231 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:24,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:24,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:24,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:24,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :197086
2018-10-27 23:52:24,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:24,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:24,240 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020161018636061901239.pdf>
None
2018-10-27 23:52:24,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:24,249 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:24,249 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:24,250 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:24,256 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:24,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:24,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:24,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:24,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :197457
2018-10-27 23:52:24,262 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:24,262 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:24,263 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020161018637080239723.pdf>
None
2018-10-27 23:52:24,265 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777743.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:24,267 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777742.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:24,268 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216589607037301.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:24,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:24,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 340:  è½¬å‘è´¢æ”¿éƒ¨ å›½å®¶ç¨åŠ¡æ€»å±€ å•†åŠ¡éƒ¨ ç§‘æŠ€éƒ¨ å›½å®¶å‘å±•æ”¹é©å§”å…³äºå®Œå–„æŠ€æœ¯å…ˆè¿›å‹æœåŠ¡...
2018-10-27 23:52:24,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:24,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:24,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:24,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:24,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :199980
2018-10-27 23:52:24,431 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:24,432 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:24,432 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777743.htm>
None
2018-10-27 23:52:24,437 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:24,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 262:  è½¬å‘è´¢æ”¿éƒ¨ å›½å®¶ç¨åŠ¡æ€»å±€ è¯ç›‘ä¼šå…³äºQFIIå’ŒRQFIIå–å¾—ä¸­å›½å¢ƒå†…çš„è‚¡ç¥¨ç­‰æƒ...
2018-10-27 23:52:24,556 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:24,558 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:24,559 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:24,559 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:24,560 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :202008
2018-10-27 23:52:24,563 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:24,564 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:24,564 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777742.htm>
None
2018-10-27 23:52:24,564 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:24,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:24,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:24,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:24,581 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:24,583 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:24,583 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:24,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:24,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :202379
2018-10-27 23:52:24,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:24,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:24,589 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216589607037301.pdf>
None
2018-10-27 23:52:25,229 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777744.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:25,332 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:25,373 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 204:  è½¬å‘è´¢æ”¿éƒ¨ å›½å®¶ç¨åŠ¡æ€»å±€å…³äºå®Œå–„å›ºå®šèµ„äº§åŠ é€ŸæŠ˜æ—§ä¼ä¸šæ‰€å¾—ç¨æ”¿ç­–çš„é€šçŸ¥ å„åœ°çº§ä»¥...
2018-10-27 23:52:25,385 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:25,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:25,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:25,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:25,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :204023
2018-10-27 23:52:25,392 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:25,392 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:25,392 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777744.htm>
None
2018-10-27 23:52:25,453 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777745.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:25,459 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777746.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:25,494 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201609/t20160905_791787.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:25,500 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777747.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:25,557 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:25,608 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 180:  è½¬å‘è´¢æ”¿éƒ¨ å›½å®¶ç¨åŠ¡æ€»å±€å…³äºé‡‘èæœºæ„ä¸å°å‹å¾®å‹ä¼ä¸šç­¾è®¢å€Ÿæ¬¾åˆåŒå…å¾å°èŠ±ç¨çš„é€šçŸ¥...
2018-10-27 23:52:25,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:25,617 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:25,617 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:25,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:25,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :205558
2018-10-27 23:52:25,622 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:25,622 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:25,622 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777745.htm>
None
2018-10-27 23:52:25,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:25,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 222:  è½¬å‘è´¢æ”¿éƒ¨ å›½å®¶ç¨åŠ¡æ€»å±€ è¯ç›‘ä¼šå…³äºæ²ªæ¸¯è‚¡ç¥¨å¸‚åœºäº¤æ˜“äº’è”äº’é€šæœºåˆ¶è¯•ç‚¹æœ‰å…³ç¨æ”¶æ”¿...
2018-10-27 23:52:25,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:25,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:25,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:25,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:25,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :207337
2018-10-27 23:52:25,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:25,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:25,737 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777746.htm>
None
2018-10-27 23:52:25,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:25,792 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 288:  å…³äºå°å‘ã€Šå¹¿ä¸œçœå›½å®¶å†œä¸šç»¼åˆå¼€å‘éƒ¨é—¨é¡¹ç›®å®æ–½åŠæ³•ã€‹çš„é€šçŸ¥ æœ‰å…³åœ°çº§å¸‚è´¢æ”¿å±€ï¼Œçœ...
2018-10-27 23:52:25,794 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:25,879 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/zcfg/gdczfg/201609/P020160905632404953968.pdf HTTP/1.1" 200 184728
2018-10-27 23:52:26,107 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201609/t20160905_791787.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:25_P020160905632404953968.pdf'
2018-10-27 23:52:26,108 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:26,149 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 387:  è½¬å‘è´¢æ”¿éƒ¨ å›½å®¶ç¨åŠ¡æ€»å±€ ä¸­å®£éƒ¨å…³äºç»§ç»­å®æ–½æ–‡åŒ–ä½“åˆ¶æ”¹é©ä¸­ç»è¥æ€§æ–‡åŒ–äº‹ä¸šå•ä½è½¬...
2018-10-27 23:52:26,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:26,157 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:26,157 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:26,157 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:26,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :210083
2018-10-27 23:52:26,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:26,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:26,162 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201606/t20160627_777747.htm>
None
2018-10-27 23:52:26,465 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020170216547777046646.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:26,490 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020170216547169831506.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:26,514 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201607/t20160725_783714.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:26,568 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:26,580 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:26,581 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:26,582 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:26,592 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:26,593 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:26,594 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:26,594 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:26,595 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :210454
2018-10-27 23:52:26,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:26,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:26,599 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020170216547777046646.pdf>
None
2018-10-27 23:52:26,602 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:26,611 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:26,612 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:26,612 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:26,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:26,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:26,621 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:26,621 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:26,622 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :210825
2018-10-27 23:52:26,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:26,626 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:26,626 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020170216547169831506.pdf>
None
2018-10-27 23:52:26,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:26,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 550:  è½¬å‘è´¢æ”¿éƒ¨ å›½å®¶ç¨åŠ¡æ€»å±€å…³äºä¿ƒè¿›æ®‹ç–¾äººå°±ä¸šå¢å€¼ç¨ä¼˜æƒ æ”¿ç­–çš„é€šçŸ¥ å„åœ°çº§ä»¥ä¸Šå¸‚è´¢...
2018-10-27 23:52:26,670 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:26,747 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/zcfg/201607/P020160725614474752941.pdf HTTP/1.1" 200 548772
2018-10-27 23:52:26,869 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:52:26] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:52:27,267 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201607/t20160725_783714.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:26_P020160725614474752941.pdf'
2018-10-27 23:52:27,269 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216592045991806.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:27,372 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:27,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:27,385 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:27,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:27,392 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:27,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:27,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:27,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:27,395 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :211196
2018-10-27 23:52:27,399 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:27,399 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:27,400 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216592045991806.pdf>
None
2018-10-27 23:52:27,610 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020161025612918506487.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:27,615 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201611/t20161123_806392.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:27,617 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216597044160867.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:27,619 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201611/P020161102596335539113.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:27,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:27,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:27,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:27,724 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:27,729 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:27,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:27,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:27,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:27,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :211567
2018-10-27 23:52:27,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:27,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:27,737 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201610/P020161025612918506487.pdf>
None
2018-10-27 23:52:27,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:27,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1041:  å…³äºæ˜ç¡®è¥ä¸šç¨æ”¹å¾å¢å€¼ç¨åé€€å½¹å£«å…µå’Œé‡ç‚¹ç¾¤ä½“åˆ›ä¸šå°±ä¸šç¨æ”¶ä¼˜æƒ æ”¿ç­–çš„é€šçŸ¥ å„åœ°çº§...
2018-10-27 23:52:27,788 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:27,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:27,790 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:27,790 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:27,791 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :218085
2018-10-27 23:52:27,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:27,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:27,795 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201611/t20161123_806392.htm>
None
2018-10-27 23:52:27,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:27,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:27,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:27,807 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:27,813 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:27,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:27,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:27,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:27,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :218456
2018-10-27 23:52:27,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:27,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:27,819 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216597044160867.pdf>
None
2018-10-27 23:52:27,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:27,830 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:27,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:27,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:27,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:27,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:27,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:27,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:27,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :218827
2018-10-27 23:52:27,857 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:27,857 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:27,858 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201611/P020161102596335539113.pdf>
None
2018-10-27 23:52:28,593 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216600737261894.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:28,596 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161216629497630774.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:28,597 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201701/P020170124633498458626.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:28,695 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:28,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:28,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:28,706 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:28,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:28,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:28,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:28,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:28,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :219198
2018-10-27 23:52:28,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:28,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:28,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216600737261894.pdf>
None
2018-10-27 23:52:28,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:28,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:28,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:28,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:28,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:28,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:28,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:28,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:28,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :219569
2018-10-27 23:52:28,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:28,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:28,751 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161216629497630774.pdf>
None
2018-10-27 23:52:28,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:28,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:28,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:28,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:28,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:28,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:28,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:28,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:28,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :219940
2018-10-27 23:52:28,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:28,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:28,776 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201701/P020170124633498458626.pdf>
None
2018-10-27 23:52:29,460 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161216631009333461.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:29,561 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:29,572 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:29,573 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:29,573 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:29,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:29,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:29,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:29,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:29,586 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :220311
2018-10-27 23:52:29,590 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:29,590 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:29,590 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161216631009333461.pdf>
None
2018-10-27 23:52:29,601 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216609506150623.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:29,615 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161220566672884739.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:29,626 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161230604621132401.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:29,636 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161221619198728147.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:29,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:29,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:29,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:29,720 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:29,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:29,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:29,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:29,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:29,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :220682
2018-10-27 23:52:29,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:29,740 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:29,741 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201702/P020170216609506150623.pdf>
None
2018-10-27 23:52:29,748 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:29,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:29,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:29,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:29,779 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:29,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:29,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:29,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:29,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :221053
2018-10-27 23:52:29,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:29,790 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:29,791 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161220566672884739.pdf>
None
2018-10-27 23:52:29,792 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:29,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:29,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:29,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:29,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:29,818 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:29,818 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:29,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:29,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :221424
2018-10-27 23:52:29,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:29,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:29,824 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161230604621132401.pdf>
None
2018-10-27 23:52:29,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:29,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:29,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:29,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:29,841 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:29,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:29,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:29,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:29,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :221795
2018-10-27 23:52:29,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:29,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:29,849 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201612/P020161221619198728147.pdf>
None
2018-10-27 23:52:30,589 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201701/P020170106611272064877.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:30,591 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201701/P020170111524066718354.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:30,607 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201701/P020170106612985047352.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:30,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:30,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:30,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:30,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:30,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:30,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:30,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:30,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:30,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :222166
2018-10-27 23:52:30,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:30,717 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:30,717 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201701/P020170106611272064877.pdf>
None
2018-10-27 23:52:30,720 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:30,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:30,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:30,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:30,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:30,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:30,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:30,744 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:30,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :222537
2018-10-27 23:52:30,748 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:30,748 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:30,749 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201701/P020170111524066718354.pdf>
None
2018-10-27 23:52:30,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:30,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:30,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:30,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:30,772 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:30,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:30,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:30,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:30,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :222908
2018-10-27 23:52:30,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:30,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:30,779 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201701/P020170106612985047352.pdf>
None
2018-10-27 23:52:31,588 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201704/P020170417640753117881.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:31,590 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524666762262464.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:31,665 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524667264540231.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:31,668 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524668314261592.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:31,670 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524667901329055.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:31,690 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:31,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:31,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:31,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:31,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:31,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:31,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:31,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:31,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :223279
2018-10-27 23:52:31,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:31,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:31,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201704/P020170417640753117881.pdf>
None
2018-10-27 23:52:31,721 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:31,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:31,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:31,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:31,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:31,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:31,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:31,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:31,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :223650
2018-10-27 23:52:31,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:31,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:31,744 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524666762262464.pdf>
None
2018-10-27 23:52:31,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:31,776 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:31,776 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:31,777 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:31,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:31,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:31,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:31,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:31,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :224021
2018-10-27 23:52:31,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:31,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:31,789 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524667264540231.pdf>
None
2018-10-27 23:52:31,792 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:31,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:31,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:31,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:31,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:31,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:31,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:31,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:31,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :224392
2018-10-27 23:52:31,823 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:31,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:31,824 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524668314261592.pdf>
None
2018-10-27 23:52:31,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:31,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:31,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:31,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:31,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:31,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:31,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:31,855 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:31,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :224763
2018-10-27 23:52:31,863 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:31,864 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:31,864 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524667901329055.pdf>
None
2018-10-27 23:52:32,586 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524669031042242.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:32,599 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524668641165961.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:32,615 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201706/P020170620647637524553.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:32,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:32,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:32,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:32,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:32,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:32,709 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:32,709 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:32,709 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:32,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :225134
2018-10-27 23:52:32,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:32,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:32,715 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524669031042242.pdf>
None
2018-10-27 23:52:32,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:32,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:32,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:32,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:32,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:32,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:32,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:32,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:32,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :225505
2018-10-27 23:52:32,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:32,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:32,751 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201705/P020170524668641165961.pdf>
None
2018-10-27 23:52:32,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:32,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:32,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:32,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:32,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:32,776 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:32,777 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:32,777 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:32,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :225876
2018-10-27 23:52:32,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:32,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:32,783 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201706/P020170620647637524553.pdf>
None
2018-10-27 23:52:33,591 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201706/P020170627639474849446.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:33,633 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201706/P020170627639698344257.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:33,657 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201706/P020170628648468426136.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:33,674 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170703679118075377.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:33,677 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170703679291800352.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:33,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:33,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:33,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:33,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:33,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:33,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:33,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:33,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:33,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :226247
2018-10-27 23:52:33,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:33,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:33,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201706/P020170627639474849446.pdf>
None
2018-10-27 23:52:33,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:33,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:33,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:33,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:33,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:33,755 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:33,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:33,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:33,757 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :226618
2018-10-27 23:52:33,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:33,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:33,761 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201706/P020170627639698344257.pdf>
None
2018-10-27 23:52:33,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:33,776 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:33,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:33,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:33,802 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:33,804 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:33,804 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:33,804 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:33,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :226989
2018-10-27 23:52:33,809 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:33,810 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:33,810 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201706/P020170628648468426136.pdf>
None
2018-10-27 23:52:33,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:33,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:33,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:33,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:33,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:33,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:33,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:33,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:33,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :227360
2018-10-27 23:52:33,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:33,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:33,844 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170703679118075377.pdf>
None
2018-10-27 23:52:33,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:33,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:33,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:33,937 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:33,951 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:33,953 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:33,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:33,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:33,955 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :227731
2018-10-27 23:52:33,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:33,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:33,960 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170703679291800352.pdf>
None
2018-10-27 23:52:34,585 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170712585976584017.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:34,588 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170718646950433670.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:34,604 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170718647484878881.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:34,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:34,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:34,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:34,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:34,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:34,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:34,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:34,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:34,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :228102
2018-10-27 23:52:34,721 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:34,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:34,722 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170712585976584017.pdf>
None
2018-10-27 23:52:34,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:34,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:34,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:34,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:34,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:34,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:34,753 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:34,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:34,755 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :228473
2018-10-27 23:52:34,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:34,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:34,761 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170718646950433670.pdf>
None
2018-10-27 23:52:34,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:34,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:34,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:34,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:34,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:34,781 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:34,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:34,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:34,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :228844
2018-10-27 23:52:34,787 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:34,788 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:34,788 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201707/P020170718647484878881.pdf>
None
2018-10-27 23:52:35,584 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201708/P020170803373431458125.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:35,621 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201709/P020170904694508419350.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:35,637 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201709/P020170929677970825942.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:35,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:35,699 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:35,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:35,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:35,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:35,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:35,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:35,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:35,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :229215
2018-10-27 23:52:35,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:35,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:35,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201708/P020170803373431458125.pdf>
None
2018-10-27 23:52:35,721 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201709/t20170930_893074.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:35,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:35,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:35,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:35,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:35,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:35,744 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:35,744 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:35,744 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:35,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :229586
2018-10-27 23:52:35,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:35,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:35,750 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201709/P020170904694508419350.pdf>
None
2018-10-27 23:52:35,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:35,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:35,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:35,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:35,768 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:35,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:35,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:35,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:35,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :229957
2018-10-27 23:52:35,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:35,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:35,776 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201709/P020170929677970825942.pdf>
None
2018-10-27 23:52:35,778 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201710/t20171019_895400.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:35,823 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:35,877 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1057:  å¹¿ä¸œçœè´¢æ”¿å… å¹¿ä¸œçœåœ°æ–¹ç¨åŠ¡å±€å…³äºè°ƒæ•´åŸé•‡åœŸåœ°ä½¿ç”¨ç¨ç¨é¢æ ‡å‡†çš„é€šçŸ¥ å„åœ°çº§ä»¥ä¸Š...
2018-10-27 23:52:35,879 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:35,949 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/zcfg/201709/P020170930553334151715.doc HTTP/1.1" 200 39936
2018-10-27 23:52:36,040 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201709/t20170930_893074.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:35_P020170930553334151715.doc'
2018-10-27 23:52:36,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:36,088 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 286:  å…³äºåºŸæ­¢å’Œå®£å¸ƒå¤±æ•ˆéƒ¨åˆ†è§„èŒƒæ€§æ–‡ä»¶çš„é€šçŸ¥ ç²¤è´¢æ³•ã€”2017ã€•25å· å„åœ°çº§ä»¥ä¸Šå¸‚...
2018-10-27 23:52:36,090 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:36,163 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/zcfg/201710/P020171019605306684607.xls HTTP/1.1" 200 40448
2018-10-27 23:52:36,257 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201710/t20171019_895400.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:36_P020171019605306684607.xls'
2018-10-27 23:52:36,258 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 79 pages (at 77 pages/min), scraped 70 items (at 70 items/min)
2018-10-27 23:52:36,602 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201711/P020171114642262451374.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:36,606 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201711/P020171114642478908793.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:36,626 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201710/t20171030_897432.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:36,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:36,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:36,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:36,717 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:36,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:36,729 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:36,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:36,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:36,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :230328
2018-10-27 23:52:36,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:36,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:36,736 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201711/P020171114642262451374.pdf>
None
2018-10-27 23:52:36,740 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:36,753 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:36,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:36,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:36,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:36,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:36,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:36,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:36,768 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :230699
2018-10-27 23:52:36,772 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:36,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:36,773 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201711/P020171114642478908793.pdf>
None
2018-10-27 23:52:36,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:36,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 302:  å…³äºå®£å¸ƒã€Šå¹¿ä¸œçœçœçº§åŸ¹è‚²å‘å±•ç¤¾ä¼šç»„ç»‡ä¸“é¡¹èµ„é‡‘ç«äº‰æ€§åˆ†é…è¯„å®¡ç®¡ç†åŠæ³•ã€‹å¤±æ•ˆçš„é€šçŸ¥...
2018-10-27 23:52:36,814 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:36,884 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/zcfg/201710/P020171030700981911345.pdf HTTP/1.1" 200 231700
2018-10-27 23:52:37,107 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201710/t20171030_897432.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:36_P020171030700981911345.pdf'
2018-10-27 23:52:37,583 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201711/P020171127641634064752.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:37,657 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201801/t20180109_918743.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:37,686 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:37,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:37,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:37,697 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:37,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:37,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:37,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:37,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:37,706 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :231070
2018-10-27 23:52:37,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:37,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:37,712 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201711/P020171127641634064752.pdf>
None
2018-10-27 23:52:37,715 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201801/t20180115_920030.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:37,759 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:37,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1318:  å…³äºç»§ç»­æ‰§è¡Œæˆ‘çœè‡ªä¸»å°±ä¸šé€€å½¹å£«å…µå’Œé‡ç‚¹ç¾¤ä½“åˆ›ä¸šå°±ä¸šæœ‰å…³ç¨æ”¶æ”¿ç­–æ‰£å‡é™é¢æ ‡å‡†çš„é€š...
2018-10-27 23:52:37,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:37,943 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:37,943 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:37,943 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:37,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :239122
2018-10-27 23:52:37,948 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:37,949 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:37,949 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201801/t20180109_918743.htm>
None
2018-10-27 23:52:37,952 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:38,118 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 5050:  å…³äºå°å‘ã€Šå¹¿ä¸œçœè´¢æ”¿å…å…³äºçœçº§è´¢æ”¿ç¤¾ä¼šç§‘å­¦ç ”ç©¶é¡¹ç›®èµ„é‡‘çš„ç®¡ç†åŠæ³•ã€‹çš„é€šçŸ¥ å„åœ°...
2018-10-27 23:52:38,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:38,133 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:38,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:38,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:38,135 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :270552
2018-10-27 23:52:38,139 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:38,139 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:38,140 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201801/t20180115_920030.htm>
None
2018-10-27 23:52:38,141 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201801/P020180118679581018441.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:38,143 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201802/P020180205601525385946.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:38,244 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:38,350 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:38,351 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:38,354 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:38,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:38,375 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:38,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:38,377 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:38,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :270923
2018-10-27 23:52:38,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:38,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:38,388 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201801/P020180118679581018441.pdf>
None
2018-10-27 23:52:38,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:38,531 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:38,532 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:38,533 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:38,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:38,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:38,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:38,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:38,546 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :271294
2018-10-27 23:52:38,551 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:38,552 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:38,552 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201802/P020180205601525385946.pdf>
None
2018-10-27 23:52:38,598 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201802/P020180223425589013889.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:38,641 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201802/P020180224614200045529.pdf via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:38,650 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201802/t20180213_926523.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:38,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:38,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:38,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:38,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:38,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:38,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:38,726 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:38,726 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:38,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :271665
2018-10-27 23:52:38,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:38,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:38,732 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201802/P020180223425589013889.pdf>
None
2018-10-27 23:52:38,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:38,892 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:429] - INFO: ruthless removal did not work. 
2018-10-27 23:52:38,893 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:432] - DEBUG: ended up stripping too much - going for a safer _parse
2018-10-27 23:52:38,896 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:438] - DEBUG: Ruthless and lenient parsing did not work. Returning raw html
2018-10-27 23:52:38,915 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:38,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:38,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:38,920 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:38,925 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :272036
2018-10-27 23:52:38,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:38,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:38,935 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201802/P020180224614200045529.pdf>
None
2018-10-27 23:52:38,939 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:39,573 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 721:  å…³äºåœå¾æ’æ±¡è´¹ç­‰è¡Œæ”¿äº‹ä¸šæ€§æ”¶è´¹æœ‰å…³äº‹é¡¹çš„é€šçŸ¥ è´¢ç¨ã€”2018ã€•4å· å„çœã€è‡ªæ²»...
2018-10-27 23:52:39,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:39,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:39,586 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:39,586 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:39,587 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :276512
2018-10-27 23:52:39,591 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:39,591 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:39,591 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201802/t20180213_926523.htm>
None
2018-10-27 23:52:40,089 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180515_941346.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:40,091 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180522_942769.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:40,093 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180522_942729.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:40,192 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:40,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 225:  å…³äºä¼ä¸šèŒå·¥æ•™è‚²ç»è´¹ç¨å‰æ‰£é™¤æ”¿ç­–çš„é€šçŸ¥ è´¢ç¨ã€”2018ã€•51å· å„çœã€è‡ªæ²»åŒºã€...
2018-10-27 23:52:40,249 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:40,250 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:40,251 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:40,251 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:40,252 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :278278
2018-10-27 23:52:40,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:40,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:40,257 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180515_941346.htm>
None
2018-10-27 23:52:40,261 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:40,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 288:  å›½åŠ¡é™¢å…³ç¨ç¨åˆ™å§”å‘˜ä¼šå…³äºé™ä½æ±½è½¦æ•´è½¦åŠé›¶éƒ¨ä»¶è¿›å£å…³ç¨çš„å…¬å‘Š ç¨å§”ä¼šå…¬å‘Šã€”201...
2018-10-27 23:52:40,531 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): gss.mof.gov.cn:80
2018-10-27 23:52:40,694 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://gss.mof.gov.cn:80 "GET /zhengwuxinxi/zhengcefabu/201805/P020180522506508786661.pdf HTTP/1.1" 200 73262
2018-10-27 23:52:40,725 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180522_942769.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:40_P020180522506508786661.pdf'
2018-10-27 23:52:40,727 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180522_942788.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:40,729 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180601_944967.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:40,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:40,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1122:  å…³äºç»§ç»­å®æ–½ä¼ä¸šæ”¹åˆ¶é‡ç»„æœ‰å…³åœŸåœ°å¢å€¼ç¨æ”¿ç­–çš„é€šçŸ¥ è´¢ç¨ã€”2018ã€•57 å· å„...
2018-10-27 23:52:40,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:40,818 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:40,818 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:40,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:40,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :285454
2018-10-27 23:52:40,829 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:40,830 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:40,832 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180522_942729.htm>
None
2018-10-27 23:52:40,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:40,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 477:  å…³äºå°å‘ã€Šå›½é™…åŒ–é«˜ç«¯ä¼šè®¡äººæ‰åŸ¹å…»å·¥ç¨‹å®æ–½æ–¹æ¡ˆã€‹çš„é€šçŸ¥ è´¢ä¼šã€”2018ã€•12å· ...
2018-10-27 23:52:40,900 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:40,966 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/zcfg/201805/P020180522607261706184.doc HTTP/1.1" 200 26075
2018-10-27 23:52:41,022 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201805/t20180522_942788.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:40_P020180522607261706184.doc'
2018-10-27 23:52:41,028 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:41,122 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 630:  ä¸¤éƒ¨é—¨å‘å¸ƒä¼šè®¡ä¸“ä¸šæŠ€æœ¯äººå‘˜ç»§ç»­æ•™è‚²è§„å®š ã€Šä¼šè®¡ä¸“ä¸šæŠ€æœ¯äººå‘˜ç»§ç»­æ•™è‚²è§„å®šã€‹æ—¥å‰ç”±...
2018-10-27 23:52:41,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:41,136 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:41,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:41,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:41,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :289624
2018-10-27 23:52:41,143 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:41,143 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:41,144 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180601_944967.htm>
None
2018-10-27 23:52:41,146 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180612_946465.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:41,148 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180619_947356.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:41,250 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:41,343 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1492:  æˆ‘å›½å°†åˆ¶å®šâ€œå°å†œæˆ·æŒ¯å…´â€æ‰¶æŒæ”¿ç­– ã€Šç»æµå‚è€ƒæŠ¥ã€‹è®°è€…æ—¥å‰è·æ‚‰ï¼Œä¸ºäº†ä¿ƒè¿›å°å†œæˆ·å’Œ...
2018-10-27 23:52:41,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:41,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:41,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:41,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:41,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :298998
2018-10-27 23:52:41,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:41,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:41,370 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180612_946465.htm>
None
2018-10-27 23:52:41,373 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:41,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 791:  å®£ä¼ æ–‡åŒ–å¢å€¼ç¨ä¼˜æƒ æ”¿ç­–ç»§ç»­å®æ–½ æ—¥å‰ï¼Œè´¢æ”¿éƒ¨ã€å›½å®¶ç¨åŠ¡æ€»å±€ä¸‹å‘ã€Šå…³äºå»¶ç»­å®£ä¼ æ–‡...
2018-10-27 23:52:41,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:41,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:41,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:41,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:41,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :303855
2018-10-27 23:52:41,432 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:41,432 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:41,433 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180619_947356.htm>
None
2018-10-27 23:52:41,586 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180601_944966.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:41,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:41,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 4071:  è´¢æ”¿éƒ¨ä¼šè®¡å¸ äººåŠ›èµ„æºç¤¾ä¼šä¿éšœéƒ¨ä¸“æŠ€å¸æœ‰å…³è´Ÿè´£äººå°±å°å‘ã€Šä¼šè®¡ä¸“ä¸šæŠ€æœ¯äººå‘˜ç»§ç»­æ•™...
2018-10-27 23:52:41,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:41,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:41,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:41,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:41,757 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :328929
2018-10-27 23:52:41,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:41,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:41,767 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180601_944966.htm>
None
2018-10-27 23:52:42,584 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180619_947358.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:42,586 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180705_954534.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:42,628 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965465.htm via http://localhost:8050/execute> (referer: None)
2018-10-27 23:52:42,686 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:42,729 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1486:  è´¢æ”¿éƒ¨åŠ›æ¨å†œæ‘ç”µå­å•†åŠ¡ä¿ƒæ‰¶è´«æ”»åš è¿‘æ—¥ï¼Œè´¢æ”¿éƒ¨ä¸‹å‘ã€Šå…³äºå¼€å±•2018å¹´ç”µå­å•†åŠ¡...
2018-10-27 23:52:42,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:42,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:42,740 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:42,740 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:42,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :338132
2018-10-27 23:52:42,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:42,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:42,747 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201806/t20180619_947358.htm>
None
2018-10-27 23:52:42,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:42,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 951:  è´¢æ”¿éƒ¨æ‹Ÿè¿›ä¸€æ­¥è§„èŒƒæ”¿åºœè´­ä¹°æœåŠ¡è¡Œä¸º ä¸¥ç¦ä»¥æ”¿åºœè´­ä¹°æœåŠ¡åä¹‰è¿è§„ä¸¾å€º è´¢æ”¿éƒ¨26...
2018-10-27 23:52:42,802 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:52:42,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:52:42,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:52:42,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:71528
2018-10-27 23:52:42,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :344234
2018-10-27 23:52:42,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:52:42,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:52:42,844 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gdczt.gov.cn/zwgk/zcfg/201807/t20180705_954534.htm>
None
2018-10-27 23:52:42,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:52:42,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>.content of length 1450:  ä¸‰éƒ¨é—¨å…¨é¢éƒ¨ç½²è½å®åŠ å¼ºè´¢æ”¿æ‰¶è´«é¡¹ç›®èµ„é‡‘ç»©æ•ˆç®¡ç† 7æœˆ4æ—¥ï¼Œè´¢æ”¿éƒ¨ç»„ç»‡å¬å¼€æ‰¶è´«é¡¹...
2018-10-27 23:52:42,933 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.gdczt.gov.cn:80
2018-10-27 23:52:43,009 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.gdczt.gov.cn:80 "GET /zwgk/zcfg/201808/W020180831595084248506.jpg HTTP/1.1" 200 30723
2018-10-27 23:52:43,091 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://www.gdczt.gov.cn/zwgk/zcfg/201808/t20180831_965465.htm via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:52:42_W020180831595084248506.jpg'
2018-10-27 23:52:43,112 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (finished)
2018-10-27 23:52:43,124 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-27 23:52:43,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-27 23:52:43,138 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 98903,
 'downloader/request_count': 101,
 'downloader/request_method_count/GET': 1,
 'downloader/request_method_count/POST': 100,
 'downloader/response_bytes': 1777133,
 'downloader/response_count': 101,
 'downloader/response_status_count/200': 101,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 10, 27, 15, 52, 43, 124686),
 'item_scraped_count': 88,
 'log_count/DEBUG': 1144,
 'log_count/ERROR': 12,
 'log_count/INFO': 509,
 'memusage/max': 86777856,
 'memusage/startup': 63954944,
 'request_depth_max': 1,
 'response_received_count': 101,
 'scheduler/dequeued': 201,
 'scheduler/dequeued/memory': 201,
 'scheduler/enqueued': 201,
 'scheduler/enqueued/memory': 201,
 'spider_exceptions/FileNotFoundError': 12,
 'splash/execute/request_count': 100,
 'splash/execute/response_count/200': 100,
 'start_time': datetime.datetime(2018, 10, 27, 15, 50, 36, 257989)}
2018-10-27 23:52:43,138 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (finished)
2018-10-27 23:54:22,277 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-27 23:54:28,104 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:54:28] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-27 23:54:39,320 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:54:39] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-27 23:56:14,585 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:14] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-27 23:56:14,728 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:14] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:14,816 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-27 23:56:14,840 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-27 23:56:14,845 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-27 23:56:14,875 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-27 23:56:14,906 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-27 23:56:14,971 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-27 23:56:14,973 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-27 23:56:15,005 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-27 23:56:15,006 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-27 23:56:15,014 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:56:15,016 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-27 23:56:17,868 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:17] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:18,040 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/ via http://localhost:8050/execute> (referer: None)
2018-10-27 23:56:18,345 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875830> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,348 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=879314> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,353 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876153> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,355 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876154> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,358 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=877741> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,375 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=877448> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,381 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876151> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,422 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876185> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,425 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876204> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,438 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=878121> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,446 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875831> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,449 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876150> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,450 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,482 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,485 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,485 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,486 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,486 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,487 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :2601
2018-10-27 23:56:18,487 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,487 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,488 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875830>
None
2018-10-27 23:56:18,491 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=879184> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,492 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876152> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,494 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875219> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,495 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=878504> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,501 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,530 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :4493
2018-10-27 23:56:18,530 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,530 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,531 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=879314>
None
2018-10-27 23:56:18,532 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=877572> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,534 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875220> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,534 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,556 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,559 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,560 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,560 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,560 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,561 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6385
2018-10-27 23:56:18,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,563 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,564 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876153>
None
2018-10-27 23:56:18,564 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,591 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,591 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,592 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,593 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,594 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :8277
2018-10-27 23:56:18,595 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,595 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,596 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876154>
None
2018-10-27 23:56:18,596 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,621 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,624 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,626 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :10169
2018-10-27 23:56:18,626 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,627 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,627 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=877741>
None
2018-10-27 23:56:18,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,656 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,660 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,660 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,661 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,661 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :12061
2018-10-27 23:56:18,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,663 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=877448>
None
2018-10-27 23:56:18,664 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,686 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,690 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,690 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,690 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :13953
2018-10-27 23:56:18,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,692 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,692 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876151>
None
2018-10-27 23:56:18,697 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875270> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,699 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875629> (referer: http://gkml.sport.gov.cn:8880/gdnps/)
2018-10-27 23:56:18,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :15845
2018-10-27 23:56:18,740 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,740 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,741 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876185>
None
2018-10-27 23:56:18,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :17737
2018-10-27 23:56:18,768 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,768 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,768 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876204>
None
2018-10-27 23:56:18,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,807 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,807 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,808 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,810 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :19629
2018-10-27 23:56:18,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,813 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=878121>
None
2018-10-27 23:56:18,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,851 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,851 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,853 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :21521
2018-10-27 23:56:18,855 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,855 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,856 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875831>
None
2018-10-27 23:56:18,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,904 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,909 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :23413
2018-10-27 23:56:18,911 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,912 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876150>
None
2018-10-27 23:56:18,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,937 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,938 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,938 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,939 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,939 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :25305
2018-10-27 23:56:18,940 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,940 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,941 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=879184>
None
2018-10-27 23:56:18,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,963 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :27197
2018-10-27 23:56:18,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:18,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:18,968 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876152>
None
2018-10-27 23:56:18,969 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:18,991 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:18,995 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:18,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:18,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:18,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:18,999 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :29089
2018-10-27 23:56:19,000 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:19,001 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:19,001 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875219>
None
2018-10-27 23:56:19,002 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:19,024 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:19,029 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:19,030 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:19,031 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:19,031 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:19,031 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :30981
2018-10-27 23:56:19,032 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:19,033 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:19,033 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=878504>
None
2018-10-27 23:56:19,034 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:19,058 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:19,062 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:19,065 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:19,065 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:19,066 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:19,066 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :32873
2018-10-27 23:56:19,067 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:19,068 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:19,069 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=877572>
None
2018-10-27 23:56:19,069 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:19,096 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:19,099 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:19,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:19,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:19,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:19,101 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :34765
2018-10-27 23:56:19,102 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:19,102 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:19,103 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875220>
None
2018-10-27 23:56:19,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:19,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:19,141 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:19,142 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:19,142 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:19,142 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:19,143 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :36657
2018-10-27 23:56:19,144 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:19,144 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:19,144 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875270>
None
2018-10-27 23:56:19,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:56:19,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 38:  ç´¢ å¼• å· å‘å¸ƒæœºæ„ å ç§° ç”Ÿæˆæ—¥æœŸ æ–‡ å· ä¸»é¢˜åˆ†ç±» ä¸»é¢˜è¯ å†…å®¹æ¦‚è¿° 
2018-10-27 23:56:19,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:56:19,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:56:19,173 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:56:19,173 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:56:19,173 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :38549
2018-10-27 23:56:19,174 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:56:19,174 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:56:19,175 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875629>
None
2018-10-27 23:56:20,958 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:20] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:24,056 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:24] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:27,158 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:27] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:29,419 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/ via http://localhost:8050/execute> (referer: None)
2018-10-27 23:56:29,536 - /anaconda3/lib/python3.6/site-packages/scrapy/dupefilters.py[line:70] - DEBUG: Filtered duplicate request: <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876154> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-27 23:56:29,545 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (finished)
2018-10-27 23:56:29,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-27 23:56:29,554 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-27 23:56:29,560 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 9965,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 20,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 298979,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 22,
 'dupefilter/filtered': 21,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 10, 27, 15, 56, 29, 546973),
 'item_scraped_count': 20,
 'log_count/DEBUG': 125,
 'log_count/INFO': 109,
 'memusage/max': 63561728,
 'memusage/startup': 63561728,
 'request_depth_max': 2,
 'response_received_count': 22,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 15, 56, 15, 14813)}
2018-10-27 23:56:29,561 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (finished)
2018-10-27 23:56:30,254 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:30] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:33,339 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:33] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:36,431 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:39,518 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:42,601 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:45,688 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:48,779 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:48] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:51,862 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:53,106 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:nosw
2018-10-27 23:56:53,106 - /Users/tian/zaluan/ScrapyA/app/views.py[line:374] - INFO: nosw
2018-10-27 23:56:54,947 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:56:55,107 - /Users/tian/zaluan/ScrapyA/app/views.py[line:391] - INFO: userinfo in crawling:{}
2018-10-27 23:56:55,124 - /Users/tian/zaluan/ScrapyA/app/views.py[line:393] - INFO: before
2018-10-27 23:56:55,125 - /Users/tian/zaluan/ScrapyA/app/views.py[line:394] - INFO: after:open
2018-10-27 23:56:58,034 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:56:58] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:00,130 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:00] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-27 23:57:00,312 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-27 23:57:00,329 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-27 23:57:00,335 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-27 23:57:00,367 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-27 23:57:00,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-27 23:57:01,123 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:01] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:01,466 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": []}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": []}}}
2018-10-27 23:57:01,468 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): 127.0.0.1:64592
2018-10-27 23:57:03,131 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session HTTP/1.1" 200 903
2018-10-27 23:57:03,133 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:03,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:80] - INFO: é¡µç æ‰€åœ¨çš„xpath://*[@id="contentId"]/table[2]/tbody/tr[2]/td/table[2]/tbody/tr
2018-10-27 23:57:03,168 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-27 23:57:03,171 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-27 23:57:03,203 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-27 23:57:03,204 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-27 23:57:03,213 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-27 23:57:03,215 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-27 23:57:03,441 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/> (referer: None)
2018-10-27 23:57:03,545 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/url {"url": "http://gkml.sport.gov.cn:8880/gdnps/", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:04,207 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:04] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:04,820 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/url HTTP/1.1" 200 72
2018-10-27 23:57:04,821 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:04,822 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:04,841 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 114131
2018-10-27 23:57:04,844 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:04,855 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=879314', 'content.jsp?id=879184', 'content.jsp?id=878504', 'content.jsp?id=878121', 'content.jsp?id=877741', 'content.jsp?id=877572', 'content.jsp?id=877448', 'content.jsp?id=876204', 'content.jsp?id=876185', 'content.jsp?id=876151', 'content.jsp?id=876152', 'content.jsp?id=876153', 'content.jsp?id=876154', 'content.jsp?id=876150', 'content.jsp?id=875831', 'content.jsp?id=875830', 'content.jsp?id=875629', 'content.jsp?id=875270', 'content.jsp?id=875219', 'content.jsp?id=875220']
2018-10-27 23:57:07,294 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:07] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:07,867 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:07,884 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 102
2018-10-27 23:57:07,885 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:07,885 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-1/displayed {"id": "0.7723595768561216-1", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:07,899 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-1/displayed HTTP/1.1" 200 72
2018-10-27 23:57:07,900 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:07,900 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-1/enabled {"id": "0.7723595768561216-1", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:07,909 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-1/enabled HTTP/1.1" 200 72
2018-10-27 23:57:07,909 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:07,910 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-1/click {"id": "0.7723595768561216-1", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:07,948 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-1/click HTTP/1.1" 200 72
2018-10-27 23:57:07,948 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:09,950 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:09,962 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115005
2018-10-27 23:57:09,964 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:09,975 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=875108', 'content.jsp?id=874453', 'content.jsp?id=874233', 'content.jsp?id=874234', 'content.jsp?id=874126', 'content.jsp?id=873972', 'content.jsp?id=873964', 'content.jsp?id=873794', 'content.jsp?id=873208', 'content.jsp?id=871905', 'content.jsp?id=871709', 'content.jsp?id=871609', 'content.jsp?id=871203', 'content.jsp?id=871143', 'content.jsp?id=870841', 'content.jsp?id=870539', 'content.jsp?id=870536', 'content.jsp?id=870535', 'content.jsp?id=870175', 'content.jsp?id=870059']
2018-10-27 23:57:10,396 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:10] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:13,007 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:13,018 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 102
2018-10-27 23:57:13,018 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:13,019 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-2/displayed {"id": "0.7723595768561216-2", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:13,031 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-2/displayed HTTP/1.1" 200 72
2018-10-27 23:57:13,031 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:13,032 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-2/enabled {"id": "0.7723595768561216-2", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:13,039 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-2/enabled HTTP/1.1" 200 72
2018-10-27 23:57:13,040 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:13,040 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-2/click {"id": "0.7723595768561216-2", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:13,072 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-2/click HTTP/1.1" 200 72
2018-10-27 23:57:13,073 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:13,483 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:13] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:15,073 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:15,082 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115493
2018-10-27 23:57:15,085 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:15,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=870011', 'content.jsp?id=869901', 'content.jsp?id=869497', 'content.jsp?id=869267', 'content.jsp?id=869266', 'content.jsp?id=868848', 'content.jsp?id=868785', 'content.jsp?id=868663', 'content.jsp?id=868440', 'content.jsp?id=868207', 'content.jsp?id=867883', 'content.jsp?id=868199', 'content.jsp?id=867464', 'content.jsp?id=867174', 'content.jsp?id=867029', 'content.jsp?id=866834', 'content.jsp?id=866847', 'content.jsp?id=866328', 'content.jsp?id=866329', 'content.jsp?id=865925']
2018-10-27 23:57:17,010 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:17] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:18,104 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:18,114 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 102
2018-10-27 23:57:18,115 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:18,115 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-3/displayed {"id": "0.7723595768561216-3", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:18,128 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-3/displayed HTTP/1.1" 200 72
2018-10-27 23:57:18,129 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:18,129 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-3/enabled {"id": "0.7723595768561216-3", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:18,137 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-3/enabled HTTP/1.1" 200 72
2018-10-27 23:57:18,137 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:18,138 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-3/click {"id": "0.7723595768561216-3", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:18,171 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-3/click HTTP/1.1" 200 72
2018-10-27 23:57:18,172 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:20,100 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:20] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:20,172 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:20,183 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115361
2018-10-27 23:57:20,184 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:20,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=865452', 'content.jsp?id=864879', 'content.jsp?id=864880', 'content.jsp?id=864778', 'content.jsp?id=864767', 'content.jsp?id=864656', 'content.jsp?id=864636', 'content.jsp?id=863776', 'content.jsp?id=863749', 'content.jsp?id=863504', 'content.jsp?id=863478', 'content.jsp?id=863223', 'content.jsp?id=863220', 'content.jsp?id=863179', 'content.jsp?id=863085', 'content.jsp?id=862995', 'content.jsp?id=862777', 'content.jsp?id=862774', 'content.jsp?id=862765', 'content.jsp?id=862764']
2018-10-27 23:57:23,185 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:23] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:23,204 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:23,213 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 102
2018-10-27 23:57:23,213 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:23,214 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-4/displayed {"id": "0.7723595768561216-4", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:23,227 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-4/displayed HTTP/1.1" 200 72
2018-10-27 23:57:23,227 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:23,228 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-4/enabled {"id": "0.7723595768561216-4", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:23,237 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-4/enabled HTTP/1.1" 200 72
2018-10-27 23:57:23,238 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:23,238 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-4/click {"id": "0.7723595768561216-4", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:23,275 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-4/click HTTP/1.1" 200 72
2018-10-27 23:57:23,276 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:25,277 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:25,290 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115081
2018-10-27 23:57:25,292 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:25,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=862711', 'content.jsp?id=862665', 'content.jsp?id=862380', 'content.jsp?id=862379', 'content.jsp?id=862365', 'content.jsp?id=862246', 'content.jsp?id=861652', 'content.jsp?id=861580', 'content.jsp?id=861578', 'content.jsp?id=861241', 'content.jsp?id=860000', 'content.jsp?id=859976', 'content.jsp?id=859839', 'content.jsp?id=859840', 'content.jsp?id=859473', 'content.jsp?id=859428', 'content.jsp?id=857833', 'content.jsp?id=857782', 'content.jsp?id=857609', 'content.jsp?id=857481']
2018-10-27 23:57:26,271 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:26] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:28,313 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:28,324 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 102
2018-10-27 23:57:28,324 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:28,325 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-5/displayed {"id": "0.7723595768561216-5", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:28,337 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-5/displayed HTTP/1.1" 200 72
2018-10-27 23:57:28,337 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:28,338 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-5/enabled {"id": "0.7723595768561216-5", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:28,345 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-5/enabled HTTP/1.1" 200 72
2018-10-27 23:57:28,346 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:28,346 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-5/click {"id": "0.7723595768561216-5", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:28,377 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-5/click HTTP/1.1" 200 72
2018-10-27 23:57:28,377 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:29,351 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:29] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:30,379 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:30,391 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115298
2018-10-27 23:57:30,393 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:30,403 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=857400', 'content.jsp?id=857396', 'content.jsp?id=857381', 'content.jsp?id=857379', 'content.jsp?id=857380', 'content.jsp?id=857377', 'content.jsp?id=857382', 'content.jsp?id=857376', 'content.jsp?id=857398', 'content.jsp?id=857052', 'content.jsp?id=856885', 'content.jsp?id=856881', 'content.jsp?id=856836', 'content.jsp?id=856646', 'content.jsp?id=855506', 'content.jsp?id=856550', 'content.jsp?id=856540', 'content.jsp?id=856538', 'content.jsp?id=856379', 'content.jsp?id=855859']
2018-10-27 23:57:30,406 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875220 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:30,408 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875219 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:30,410 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875108 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:30,412 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875830 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:30,414 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=879314 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:30,416 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875629 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:30,418 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875831 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:30,420 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875270 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:32,454 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:32] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:33,437 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:33,447 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 102
2018-10-27 23:57:33,448 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:33,448 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-6/displayed {"id": "0.7723595768561216-6", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:33,460 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-6/displayed HTTP/1.1" 200 72
2018-10-27 23:57:33,460 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:33,461 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-6/enabled {"id": "0.7723595768561216-6", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:33,468 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-6/enabled HTTP/1.1" 200 72
2018-10-27 23:57:33,469 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:33,469 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-6/click {"id": "0.7723595768561216-6", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:33,500 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-6/click HTTP/1.1" 200 72
2018-10-27 23:57:33,501 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:35,502 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:35,513 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 114533
2018-10-27 23:57:35,515 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:35,524 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=855531', 'content.jsp?id=855029', 'content.jsp?id=855030', 'content.jsp?id=854644', 'content.jsp?id=854104', 'content.jsp?id=854105', 'content.jsp?id=853808', 'content.jsp?id=853699', 'content.jsp?id=853452', 'content.jsp?id=853437', 'content.jsp?id=853360', 'content.jsp?id=853154', 'content.jsp?id=852853', 'content.jsp?id=852528', 'content.jsp?id=852469', 'content.jsp?id=852189', 'content.jsp?id=851832', 'content.jsp?id=850904', 'content.jsp?id=850853', 'content.jsp?id=850249']
2018-10-27 23:57:35,549 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:35] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:38,544 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:38,551 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 102
2018-10-27 23:57:38,551 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:38,551 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-7/displayed {"id": "0.7723595768561216-7", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:38,561 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-7/displayed HTTP/1.1" 200 72
2018-10-27 23:57:38,562 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:38,562 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-7/enabled {"id": "0.7723595768561216-7", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:38,569 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-7/enabled HTTP/1.1" 200 72
2018-10-27 23:57:38,570 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:38,570 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-7/click {"id": "0.7723595768561216-7", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:38,605 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-7/click HTTP/1.1" 200 72
2018-10-27 23:57:38,605 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:38,647 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:38] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:40,607 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:40,619 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 114693
2018-10-27 23:57:40,621 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:40,630 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=850167', 'content.jsp?id=849940', 'content.jsp?id=849933', 'content.jsp?id=849842', 'content.jsp?id=849781', 'content.jsp?id=849169', 'content.jsp?id=849144', 'content.jsp?id=849146', 'content.jsp?id=849147', 'content.jsp?id=849148', 'content.jsp?id=847118', 'content.jsp?id=847079', 'content.jsp?id=847080', 'content.jsp?id=847084', 'content.jsp?id=846569', 'content.jsp?id=846511', 'content.jsp?id=845974', 'content.jsp?id=845973', 'content.jsp?id=845893', 'content.jsp?id=845758']
2018-10-27 23:57:40,633 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876150 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:40,635 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876154 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:40,637 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876153 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:40,638 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876152 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:40,640 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876151 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:40,642 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876185 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:40,643 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876204 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:40,645 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=877448 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:40,646 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:40,683 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:57:40,727 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9343/n9367/c875220/part/519872.jpg HTTP/1.1" 200 667921
2018-10-27 23:57:40,856 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875220 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:57:40_519872.jpg'
2018-10-27 23:57:40,858 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:40,886 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:57:40,957 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9343/n9367/c875219/part/519869.jpg HTTP/1.1" 200 658579
2018-10-27 23:57:41,202 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875219 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:57:40_519869.jpg'
2018-10-27 23:57:41,203 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:41,226 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:57:41,266 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c875108/part/519713.jpg HTTP/1.1" 200 103801
2018-10-27 23:57:41,322 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875108 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:57:41_519713.jpg'
2018-10-27 23:57:41,323 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:41,349 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:57:41,468 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9093/n9103/c875830/part/520772.docx HTTP/1.1" 200 20108
2018-10-27 23:57:41,509 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875830 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:57:41_520772.docx'
2018-10-27 23:57:41,510 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:41,549 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:57:41,742 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:41] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:41,815 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9043/n9053/c879314/part/524618.docx HTTP/1.1" 200 16226
2018-10-27 23:57:41,837 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=879314 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:57:41_524618.docx'
2018-10-27 23:57:41,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:41,866 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:57:41,866 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:57:41,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:57:41,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:57:41,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :5155
2018-10-27 23:57:41,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:57:41,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:57:41,869 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875629>
None
2018-10-27 23:57:41,869 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:41,894 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:57:41,987 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c875831/part/520773.doc HTTP/1.1" 200 42496
2018-10-27 23:57:42,077 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875831 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:57:41_520773.doc'
2018-10-27 23:57:42,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:42,118 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:57:42,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:57:42,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:57:42,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:57:42,120 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :8821
2018-10-27 23:57:42,121 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:57:42,121 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:57:42,122 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=875270>
None
2018-10-27 23:57:44,853 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:44] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:45,149 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:45,159 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 102
2018-10-27 23:57:45,160 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:45,160 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-8/displayed {"id": "0.7723595768561216-8", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:45,171 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-8/displayed HTTP/1.1" 200 72
2018-10-27 23:57:45,172 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:45,172 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-8/enabled {"id": "0.7723595768561216-8", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:45,180 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-8/enabled HTTP/1.1" 200 72
2018-10-27 23:57:45,180 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:45,181 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-8/click {"id": "0.7723595768561216-8", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:45,211 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-8/click HTTP/1.1" 200 72
2018-10-27 23:57:45,212 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:47,212 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:47,221 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115877
2018-10-27 23:57:47,223 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:47,232 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=845115', 'content.jsp?id=844821', 'content.jsp?id=844811', 'content.jsp?id=844638', 'content.jsp?id=844628', 'content.jsp?id=844432', 'content.jsp?id=844127', 'content.jsp?id=843752', 'content.jsp?id=843712', 'content.jsp?id=843391', 'content.jsp?id=843392', 'content.jsp?id=843367', 'content.jsp?id=843124', 'content.jsp?id=843065', 'content.jsp?id=842931', 'content.jsp?id=842767', 'content.jsp?id=842373', 'content.jsp?id=842231', 'content.jsp?id=842187', 'content.jsp?id=841636']
2018-10-27 23:57:47,940 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:47] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:50,257 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:50,267 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 102
2018-10-27 23:57:50,268 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:50,268 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-9/displayed {"id": "0.7723595768561216-9", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:50,280 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-9/displayed HTTP/1.1" 200 72
2018-10-27 23:57:50,280 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:50,280 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-9/enabled {"id": "0.7723595768561216-9", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:50,288 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-9/enabled HTTP/1.1" 200 72
2018-10-27 23:57:50,289 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:50,289 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-9/click {"id": "0.7723595768561216-9", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:50,328 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-9/click HTTP/1.1" 200 72
2018-10-27 23:57:50,328 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:51,026 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:52,330 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:52,342 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 114757
2018-10-27 23:57:52,344 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:52,354 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=841628', 'content.jsp?id=841623', 'content.jsp?id=841504', 'content.jsp?id=837608', 'content.jsp?id=840488', 'content.jsp?id=840283', 'content.jsp?id=840218', 'content.jsp?id=839981', 'content.jsp?id=839571', 'content.jsp?id=838976', 'content.jsp?id=838903', 'content.jsp?id=838803', 'content.jsp?id=838692', 'content.jsp?id=838693', 'content.jsp?id=838028', 'content.jsp?id=837904', 'content.jsp?id=837610', 'content.jsp?id=837605', 'content.jsp?id=837512', 'content.jsp?id=837438']
2018-10-27 23:57:52,356 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857400 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:52,358 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857481 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:52,360 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857609 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:52,362 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857782 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:52,364 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857833 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:52,365 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=859428 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:52,367 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=859473 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:52,369 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=859840 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:57:52,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:52,396 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:57:52,557 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9043/n9053/c876150/part/521189.xlsx HTTP/1.1" 200 11683
2018-10-27 23:57:52,589 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876150 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:57:52_521189.xlsx'
2018-10-27 23:57:52,590 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:52,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:57:52,621 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:57:52,622 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:57:52,622 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:57:52,623 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :10301
2018-10-27 23:57:52,624 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:57:52,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:57:52,626 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876154>
None
2018-10-27 23:57:52,626 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:52,655 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table of length 61:  å›½å®¶ä½“è‚²æ€»å±€å¹²éƒ¨è°ƒæ•´ä¿¡æ¯ï¼ˆ2018.06.13ï¼‰ ä»»å‘½ï¼šæ®·ç»§çº¢ä¸ºç›´å±æœºå…³çºªå§”å‰¯...
2018-10-27 23:57:52,656 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 105:  ç´¢ å¼• å· 00001854-5/2018-00216 å‘å¸ƒæœºæ„ äººäº‹å¸ å ...
2018-10-27 23:57:52,660 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:57:52,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:57:52,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:57:52,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:57:52,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :13082
2018-10-27 23:57:52,664 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:57:52,665 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:57:52,665 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876153>
None
2018-10-27 23:57:52,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:52,698 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:57:52,698 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:57:52,699 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:57:52,699 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:57:52,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :15405
2018-10-27 23:57:52,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:57:52,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:57:52,701 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876152>
None
2018-10-27 23:57:52,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:52,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table of length 180:  å›½å®¶ä½“è‚²æ€»å±€å¹²éƒ¨è°ƒæ•´ä¿¡æ¯ï¼ˆ2018.07.11ï¼‰ ä»»å‘½ï¼šåˆ˜å®—è¹Ÿä¸ºåŠå…¬å…å‰¯å·¡è§†å‘˜...
2018-10-27 23:57:52,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 105:  ç´¢ å¼• å· 00001854-5/2018-00218 å‘å¸ƒæœºæ„ äººäº‹å¸ å ...
2018-10-27 23:57:52,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:57:52,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:57:52,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:57:52,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:57:52,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :19378
2018-10-27 23:57:52,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:57:52,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:57:52,733 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876151>
None
2018-10-27 23:57:52,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:52,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:57:52,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:57:52,759 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:57:52,759 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:57:52,759 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :22089
2018-10-27 23:57:52,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:57:52,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:57:52,760 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876185>
None
2018-10-27 23:57:52,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:52,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:57:52,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:57:52,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:57:52,796 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:57:52,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :25165
2018-10-27 23:57:52,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:57:52,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:57:52,800 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=876204>
None
2018-10-27 23:57:52,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:57:52,833 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:57:53,095 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9318/n9328/c877448/part/522745.webp.jpg HTTP/1.1" 404 1163
2018-10-27 23:57:53,126 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=877448 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:57:52_522745.webp.jpg'
2018-10-27 23:57:54,110 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:56,146 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:56,157 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:57:56,158 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:56,158 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-10/displayed {"id": "0.7723595768561216-10", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:56,170 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-10/displayed HTTP/1.1" 200 72
2018-10-27 23:57:56,171 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:56,171 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-10/enabled {"id": "0.7723595768561216-10", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:56,179 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-10/enabled HTTP/1.1" 200 72
2018-10-27 23:57:56,180 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:56,181 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-10/click {"id": "0.7723595768561216-10", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:56,216 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-10/click HTTP/1.1" 200 72
2018-10-27 23:57:56,216 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:57,202 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:57:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:57:58,217 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:57:58,226 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115377
2018-10-27 23:57:58,228 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:57:58,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=837436', 'content.jsp?id=837320', 'content.jsp?id=837308', 'content.jsp?id=837080', 'content.jsp?id=836835', 'content.jsp?id=836770', 'content.jsp?id=835494', 'content.jsp?id=835294', 'content.jsp?id=834102', 'content.jsp?id=833943', 'content.jsp?id=833929', 'content.jsp?id=833736', 'content.jsp?id=833616', 'content.jsp?id=833614', 'content.jsp?id=833500', 'content.jsp?id=833497', 'content.jsp?id=833496', 'content.jsp?id=833481', 'content.jsp?id=833278', 'content.jsp?id=833263']
2018-10-27 23:58:00,298 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:00] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:01,261 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:01,273 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:58:01,273 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:01,274 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-11/displayed {"id": "0.7723595768561216-11", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:01,285 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-11/displayed HTTP/1.1" 200 72
2018-10-27 23:58:01,286 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:01,286 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-11/enabled {"id": "0.7723595768561216-11", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:01,294 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-11/enabled HTTP/1.1" 200 72
2018-10-27 23:58:01,295 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:01,295 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-11/click {"id": "0.7723595768561216-11", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:01,326 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-11/click HTTP/1.1" 200 72
2018-10-27 23:58:01,327 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:03,328 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:03,340 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115209
2018-10-27 23:58:03,342 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:03,353 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=564345', 'content.jsp?id=833016', 'content.jsp?id=832917', 'content.jsp?id=832915', 'content.jsp?id=832893', 'content.jsp?id=832886', 'content.jsp?id=832672', 'content.jsp?id=832336', 'content.jsp?id=832034', 'content.jsp?id=832018', 'content.jsp?id=831958', 'content.jsp?id=831954', 'content.jsp?id=773035', 'content.jsp?id=830904', 'content.jsp?id=830905', 'content.jsp?id=830855', 'content.jsp?id=830854', 'content.jsp?id=830691', 'content.jsp?id=830673', 'content.jsp?id=830509']
2018-10-27 23:58:03,356 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=850167 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:03,358 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=850249 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:03,360 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=850853 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:03,362 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=850904 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:03,363 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=851832 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:03,365 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=852189 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:03,367 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=852469 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:03,369 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=852528 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:03,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:03,380 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:03] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:03,398 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:03,511 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9293/n9317/c857400/part/500555.docx HTTP/1.1" 200 20372
2018-10-27 23:58:03,535 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857400 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:03_500555.docx'
2018-10-27 23:58:03,536 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:03,578 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:03,733 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9043/n9053/c857481/part/500619.docx HTTP/1.1" 200 17993
2018-10-27 23:58:03,763 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857481 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:03_500619.docx'
2018-10-27 23:58:03,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:03,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:03,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:03,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:03,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:03,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :28341
2018-10-27 23:58:03,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:03,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:03,800 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857609>
None
2018-10-27 23:58:03,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:03,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:03,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:03,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:03,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:03,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :31442
2018-10-27 23:58:03,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:03,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:03,838 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857782>
None
2018-10-27 23:58:03,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:03,883 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:03,996 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9068/n9078/c857833/part/500958.docx HTTP/1.1" 200 20144
2018-10-27 23:58:04,039 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=857833 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:03_500958.docx'
2018-10-27 23:58:04,040 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:04,086 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:04,254 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9193/n9203/c859428/part/502435.docx HTTP/1.1" 200 13698
2018-10-27 23:58:04,287 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=859428 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:04_502435.docx'
2018-10-27 23:58:04,289 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:04,324 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:04,422 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9143/n9153/c859473/part/502446.doc HTTP/1.1" 200 48640
2018-10-27 23:58:04,477 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=859473 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:04_502446.doc'
2018-10-27 23:58:04,478 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:04,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:04,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:04,527 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:04,527 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:04,527 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :36930
2018-10-27 23:58:04,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:04,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:04,530 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=859840>
None
2018-10-27 23:58:04,543 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 33 pages (at 33 pages/min), scraped 11 items (at 11 items/min)
2018-10-27 23:58:06,468 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:06] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:07,620 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:07,630 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:58:07,631 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:07,631 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-12/displayed {"id": "0.7723595768561216-12", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:07,642 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-12/displayed HTTP/1.1" 200 72
2018-10-27 23:58:07,643 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:07,643 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-12/enabled {"id": "0.7723595768561216-12", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:07,651 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-12/enabled HTTP/1.1" 200 72
2018-10-27 23:58:07,651 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:07,652 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-12/click {"id": "0.7723595768561216-12", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:07,683 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-12/click HTTP/1.1" 200 72
2018-10-27 23:58:07,683 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:09,552 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:09] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:09,684 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:09,693 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115183
2018-10-27 23:58:09,694 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:09,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=830383', 'content.jsp?id=830067', 'content.jsp?id=830069', 'content.jsp?id=830070', 'content.jsp?id=830071', 'content.jsp?id=830072', 'content.jsp?id=830073', 'content.jsp?id=830074', 'content.jsp?id=830075', 'content.jsp?id=830076', 'content.jsp?id=828741', 'content.jsp?id=828510', 'content.jsp?id=828502', 'content.jsp?id=828501', 'content.jsp?id=828397', 'content.jsp?id=827930', 'content.jsp?id=827828', 'content.jsp?id=827751', 'content.jsp?id=827602', 'content.jsp?id=827487']
2018-10-27 23:58:09,705 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=841628 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:09,707 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=841636 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:09,709 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842187 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:09,710 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842231 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:09,712 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842373 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:09,714 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842767 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:09,715 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842931 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:09,717 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=843065 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:09,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:09,749 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:09,980 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9243/n9253/c850167/part/493548.2018%E5%B9%B4%E5%9B%BD%E5%AE%B6%E7%BA%A7%E6%95%99%E7%BB%83%E5%91%98%E5%B2%97%E4%BD%8D%E5%9F%B9%E8%AE%AD%E7%8F%AD%E6%8A%A5%E5%90%8D%E8%A1%A8.doc HTTP/1.1" 404 1163
2018-10-27 23:58:10,008 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=850167 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:09_493548.2018å¹´å›½å®¶çº§æ•™ç»ƒå‘˜å²—ä½åŸ¹è®­ç­æŠ¥åè¡¨.doc'
2018-10-27 23:58:10,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:10,037 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:11,095 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9143/n9153/c850249/part/493640.pdf HTTP/1.1" 200 116159
2018-10-27 23:58:12,018 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=850249 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:10_493640.pdf'
2018-10-27 23:58:12,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:12,045 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:12,096 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9343/n9353/c850853/part/494123.jpg HTTP/1.1" 200 349395
2018-10-27 23:58:12,200 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=850853 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:12_494123.jpg'
2018-10-27 23:58:12,201 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:12,226 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:12,227 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:12,227 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:12,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:12,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :39497
2018-10-27 23:58:12,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:12,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:12,229 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=850904>
None
2018-10-27 23:58:12,230 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:12,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:12,261 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:12,262 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:12,262 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:12,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :42718
2018-10-27 23:58:12,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:12,265 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:12,265 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=851832>
None
2018-10-27 23:58:12,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:12,302 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:12,304 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:12,304 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:12,305 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:12,305 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :45458
2018-10-27 23:58:12,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:12,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:12,307 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=852189>
None
2018-10-27 23:58:12,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:12,343 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:12,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:12,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:12,345 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:12,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :50244
2018-10-27 23:58:12,348 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:12,349 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:12,349 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=852469>
None
2018-10-27 23:58:12,350 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:12,377 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:12,453 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9043/n9053/c852528/part/495613.jpg HTTP/1.1" 200 28844
2018-10-27 23:58:12,490 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=852528 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:12_495613.jpg'
2018-10-27 23:58:12,640 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:12] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:15,554 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:15,564 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:58:15,564 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:15,565 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-13/displayed {"id": "0.7723595768561216-13", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:15,576 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-13/displayed HTTP/1.1" 200 72
2018-10-27 23:58:15,577 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:15,577 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-13/enabled {"id": "0.7723595768561216-13", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:15,585 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-13/enabled HTTP/1.1" 200 72
2018-10-27 23:58:15,586 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:15,586 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-13/click {"id": "0.7723595768561216-13", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:15,618 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-13/click HTTP/1.1" 200 72
2018-10-27 23:58:15,619 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:15,746 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:15] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:17,619 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:17,629 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115104
2018-10-27 23:58:17,631 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:17,640 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=830431', 'content.jsp?id=827194', 'content.jsp?id=827195', 'content.jsp?id=825555', 'content.jsp?id=824548', 'content.jsp?id=824495', 'content.jsp?id=824148', 'content.jsp?id=823970', 'content.jsp?id=823922', 'content.jsp?id=823923', 'content.jsp?id=823448', 'content.jsp?id=823190', 'content.jsp?id=823191', 'content.jsp?id=823115', 'content.jsp?id=822870', 'content.jsp?id=822671', 'content.jsp?id=822276', 'content.jsp?id=822257', 'content.jsp?id=822255', 'content.jsp?id=822022']
2018-10-27 23:58:17,643 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=564345 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:17,645 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833263 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:17,647 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833278 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:17,649 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833481 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:17,650 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833496 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:17,652 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833497 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:17,654 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833500 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:17,655 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833614 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:17,656 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:17,680 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:17,762 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9193/n9203/c841628/part/486764.jpg HTTP/1.1" 200 87027
2018-10-27 23:58:17,841 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=841628 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:17_486764.jpg'
2018-10-27 23:58:17,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:17,880 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:17,881 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:17,881 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:17,882 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:17,882 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :56355
2018-10-27 23:58:17,884 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:17,885 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:17,886 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=841636>
None
2018-10-27 23:58:17,887 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:17,919 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:18,047 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c842187/part/487150.doc HTTP/1.1" 200 46592
2018-10-27 23:58:18,126 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842187 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:17_487150.doc'
2018-10-27 23:58:18,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:18,168 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:18,345 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9193/n9203/c842231/part/487219.xls HTTP/1.1" 200 25088
2018-10-27 23:58:18,388 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842231 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:18_487219.xls'
2018-10-27 23:58:18,389 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:18,419 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:18,580 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9193/n9203/c842373/part/487245.xlsx HTTP/1.1" 200 19973
2018-10-27 23:58:18,657 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842373 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:18_487245.xlsx'
2018-10-27 23:58:18,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:18,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td#tcon.sv14_33>table.MsoNormalTable of length 43: å•ä½åç§°å•ä½åœ°å€é‚®æ”¿ç¼–ç è”ç³»äººè”ç³»ç”µè¯å»ºè®®ç«‹é¡¹ç ”ç©¶åç§°ï¼šå»ºè®®ç«‹é¡¹ç ”ç©¶çš„ä¸»è¦å†…å®¹å’Œ...
2018-10-27 23:58:18,697 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:18,698 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:18,698 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:18,699 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:18,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :61416
2018-10-27 23:58:18,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:18,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:18,702 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842767>
None
2018-10-27 23:58:18,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:18,724 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:18,858 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:18] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:19,637 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9343/n9353/c842931/part/487660.jpg HTTP/1.1" 200 620807
2018-10-27 23:58:21,970 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:21] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:23,978 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=842931 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:18_487660.jpg'
2018-10-27 23:58:23,979 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:24,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:24,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:24,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:24,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:24,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :65360
2018-10-27 23:58:24,008 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:24,009 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:24,009 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=843065>
None
2018-10-27 23:58:25,058 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:25] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:27,025 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:27,036 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:58:27,037 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:27,037 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-14/displayed {"id": "0.7723595768561216-14", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:27,048 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-14/displayed HTTP/1.1" 200 72
2018-10-27 23:58:27,048 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:27,049 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-14/enabled {"id": "0.7723595768561216-14", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:27,056 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-14/enabled HTTP/1.1" 200 72
2018-10-27 23:58:27,056 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:27,056 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-14/click {"id": "0.7723595768561216-14", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:27,086 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-14/click HTTP/1.1" 200 72
2018-10-27 23:58:27,087 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:28,144 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:28] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:29,087 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:29,097 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115344
2018-10-27 23:58:29,099 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:29,108 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=822019', 'content.jsp?id=821922', 'content.jsp?id=821454', 'content.jsp?id=821458', 'content.jsp?id=821457', 'content.jsp?id=821024', 'content.jsp?id=820471', 'content.jsp?id=820472', 'content.jsp?id=820233', 'content.jsp?id=819992', 'content.jsp?id=819988', 'content.jsp?id=819823', 'content.jsp?id=819792', 'content.jsp?id=819790', 'content.jsp?id=819596', 'content.jsp?id=819120', 'content.jsp?id=819014', 'content.jsp?id=818703', 'content.jsp?id=818642', 'content.jsp?id=818442']
2018-10-27 23:58:31,228 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:31] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:32,133 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:32,144 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:58:32,144 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:32,145 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-15/displayed {"id": "0.7723595768561216-15", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:32,156 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-15/displayed HTTP/1.1" 200 72
2018-10-27 23:58:32,157 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:32,157 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-15/enabled {"id": "0.7723595768561216-15", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:32,165 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-15/enabled HTTP/1.1" 200 72
2018-10-27 23:58:32,165 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:32,166 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-15/click {"id": "0.7723595768561216-15", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:32,197 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-15/click HTTP/1.1" 200 72
2018-10-27 23:58:32,198 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:34,199 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:34,211 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115074
2018-10-27 23:58:34,213 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:34,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=818187', 'content.jsp?id=818014', 'content.jsp?id=817831', 'content.jsp?id=817773', 'content.jsp?id=817658', 'content.jsp?id=817621', 'content.jsp?id=817623', 'content.jsp?id=817624', 'content.jsp?id=817511', 'content.jsp?id=817416', 'content.jsp?id=817323', 'content.jsp?id=817324', 'content.jsp?id=816643', 'content.jsp?id=816646', 'content.jsp?id=816504', 'content.jsp?id=816506', 'content.jsp?id=816277', 'content.jsp?id=816041', 'content.jsp?id=816010', 'content.jsp?id=816009']
2018-10-27 23:58:34,225 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830383 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:34,227 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830509 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:34,229 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830673 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:34,231 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830691 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:34,232 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830854 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:34,234 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830855 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:34,236 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830905 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:34,239 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830904 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:34,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:34,274 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:34,361 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:34] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:34,427 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n10471/c564345/part/304805.doc HTTP/1.1" 200 25088
2018-10-27 23:58:34,472 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=564345 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:34_304805.doc'
2018-10-27 23:58:34,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:34,505 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:34,506 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:34,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:34,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:34,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :67436
2018-10-27 23:58:34,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:34,510 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:34,510 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833263>
None
2018-10-27 23:58:34,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:34,555 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:34,556 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:34,556 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:34,557 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:34,558 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :75869
2018-10-27 23:58:34,560 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:34,561 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:34,562 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833278>
None
2018-10-27 23:58:34,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:34,590 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:35,906 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9143/n9153/c833481/part/479489.xlsx HTTP/1.1" 200 15132
2018-10-27 23:58:36,302 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833481 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:34_479489.xlsx'
2018-10-27 23:58:36,303 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:36,329 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:36,361 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c833496/part/479517.jpg HTTP/1.1" 200 95782
2018-10-27 23:58:36,403 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833496 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:36_479517.jpg'
2018-10-27 23:58:36,404 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:36,433 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:36,727 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9093/n9103/c833497/part/479521.xlsx HTTP/1.1" 200 12298
2018-10-27 23:58:36,755 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833497 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:36_479521.xlsx'
2018-10-27 23:58:36,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:36,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:36,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:36,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:36,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:36,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :78489
2018-10-27 23:58:36,787 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:36,787 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:36,787 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833500>
None
2018-10-27 23:58:36,788 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:36,814 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:36,888 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c833614/part/479572.jpg HTTP/1.1" 200 308772
2018-10-27 23:58:37,035 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=833614 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:36_479572.jpg'
2018-10-27 23:58:37,510 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:37] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:40,091 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:40,098 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:58:40,099 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:40,099 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-16/displayed {"id": "0.7723595768561216-16", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:40,109 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-16/displayed HTTP/1.1" 200 72
2018-10-27 23:58:40,110 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:40,110 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-16/enabled {"id": "0.7723595768561216-16", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:40,117 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-16/enabled HTTP/1.1" 200 72
2018-10-27 23:58:40,118 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:40,118 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-16/click {"id": "0.7723595768561216-16", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:40,149 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-16/click HTTP/1.1" 200 72
2018-10-27 23:58:40,150 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:40,607 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:40] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:42,150 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:42,159 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115611
2018-10-27 23:58:42,161 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:42,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=815936', 'content.jsp?id=815928', 'content.jsp?id=815623', 'content.jsp?id=815473', 'content.jsp?id=815474', 'content.jsp?id=814884', 'content.jsp?id=814863', 'content.jsp?id=814636', 'content.jsp?id=814437', 'content.jsp?id=818189', 'content.jsp?id=814348', 'content.jsp?id=814338', 'content.jsp?id=814342', 'content.jsp?id=813844', 'content.jsp?id=813751', 'content.jsp?id=813443', 'content.jsp?id=813371', 'content.jsp?id=813230', 'content.jsp?id=813228', 'content.jsp?id=813083']
2018-10-27 23:58:42,172 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830431 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:42,173 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827487 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:42,175 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827602 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:42,177 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827751 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:42,178 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827828 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:42,180 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827930 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:42,182 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=828397 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:42,182 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:42,207 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:42,208 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:42,208 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:42,208 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:42,209 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :81578
2018-10-27 23:58:42,210 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:42,211 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:42,211 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830383>
None
2018-10-27 23:58:42,211 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:42,234 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:42,382 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9193/n9203/c830509/part/475739.xlsx HTTP/1.1" 200 9937
2018-10-27 23:58:42,407 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830509 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:42_475739.xlsx'
2018-10-27 23:58:42,409 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:42,439 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:42,507 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c830673/part/475872.jpg HTTP/1.1" 200 371387
2018-10-27 23:58:42,685 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830673 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:42_475872.jpg'
2018-10-27 23:58:42,687 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:42,726 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:42,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:42,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:42,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:42,729 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :109108
2018-10-27 23:58:42,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:42,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:42,731 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830691>
None
2018-10-27 23:58:42,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:42,757 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:42,757 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:42,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:42,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:42,759 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :113740
2018-10-27 23:58:42,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:42,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:42,761 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830854>
None
2018-10-27 23:58:42,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:42,793 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:43,020 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c830855/part/476108.doc HTTP/1.1" 200 39936
2018-10-27 23:58:43,124 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830855 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:42_476108.doc'
2018-10-27 23:58:43,125 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:43,157 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): kjs.sport.gov.cn:80
2018-10-27 23:58:43,419 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://kjs.sport.gov.cn:80 "GET /n5081/c813368/part/460074.doc HTTP/1.1" 200 81920
2018-10-27 23:58:43,516 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830905 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:43_460074.doc'
2018-10-27 23:58:43,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:43,551 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:43,719 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:43] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:43,720 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9243/n9253/c830904/part/476146.docx HTTP/1.1" 200 45221
2018-10-27 23:58:43,789 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830904 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:43_476146.docx'
2018-10-27 23:58:46,806 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:46,813 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:46] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:46,815 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:58:46,816 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:46,816 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-17/displayed {"id": "0.7723595768561216-17", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:46,830 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-17/displayed HTTP/1.1" 200 72
2018-10-27 23:58:46,831 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:46,831 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-17/enabled {"id": "0.7723595768561216-17", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:46,840 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-17/enabled HTTP/1.1" 200 72
2018-10-27 23:58:46,840 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:46,841 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-17/click {"id": "0.7723595768561216-17", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:46,876 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-17/click HTTP/1.1" 200 72
2018-10-27 23:58:46,876 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:48,878 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:48,890 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115746
2018-10-27 23:58:48,892 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:48,901 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=812961', 'content.jsp?id=812931', 'content.jsp?id=812930', 'content.jsp?id=812776', 'content.jsp?id=812777', 'content.jsp?id=812371', 'content.jsp?id=812372', 'content.jsp?id=811788', 'content.jsp?id=811770', 'content.jsp?id=811238', 'content.jsp?id=806954', 'content.jsp?id=806903', 'content.jsp?id=806705', 'content.jsp?id=806703', 'content.jsp?id=806255', 'content.jsp?id=806153', 'content.jsp?id=805957', 'content.jsp?id=805849', 'content.jsp?id=805398', 'content.jsp?id=805395']
2018-10-27 23:58:48,905 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=828501 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:49,913 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:49] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:51,932 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:51,938 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:58:51,939 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:51,939 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-18/displayed {"id": "0.7723595768561216-18", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:51,952 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-18/displayed HTTP/1.1" 200 72
2018-10-27 23:58:51,952 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:51,952 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-18/enabled {"id": "0.7723595768561216-18", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:51,963 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-18/enabled HTTP/1.1" 200 72
2018-10-27 23:58:51,963 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:51,963 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-18/click {"id": "0.7723595768561216-18", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:51,995 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-18/click HTTP/1.1" 200 72
2018-10-27 23:58:51,996 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:53,015 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:53] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:53,998 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:54,010 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115063
2018-10-27 23:58:54,012 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:54,022 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=805396', 'content.jsp?id=805049', 'content.jsp?id=805041', 'content.jsp?id=804835', 'content.jsp?id=804538', 'content.jsp?id=804286', 'content.jsp?id=804287', 'content.jsp?id=804027', 'content.jsp?id=804026', 'content.jsp?id=818190', 'content.jsp?id=803825', 'content.jsp?id=801316', 'content.jsp?id=803432', 'content.jsp?id=803234', 'content.jsp?id=802518', 'content.jsp?id=802375', 'content.jsp?id=802282', 'content.jsp?id=801796', 'content.jsp?id=801703', 'content.jsp?id=801588']
2018-10-27 23:58:54,024 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=818187 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:54,026 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=818442 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:54,028 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=818703 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:54,030 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=819014 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:54,032 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=819120 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:54,034 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=819596 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:58:54,034 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:54,058 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:54,106 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c830431/part/475638.JPG HTTP/1.1" 200 134575
2018-10-27 23:58:54,183 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=830431 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:54_475638.JPG'
2018-10-27 23:58:54,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:54,210 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:54,273 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c827487/part/472963.jpg HTTP/1.1" 200 89162
2018-10-27 23:58:54,336 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827487 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:54_472963.jpg'
2018-10-27 23:58:54,337 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:54,370 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:54,691 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c827602/part/473111.doc HTTP/1.1" 200 36352
2018-10-27 23:58:54,796 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827602 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:54_473111.doc'
2018-10-27 23:58:54,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:54,830 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:54,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:54,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:54,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:54,832 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :122041
2018-10-27 23:58:54,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:54,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:54,834 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827751>
None
2018-10-27 23:58:54,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:54,864 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:55,040 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9293/n9303/c827828/part/473226.%E4%BD%93%E8%82%B2%E6%80%BB%E5%B1%80%E5%AE%9A%E7%82%B9%E6%89%B6%E8%B4%AB%E6%8D%90%E8%B5%A0%E6%AC%BE%E7%89%A9%E7%BB%9F%E8%AE%A1%E8%A1%A8.docx HTTP/1.1" 404 1163
2018-10-27 23:58:55,062 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827828 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:54_473226.ä½“è‚²æ€»å±€å®šç‚¹æ‰¶è´«æèµ æ¬¾ç‰©ç»Ÿè®¡è¡¨.docx'
2018-10-27 23:58:55,063 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:55,085 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td#tcon.sv14_33>table of length 22: ä½“è‚²æ€»å±€å‰¯å±€é•¿ã€å…šç»„å‰¯ä¹¦è®°æ¨æ ‘å®‰è®²è¯ä¼šè®®ç°åœº
2018-10-27 23:58:55,087 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:58:55,198 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9043/n9053/c827930/part/473305.jpg HTTP/1.1" 200 41331
2018-10-27 23:58:55,239 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=827930 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:58:55_473305.jpg'
2018-10-27 23:58:55,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:55,277 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:55,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:55,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:55,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:55,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :127287
2018-10-27 23:58:55,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:55,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:55,283 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=828397>
None
2018-10-27 23:58:55,327 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:58:55,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:58:55,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:58:55,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:58:55,414 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:58:55,414 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :161050
2018-10-27 23:58:55,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:58:55,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:58:55,417 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=828501>
None
2018-10-27 23:58:56,118 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:56] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:58:58,421 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:58,431 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:58:58,431 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:58,432 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-19/displayed {"id": "0.7723595768561216-19", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:58,443 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-19/displayed HTTP/1.1" 200 72
2018-10-27 23:58:58,444 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:58,444 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-19/enabled {"id": "0.7723595768561216-19", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:58,452 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-19/enabled HTTP/1.1" 200 72
2018-10-27 23:58:58,452 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:58,453 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-19/click {"id": "0.7723595768561216-19", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:58:58,483 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-19/click HTTP/1.1" 200 72
2018-10-27 23:58:58,484 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:58:59,211 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:58:59] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:59:00,485 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:00,498 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 114669
2018-10-27 23:59:00,500 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:00,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=801362', 'content.jsp?id=801360', 'content.jsp?id=801095', 'content.jsp?id=801094', 'content.jsp?id=801093', 'content.jsp?id=800845', 'content.jsp?id=800830', 'content.jsp?id=818191', 'content.jsp?id=800525', 'content.jsp?id=800265', 'content.jsp?id=800258', 'content.jsp?id=800248', 'content.jsp?id=800255', 'content.jsp?id=800143', 'content.jsp?id=800034', 'content.jsp?id=799984', 'content.jsp?id=799926', 'content.jsp?id=818192', 'content.jsp?id=798162', 'content.jsp?id=798019']
2018-10-27 23:59:00,512 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=815936 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:00,514 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816009 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:00,517 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=818642 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:00,519 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816010 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:00,521 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816277 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:00,523 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816506 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:00,525 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=819790 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:00,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:00,552 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table of length 252:  å›½å®¶ä½“è‚²æ€»å±€äººäº‹ä»»å… å›½å®¶ä½“è‚²æ€»å±€å¹²éƒ¨è°ƒæ•´ä¿¡æ¯ï¼š ä»»å‘½ï¼š å¾ç¿”é¸¿ä¸ºåŠå…¬å…å‰¯ä¸»ä»»...
2018-10-27 23:59:00,553 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td{01}>table.sv14_33 of length 91:  ç´¢ å¼• å· 00001854-5/2017-00231 å‘å¸ƒæœºæ„ äººäº‹å¸ å ...
2018-10-27 23:59:00,561 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:00,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:00,563 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:00,563 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:00,564 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :165450
2018-10-27 23:59:00,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:00,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:00,567 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=818187>
None
2018-10-27 23:59:00,567 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:00,603 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:00,604 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:00,605 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:00,605 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:00,606 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :167751
2018-10-27 23:59:00,608 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:00,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:00,609 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=818442>
None
2018-10-27 23:59:00,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:00,640 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:00,642 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:00,642 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:00,642 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:00,643 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :171986
2018-10-27 23:59:00,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:00,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:00,646 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=818703>
None
2018-10-27 23:59:00,646 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:00,684 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:59:00,826 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9068/n9078/c819014/part/465721.xlsx HTTP/1.1" 200 16018
2018-10-27 23:59:00,912 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=819014 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:59:00_465721.xlsx'
2018-10-27 23:59:00,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:00,944 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:59:01,090 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9043/n9053/c819120/part/465823.docx HTTP/1.1" 200 14582
2018-10-27 23:59:01,126 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=819120 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:59:00_465823.docx'
2018-10-27 23:59:01,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:01,159 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:01,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:01,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:01,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:01,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :180216
2018-10-27 23:59:01,164 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:01,165 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:01,165 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=819596>
None
2018-10-27 23:59:03,299 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [27/Oct/2018 23:59:03] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-27 23:59:04,184 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:04,199 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:59:04,199 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:04,200 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-20/displayed {"id": "0.7723595768561216-20", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:04,211 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-20/displayed HTTP/1.1" 200 72
2018-10-27 23:59:04,212 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:04,212 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-20/enabled {"id": "0.7723595768561216-20", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:04,219 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-20/enabled HTTP/1.1" 200 72
2018-10-27 23:59:04,220 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:04,220 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-20/click {"id": "0.7723595768561216-20", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:04,250 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-20/click HTTP/1.1" 200 72
2018-10-27 23:59:04,251 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:06,252 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:06,264 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115142
2018-10-27 23:59:06,266 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:06,276 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=798020', 'content.jsp?id=797748', 'content.jsp?id=797505', 'content.jsp?id=797495', 'content.jsp?id=797496', 'content.jsp?id=797351', 'content.jsp?id=796902', 'content.jsp?id=796849', 'content.jsp?id=796616', 'content.jsp?id=796168', 'content.jsp?id=795946', 'content.jsp?id=795824', 'content.jsp?id=795622', 'content.jsp?id=795611', 'content.jsp?id=795360', 'content.jsp?id=795325', 'content.jsp?id=795209', 'content.jsp?id=794810', 'content.jsp?id=794552', 'content.jsp?id=794402']
2018-10-27 23:59:06,280 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816041 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:06,294 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 79 pages (at 46 pages/min), scraped 31 items (at 20 items/min)
2018-10-27 23:59:09,304 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:09,314 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:59:09,315 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:09,315 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-21/displayed {"id": "0.7723595768561216-21", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:09,327 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-21/displayed HTTP/1.1" 200 72
2018-10-27 23:59:09,327 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:09,328 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-21/enabled {"id": "0.7723595768561216-21", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:09,335 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-21/enabled HTTP/1.1" 200 72
2018-10-27 23:59:09,336 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:09,336 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-21/click {"id": "0.7723595768561216-21", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:09,367 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-21/click HTTP/1.1" 200 72
2018-10-27 23:59:09,368 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:11,369 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:11,382 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115447
2018-10-27 23:59:11,384 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:11,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=794401', 'content.jsp?id=794317', 'content.jsp?id=794181', 'content.jsp?id=793850', 'content.jsp?id=793709', 'content.jsp?id=793710', 'content.jsp?id=793625', 'content.jsp?id=793617', 'content.jsp?id=793615', 'content.jsp?id=793616', 'content.jsp?id=793345', 'content.jsp?id=793260', 'content.jsp?id=793254', 'content.jsp?id=792143', 'content.jsp?id=791999', 'content.jsp?id=791791', 'content.jsp?id=791787', 'content.jsp?id=791449', 'content.jsp?id=790162', 'content.jsp?id=790002']
2018-10-27 23:59:11,396 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816504 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:11,398 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=812961 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:11,399 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=805396 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:11,401 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=805398 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:11,403 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=805849 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:11,405 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=805957 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:11,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:11,433 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:59:11,589 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9093/n9103/c815936/part/462475.pdf HTTP/1.1" 200 82370
2018-10-27 23:59:11,654 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=815936 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:59:11_462475.pdf'
2018-10-27 23:59:11,655 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:11,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:11,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:11,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:11,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:11,706 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :182327
2018-10-27 23:59:11,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:11,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:11,711 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816009>
None
2018-10-27 23:59:11,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:11,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td#tcon.sv14_33>table.MsoNormalTable of length 184: å‚ä¸å­¦è€…å• ä½è®ºæ–‡é¢˜ç›®æ¢ ä¼Ÿæš¨å—å¤§å­¦ä½“è‚²å­¦é™¢â€œæ„åœ¨å•†ä¸šï¼Œè€Œéè¶³çƒâ€â€”â€”ä¸­å›½èŒä¸šè¶³...
2018-10-27 23:59:11,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td#tcon.sv14_33>table.MsoNormalTable of length 123: å‚ä¸å­¦è€…å• ä½è®ºæ–‡é¢˜ç›®æ¢ç«‹å¯å¹¿ä¸œæ¹›æ±Ÿå²­å—å¸ˆèŒƒå­¦é™¢æˆ‘å›½ä½“è‚²è¯è¯­æƒçš„äº§ç”ŸåŸºç¡€ä¸æœ‰æ•ˆå‘...
2018-10-27 23:59:11,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td#tcon.sv14_33>table.MsoNormalTable of length 140: å‚ä¸å­¦è€…å• ä½è®ºæ–‡é¢˜ç›®å­”è‡³è¾¾ä¸­å›½è¶³çƒåä¼šå…¨é¢â€œè¶³æ”¹â€ã€ç²¾å‡†â€œè¶³æ”¹â€é«˜å¤æœ‹æ€»å±€å°çƒ...
2018-10-27 23:59:11,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td#tcon.sv14_33>table.MsoNormalTable of length 167: å‚ä¸å­¦è€…å• ä½è®ºæ–‡é¢˜ç›®é©¬å¾·æµ©åä¸œå¸ˆèŒƒå¤§å­¦è·¨åŸŸæ²»ç†ï¼šæˆ‘å›½åŒºåŸŸå…¬å…±ä½“è‚²æœåŠ¡åè°ƒå‘å±•çš„...
2018-10-27 23:59:11,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td#tcon.sv14_33>table.MsoNormalTable of length 127: å‚ä¸å­¦è€…å• ä½è®ºæ–‡é¢˜ç›®æ¨ä¸½å¨œé™•è¥¿å¸ˆèŒƒå¤§å­¦å¥åº·ä¸­å›½â€œä½“åŒ»ç»“åˆâ€è‡³â€œä½“åŒ»èåˆâ€çš„æ¨¡å¼...
2018-10-27 23:59:11,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td#tcon.sv14_33>table.MsoNormalTable of length 179: æ—¶é—´å®‰æ’8æœˆ24æ—¥8:30-9:00å¼€å¹•å¼9:00-10:20ä¸“é¢˜ä¸€10:20-...
2018-10-27 23:59:11,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:11,877 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:11,877 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:11,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:11,879 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :218448
2018-10-27 23:59:11,885 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:11,886 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:11,886 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=818642>
None
2018-10-27 23:59:11,887 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:11,929 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:11,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:11,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:11,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:11,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :225035
2018-10-27 23:59:11,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:11,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:11,936 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816010>
None
2018-10-27 23:59:11,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:11,969 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:11,971 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:11,971 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:11,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:11,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :229885
2018-10-27 23:59:11,975 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:11,976 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:11,976 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816277>
None
2018-10-27 23:59:11,976 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:12,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:12,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:12,008 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:12,008 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:12,009 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :234242
2018-10-27 23:59:12,012 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:12,012 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:12,012 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816506>
None
2018-10-27 23:59:12,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:12,046 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:12,047 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:12,048 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:12,048 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:12,049 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :241107
2018-10-27 23:59:12,052 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:12,052 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:12,053 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=819790>
None
2018-10-27 23:59:15,068 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:15,079 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:59:15,079 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:15,080 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-22/displayed {"id": "0.7723595768561216-22", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:15,091 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-22/displayed HTTP/1.1" 200 72
2018-10-27 23:59:15,092 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:15,092 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-22/enabled {"id": "0.7723595768561216-22", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:15,100 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-22/enabled HTTP/1.1" 200 72
2018-10-27 23:59:15,100 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:15,101 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-22/click {"id": "0.7723595768561216-22", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:15,133 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-22/click HTTP/1.1" 200 72
2018-10-27 23:59:15,133 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:17,134 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:17,147 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 115092
2018-10-27 23:59:17,149 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:17,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=789992', 'content.jsp?id=789812', 'content.jsp?id=789806', 'content.jsp?id=789561', 'content.jsp?id=789355', 'content.jsp?id=788949', 'content.jsp?id=788942', 'content.jsp?id=788876', 'content.jsp?id=788570', 'content.jsp?id=788565', 'content.jsp?id=788562', 'content.jsp?id=788187', 'content.jsp?id=788016', 'content.jsp?id=788094', 'content.jsp?id=785872', 'content.jsp?id=785790', 'content.jsp?id=785298', 'content.jsp?id=785227', 'content.jsp?id=785221', 'content.jsp?id=785219']
2018-10-27 23:59:17,161 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=805395 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:17,163 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=806153 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:17,210 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:17,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td#tcon.sv14_33>table.MsoNormalTable of length 758: é¡¹ç›®åç§°ç­”è¾©æ—¶é—´å§“ åå·¥ä½œå•ä½ä½“è‚²ç‰¹è‰²å°é•‡å»ºè®¾è·¯å¾„ç ”ç©¶8:00-8:18æ¨ æ˜æ­...
2018-10-27 23:59:17,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:17,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:17,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:17,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:17,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :267123
2018-10-27 23:59:17,315 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:17,315 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:17,316 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816041>
None
2018-10-27 23:59:20,324 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:20,334 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:59:20,335 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:20,335 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-23/displayed {"id": "0.7723595768561216-23", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:20,347 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-23/displayed HTTP/1.1" 200 72
2018-10-27 23:59:20,347 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:20,348 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-23/enabled {"id": "0.7723595768561216-23", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:20,355 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-23/enabled HTTP/1.1" 200 72
2018-10-27 23:59:20,356 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:20,356 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-23/click {"id": "0.7723595768561216-23", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:20,387 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-23/click HTTP/1.1" 200 72
2018-10-27 23:59:20,388 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:22,389 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/source {"sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:22,403 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/source HTTP/1.1" 200 114759
2018-10-27 23:59:22,405 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:22,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/seleniumSpider.py[line:126] - DEBUG: urls: ['content.jsp?id=785036', 'content.jsp?id=784141', 'content.jsp?id=784139', 'content.jsp?id=784095', 'content.jsp?id=784048', 'content.jsp?id=783978', 'content.jsp?id=783955', 'content.jsp?id=783949', 'content.jsp?id=783953', 'content.jsp?id=783947', 'content.jsp?id=783962', 'content.jsp?id=783354', 'content.jsp?id=783065', 'content.jsp?id=782678', 'content.jsp?id=782461', 'content.jsp?id=782462', 'content.jsp?id=782107', 'content.jsp?id=781886', 'content.jsp?id=781503', 'content.jsp?id=781312']
2018-10-27 23:59:22,421 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=801588 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:22,424 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=801703 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:22,426 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=801796 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:22,428 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=802282 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:22,430 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=802375 via http://localhost:8050/execute> (referer: None)
2018-10-27 23:59:22,431 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:22,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:22,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:22,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:22,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:22,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :271116
2018-10-27 23:59:22,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:22,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:22,475 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=816504>
None
2018-10-27 23:59:22,476 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:22,499 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:59:22,647 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9093/n9103/c812961/part/459752.docx HTTP/1.1" 200 24820
2018-10-27 23:59:22,687 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=812961 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:59:22_459752.docx'
2018-10-27 23:59:22,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:22,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:22,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:22,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:22,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:22,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :280452
2018-10-27 23:59:22,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:22,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:22,741 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=805396>
None
2018-10-27 23:59:22,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:22,776 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-27 23:59:22,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-27 23:59:22,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-27 23:59:22,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:28889
2018-10-27 23:59:22,779 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :282851
2018-10-27 23:59:22,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-27 23:59:22,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-27 23:59:22,784 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=805398>
None
2018-10-27 23:59:22,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:22,816 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:59:22,850 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9068/n9078/c805849/part/453543.jpg HTTP/1.1" 200 59455
2018-10-27 23:59:22,892 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=805849 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 63, in dealWithText
    self.downloadFile(img_url, img_name)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:59:22_453543.jpg'
2018-10-27 23:59:22,893 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-27 23:59:22,924 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:205] - DEBUG: Starting new HTTP connection (1): www.sport.gov.cn:80
2018-10-27 23:59:23,220 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://www.sport.gov.cn:80 "GET /n315/n9041/n9042/n9118/n9128/c805957/part/453711.doc HTTP/1.1" 200 37888
2018-10-27 23:59:23,325 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:158] - ERROR: Spider error processing <GET http://gkml.sport.gov.cn:8880/gdnps/content.jsp?id=805957 via http://localhost:8050/execute> (referer: None)
Traceback (most recent call last):
  File "/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/anaconda3/lib/python3.6/site-packages/scrapy_splash/middleware.py", line 156, in process_spider_output
    for el in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 304, in con_parse
    mytitle, myarticle = self.getTitleAndText(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py", line 466, in getTitleAndText
    myarticle = article.getArticleWithAttachment(response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 15, in getArticleWithAttachment
    dict_file = self.dealWithText(myArticle, response)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 49, in dealWithText
    self.downloadFile(url, filename)
  File "/Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/AticleWithAttachment.py", line 21, in downloadFile
    with open(DOWNLOAD_LOCATION + filename, 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/myuser/file/2018-10-27 23:59:22_453711.doc'
2018-10-27 23:59:26,344 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element {"using": "xpath", "value": "//a[contains(text(), \"\u4e0b\u9875\") or contains(text(), \"\u4e0b\u4e00\u9875\")]", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:26,354 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element HTTP/1.1" 200 103
2018-10-27 23:59:26,355 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:26,355 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-24/displayed {"id": "0.7723595768561216-24", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:26,366 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-24/displayed HTTP/1.1" 200 72
2018-10-27 23:59:26,367 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:26,367 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: GET http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-24/enabled {"id": "0.7723595768561216-24", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:26,375 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "GET /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-24/enabled HTTP/1.1" 200 72
2018-10-27 23:59:26,375 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:26,376 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:389] - DEBUG: POST http://127.0.0.1:64592/session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-24/click {"id": "0.7723595768561216-24", "sessionId": "e54c35b376f1bbc243afc6c4024ff3da"}
2018-10-27 23:59:26,409 - /anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py[line:393] - DEBUG: http://127.0.0.1:64592 "POST /session/e54c35b376f1bbc243afc6c4024ff3da/element/0.7723595768561216-24/click HTTP/1.1" 200 72
2018-10-27 23:59:26,410 - /anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py[line:440] - DEBUG: Finished Request
2018-10-27 23:59:28,012 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-27 23:59:28,074 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-28 00:03:17,186 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:03:22,210 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:22] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:03:25,353 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:25] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:03:36,120 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:36] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:03:36,268 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:03:36,374 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:03:36,395 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:03:36,400 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:03:36,430 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:03:36,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:03:36,521 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:03:36,523 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:03:36,552 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:03:36,553 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:03:36,559 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:03:36,560 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:03:39,363 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:03:42,445 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:03:43,108 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:03:43,316 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:43,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:43,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:43,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:43,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:43,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :38621
2018-10-28 00:03:43,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:43,472 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:43,472 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:03:43,577 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,587 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,616 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,621 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,680 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:43,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:43,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:43,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:43,717 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:43,717 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :45736
2018-10-28 00:03:43,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:43,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:43,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:03:43,721 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,724 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:43,759 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:43,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:43,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:43,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:43,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :63826
2018-10-28 00:03:43,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:43,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:43,763 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:03:43,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:43,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:43,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:43,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:43,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:43,807 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :99874
2018-10-28 00:03:43,809 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:43,809 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:43,810 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:03:43,813 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,816 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,818 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:43,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:43,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:43,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:43,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:43,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :118251
2018-10-28 00:03:43,866 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:43,866 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:43,867 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:03:43,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:43,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:43,923 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:43,923 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:43,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:43,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :150464
2018-10-28 00:03:43,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:43,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:43,928 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:03:43,930 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,932 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:43,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:03:43,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:43,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:43,989 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:43,989 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:43,989 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :230129
2018-10-28 00:03:43,993 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:43,993 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:43,993 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:03:43,997 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,998 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:43,999 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,048 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,052 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,053 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :264171
2018-10-28 00:03:44,060 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,062 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,062 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:03:44,063 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,142 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,144 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :348580
2018-10-28 00:03:44,152 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,152 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,152 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:03:44,154 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:44,155 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:44,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,213 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,217 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :357927
2018-10-28 00:03:44,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,223 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,223 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:03:44,223 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,285 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :391275
2018-10-28 00:03:44,305 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,306 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:03:44,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :397198
2018-10-28 00:03:44,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,381 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:03:44,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,430 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,431 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,431 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,432 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :427970
2018-10-28 00:03:44,438 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,439 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:03:44,441 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:44,442 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:44,443 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:44,448 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,503 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,510 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :462889
2018-10-28 00:03:44,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,524 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:03:44,527 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,596 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :496061
2018-10-28 00:03:44,608 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,609 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:03:44,610 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:44,615 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,663 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :524628
2018-10-28 00:03:44,670 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,671 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:03:44,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,748 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:03:44,792 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :586362
2018-10-28 00:03:44,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,824 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:03:44,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,874 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,877 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,880 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :608592
2018-10-28 00:03:44,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,890 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:03:44,895 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:44,945 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:44,949 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:44,949 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:44,950 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:44,951 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :640395
2018-10-28 00:03:44,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:44,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:44,961 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:03:45,004 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:03:45,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:03:45,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:03:45,337 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:03:45,338 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:03:45,338 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:03:45,340 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:03:45,349 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:03:45,350 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:03:45,350 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:03:45,549 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:03:48,357 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:03:48,359 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:48] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:03:48,409 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:48] "[37mGET /results%3Fid%3D38341 HTTP/1.1[0m" 200 -
2018-10-28 00:03:51,496 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:51] "[37mPOST /results%3Fid%3D38341 HTTP/1.1[0m" 200 -
2018-10-28 00:03:54,579 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:54] "[37mPOST /results%3Fid%3D38341 HTTP/1.1[0m" 200 -
2018-10-28 00:03:57,687 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:03:57] "[37mPOST /results%3Fid%3D38341 HTTP/1.1[0m" 200 -
2018-10-28 00:04:00,821 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:04:00] "[37mPOST /results%3Fid%3D38341 HTTP/1.1[0m" 200 -
2018-10-28 00:04:01,892 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:04:01] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:04:06,090 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:04:06,245 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,266 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,348 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:04:06,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 1947:  æ–°åç¤¾åŒ—äº¬4æœˆ28æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘äº†ã€Šå…³äºå»ºç«‹è´«å›°...
2018-10-28 00:04:06,378 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:04:06,379 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:04:06,379 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:04:06,379 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:38341
2018-10-28 00:04:06,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :12921
2018-10-28 00:04:06,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:04:06,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:04:06,381 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm>
None
2018-10-28 00:04:06,385 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:04:06,515 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,523 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,525 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,530 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,536 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,622 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,627 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,672 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,678 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,712 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,823 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,837 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,845 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:06,976 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:07,064 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:04:19,169 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:04:19,283 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:04:19,283 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:04:19,284 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17804,
 'downloader/request_count': 40,
 'downloader/request_method_count/GET': 37,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1408154,
 'downloader/response_count': 40,
 'downloader/response_status_count/200': 40,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 4, 19, 283137),
 'item_scraped_count': 21,
 'log_count/DEBUG': 129,
 'log_count/INFO': 114,
 'memusage/max': 64176128,
 'memusage/startup': 64176128,
 'request_depth_max': 3,
 'response_received_count': 40,
 'scheduler/dequeued': 43,
 'scheduler/dequeued/memory': 43,
 'scheduler/enqueued': 67,
 'scheduler/enqueued/memory': 67,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 3,
 'start_time': datetime.datetime(2018, 10, 27, 16, 3, 36, 559170)}
2018-10-28 00:04:19,284 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:06:21,216 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:06:25,499 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:25] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:06:27,816 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:27] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:06:36,197 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:36] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:06:36,289 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:06:36,445 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:06:36,461 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:06:36,466 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:06:36,493 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:06:36,530 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:06:36,597 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:06:36,600 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:06:36,629 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:06:36,629 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:06:36,635 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:06:36,636 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:06:39,382 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:06:42,509 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:06:43,990 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:06:44,167 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,182 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,184 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,186 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,188 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,190 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,191 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,201 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,233 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,239 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,241 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,245 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,248 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,249 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,251 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,261 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,320 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,320 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,321 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :18788
2018-10-28 00:06:44,322 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,322 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,322 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:06:44,324 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,325 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,326 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :47355
2018-10-28 00:06:44,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,370 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:06:44,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,406 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,406 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,407 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,407 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :78127
2018-10-28 00:06:44,409 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,409 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,409 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:06:44,410 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,452 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,454 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,454 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :114175
2018-10-28 00:06:44,458 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,459 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,459 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:06:44,460 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,503 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,506 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :147347
2018-10-28 00:06:44,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,512 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,512 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:06:44,513 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,570 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,571 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,571 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,571 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,572 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :156694
2018-10-28 00:06:44,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,575 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:06:44,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,624 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:06:44,633 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,635 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,637 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :236359
2018-10-28 00:06:44,643 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,643 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,644 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:06:44,644 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,706 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :270401
2018-10-28 00:06:44,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,714 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,714 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:06:44,718 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:44,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,786 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :288778
2018-10-28 00:06:44,791 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,791 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,792 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:06:44,792 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :322126
2018-10-28 00:06:44,853 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,854 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:06:44,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,926 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,933 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :360049
2018-10-28 00:06:44,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:44,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:44,945 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:06:44,945 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:44,992 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:44,994 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:44,994 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:44,995 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:44,996 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :392262
2018-10-28 00:06:45,002 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:45,002 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:45,002 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:06:45,003 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:45,232 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:45,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:45,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:45,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:45,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :456214
2018-10-28 00:06:45,241 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:45,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:45,242 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:06:45,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:45,283 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:45,285 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:45,285 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:45,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:45,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :478444
2018-10-28 00:06:45,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:45,294 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:45,294 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:06:45,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:45,341 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:45,343 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:45,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:45,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:45,345 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :513363
2018-10-28 00:06:45,353 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:45,353 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:45,353 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:06:45,354 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:45,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:45,390 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:45,391 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:45,391 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:45,392 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :519286
2018-10-28 00:06:45,398 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:45,399 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:45,399 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:06:45,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:45,476 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:45,480 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:45,480 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:45,481 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:45,486 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :603695
2018-10-28 00:06:45,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:45,499 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:45,499 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:06:45,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:45,574 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:45,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:45,577 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:45,577 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:45,579 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :610810
2018-10-28 00:06:45,589 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:45,589 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:45,590 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:06:45,590 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:45,615 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:06:45,641 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:45,644 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:45,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:45,646 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:45,648 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :642613
2018-10-28 00:06:45,658 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:45,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:45,659 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:06:45,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:45,790 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:06:45,813 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:45,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:45,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:45,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:45,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:06:45,829 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:06:45,830 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:45,830 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:06:46,516 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:06:46,517 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:46] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:06:46,562 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:46] "[37mGET /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:06:49,651 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:49] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:06:52,780 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:52] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:06:53,973 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:06:54,118 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,122 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,133 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,135 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,137 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,139 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,151 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,154 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,168 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,170 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,172 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,180 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,186 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,193 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,195 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,198 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,200 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,221 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:06:54,251 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 3132:  ä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘ ã€Šå…³äºåšå¥½æ–°æ—¶æœŸæ•™è‚²å¯¹å¤–å¼€æ”¾å·¥ä½œçš„è‹¥å¹²æ„è§ã€‹...
2018-10-28 00:06:54,252 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:06:54,254 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:06:54,254 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:06:54,255 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:85605
2018-10-28 00:06:54,255 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :19917
2018-10-28 00:06:54,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:06:54,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:06:54,259 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm>
None
2018-10-28 00:06:54,267 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:06:54,437 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,598 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:54,850 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:06:55,863 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:55] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:06:58,946 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:06:58] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:02,041 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:02] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:05,127 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:05] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:08,206 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:08] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:11,302 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:11] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:14,390 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:14] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:17,476 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:17] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:20,563 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:20] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:23,935 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:23] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:24,136 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (failed 1 times): 504 Gateway Time-out
2018-10-28 00:07:24,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:07:24,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:07:24,139 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 19363,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 40,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1496242,
 'downloader/response_count': 43,
 'downloader/response_status_count/200': 42,
 'downloader/response_status_count/504': 1,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 7, 24, 137690),
 'item_scraped_count': 21,
 'log_count/DEBUG': 132,
 'log_count/INFO': 114,
 'memusage/max': 63799296,
 'memusage/startup': 63799296,
 'request_depth_max': 2,
 'response_received_count': 42,
 'retry/count': 1,
 'retry/reason_count/504 Gateway Time-out': 1,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 47,
 'scheduler/enqueued/memory': 47,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 2,
 'splash/execute/response_count/504': 1,
 'start_time': datetime.datetime(2018, 10, 27, 16, 6, 36, 635014)}
2018-10-28 00:07:24,139 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:07:27,789 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:27] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:30,867 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:30] "[37mPOST /results%3Fid%3D85605 HTTP/1.1[0m" 200 -
2018-10-28 00:07:31,540 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:31] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:07:34,367 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:34] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:07:44,041 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:44] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:07:44,127 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:44] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:07:44,280 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:07:44,295 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:07:44,300 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:07:44,329 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:07:44,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:07:44,429 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:07:44,431 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:07:44,465 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:07:44,466 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:07:44,471 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:07:44,473 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:07:46,387 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:07:46,388 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:46] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:07:46,439 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:46] "[37mGET /results%3Fid%3D47078 HTTP/1.1[0m" 200 -
2018-10-28 00:07:49,521 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:49] "[37mPOST /results%3Fid%3D47078 HTTP/1.1[0m" 200 -
2018-10-28 00:07:49,536 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/39.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:07:49,706 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-01/19/content_5034320.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:49,808 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:07:49,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:07:49,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:07:49,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:07:49,851 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:47078
2018-10-28 00:07:49,851 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :33267
2018-10-28 00:07:49,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:07:49,853 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:07:49,853 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-01/19/content_5034320.htm>
None
2018-10-28 00:07:50,005 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-01/19/content_5034127.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,108 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:07:50,130 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/17/content_5042525.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,153 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-01/29/content_5037340.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,233 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-01/18/content_5033735.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,249 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/19/content_5043585.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,257 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/05/content_5039686.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,271 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-01/25/content_5036072.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,350 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/16/content_5041486.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,466 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/04/content_5039353.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,556 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/19/content_5043501.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,567 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/15/content_5041201.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,589 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-01/15/content_10602.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,599 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/15/content_5041316.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,661 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/18/content_5043305.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,809 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/14/content_5041066.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:50,852 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-02/19/content_5043903.htm> (referer: http://sousuo.gov.cn/column/30469/39.htm)
2018-10-28 00:07:52,677 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:07:52] "[37mPOST /results%3Fid%3D47078 HTTP/1.1[0m" 200 -
2018-10-28 00:08:12,520 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/39.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:08:12,629 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:08:12,629 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:08:12,630 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8678,
 'downloader/request_count': 19,
 'downloader/request_method_count/GET': 17,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 593038,
 'downloader/response_count': 19,
 'downloader/response_status_count/200': 19,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 8, 12, 629065),
 'item_scraped_count': 1,
 'log_count/DEBUG': 25,
 'log_count/INFO': 14,
 'memusage/max': 64385024,
 'memusage/startup': 64385024,
 'request_depth_max': 2,
 'response_received_count': 19,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 38,
 'scheduler/enqueued/memory': 38,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 16, 7, 44, 471738)}
2018-10-28 00:08:12,630 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:11:33,452 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:11:35,815 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:11:35] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:11:38,279 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:11:38] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:11:46,995 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:11:46] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:11:47,090 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:11:47] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:11:47,230 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:11:47,246 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:11:47,251 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:11:47,277 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:11:47,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:11:47,378 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:11:47,381 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:11:47,410 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:11:47,411 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:11:47,418 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:11:47,419 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:11:50,179 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:11:50] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:11:51,756 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:11:51,926 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,932 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,939 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,941 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,943 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,945 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,947 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,953 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,958 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,972 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,991 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,993 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,995 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:51,996 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:52,005 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:52,018 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:52,023 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:52,026 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:52,030 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,089 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,091 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :34046
2018-10-28 00:11:52,092 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,093 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:11:52,094 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:52,096 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:52,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,131 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,131 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,131 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :39969
2018-10-28 00:11:52,133 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,133 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,134 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:11:52,135 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,182 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:11:52,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,188 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,188 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :119634
2018-10-28 00:11:52,192 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,193 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:11:52,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,238 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :141864
2018-10-28 00:11:52,241 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,243 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:11:52,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :148979
2018-10-28 00:11:52,296 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,296 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,297 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:11:52,297 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,339 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,340 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,340 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,341 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,341 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :179751
2018-10-28 00:11:52,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,344 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:11:52,345 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,383 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,383 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :198128
2018-10-28 00:11:52,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,388 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:11:52,389 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,477 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:11:52,501 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,503 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,504 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,504 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,505 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :259862
2018-10-28 00:11:52,513 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,514 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,514 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:11:52,515 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,567 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,568 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,570 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :269209
2018-10-28 00:11:52,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,575 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:11:52,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,612 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,612 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,612 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,613 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :287299
2018-10-28 00:11:52,617 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,618 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:11:52,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,676 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,678 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,678 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,680 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :371708
2018-10-28 00:11:52,685 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,686 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,686 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:11:52,687 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,753 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,755 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :403511
2018-10-28 00:11:52,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,771 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:11:52,772 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :439559
2018-10-28 00:11:52,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,848 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:11:52,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:52,894 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:52,896 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:52,897 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:52,897 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:52,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :474478
2018-10-28 00:11:52,907 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:52,907 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:52,907 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:11:52,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:53,011 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:53,015 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:53,015 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:53,015 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:53,017 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :512401
2018-10-28 00:11:53,025 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:53,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:53,026 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:11:53,029 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:53,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:53,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:53,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:53,080 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:53,081 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :545573
2018-10-28 00:11:53,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:53,091 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:53,092 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:11:53,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:53,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:53,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:53,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:53,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:53,163 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :574140
2018-10-28 00:11:53,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:53,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:53,188 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:11:53,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:53,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:53,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:53,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:53,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:53,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :608182
2018-10-28 00:11:53,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:53,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:53,282 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:11:53,284 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:53,289 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:11:53] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:11:53,342 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:53,345 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:53,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:53,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:53,349 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :640395
2018-10-28 00:11:53,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:53,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:53,364 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:11:53,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:53,698 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:53,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:53,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:53,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:53,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:11:53,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:11:53,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:53,717 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:11:54,070 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:11:54,072 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:11:54] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:11:54,115 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:11:54] "[37mGET /results%3Fid%3D93426 HTTP/1.1[0m" 200 -
2018-10-28 00:11:57,203 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:11:57] "[37mPOST /results%3Fid%3D93426 HTTP/1.1[0m" 200 -
2018-10-28 00:11:58,305 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:11:58,443 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,446 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,464 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,469 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,471 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,473 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,475 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,476 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,478 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,479 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,486 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,493 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,497 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,499 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,507 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,508 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,510 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,512 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,514 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,516 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:11:58,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:11:58,579 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:11:58,580 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:11:58,580 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:11:58,580 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:93426
2018-10-28 00:11:58,581 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6081
2018-10-28 00:11:58,582 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:11:58,582 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:11:58,582 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm>
None
2018-10-28 00:11:58,596 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:12:00,286 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:00] "[37mPOST /results%3Fid%3D93426 HTTP/1.1[0m" 200 -
2018-10-28 00:12:03,359 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:03] "[37mPOST /results%3Fid%3D93426 HTTP/1.1[0m" 200 -
2018-10-28 00:12:06,444 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:06] "[37mPOST /results%3Fid%3D93426 HTTP/1.1[0m" 200 -
2018-10-28 00:12:09,527 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:09] "[37mPOST /results%3Fid%3D93426 HTTP/1.1[0m" 200 -
2018-10-28 00:12:12,613 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:12] "[37mPOST /results%3Fid%3D93426 HTTP/1.1[0m" 200 -
2018-10-28 00:12:15,705 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:15] "[37mPOST /results%3Fid%3D93426 HTTP/1.1[0m" 200 -
2018-10-28 00:12:16,798 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:12:16,914 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:12:16,915 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:12:16,916 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 19518,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 40,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1519975,
 'downloader/response_count': 43,
 'downloader/response_status_count/200': 43,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 12, 16, 914528),
 'item_scraped_count': 21,
 'log_count/DEBUG': 131,
 'log_count/INFO': 114,
 'memusage/max': 64253952,
 'memusage/startup': 64253952,
 'request_depth_max': 3,
 'response_received_count': 43,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 67,
 'scheduler/enqueued/memory': 67,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 3,
 'start_time': datetime.datetime(2018, 10, 27, 16, 11, 47, 418064)}
2018-10-28 00:12:16,916 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:12:18,802 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:18] "[37mPOST /results%3Fid%3D93426 HTTP/1.1[0m" 200 -
2018-10-28 00:12:19,602 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:19] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:12:21,150 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:21] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:12:27,930 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:27] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:12:28,009 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:28] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:12:28,167 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:12:28,182 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:12:28,187 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:12:28,216 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:12:28,250 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:12:28,317 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:12:28,319 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:12:28,350 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:12:28,350 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:12:28,357 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:12:28,358 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:12:31,095 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:31] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:12:33,593 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:12:33,770 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,772 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,774 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,785 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,786 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,788 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,791 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,801 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,803 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,815 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,827 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,834 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,836 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,839 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,842 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,843 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,845 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,853 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,863 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,872 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:33,915 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:33,916 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:33,916 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:33,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:33,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :19075
2018-10-28 00:12:33,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:33,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:33,919 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:12:33,929 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:33,929 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:33,958 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:33,958 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:33,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:33,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:33,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :26190
2018-10-28 00:12:33,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:33,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:33,960 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:12:33,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:33,995 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:33,996 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:33,996 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:33,996 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:33,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :58403
2018-10-28 00:12:33,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:33,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:33,999 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:12:33,999 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,036 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,038 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,038 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,039 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,039 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :80633
2018-10-28 00:12:34,043 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,044 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,044 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:12:34,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,099 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,099 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :113981
2018-10-28 00:12:34,106 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,106 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,106 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:12:34,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,157 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :144753
2018-10-28 00:12:34,160 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,161 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,161 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:12:34,162 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,181 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:34] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:12:34,216 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:12:34,224 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,227 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :224418
2018-10-28 00:12:34,232 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,232 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,233 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:12:34,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,347 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:12:34,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :286152
2018-10-28 00:12:34,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,382 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:12:34,383 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :292075
2018-10-28 00:12:34,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,425 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:12:34,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,462 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,464 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,464 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,465 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,465 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :310165
2018-10-28 00:12:34,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,471 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:12:34,485 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,536 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,538 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,539 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,539 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,540 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :319512
2018-10-28 00:12:34,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,545 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:12:34,546 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,614 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,615 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :351315
2018-10-28 00:12:34,629 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,630 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,631 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:12:34,632 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,699 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,699 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :386234
2018-10-28 00:12:34,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,708 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,708 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:12:34,709 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :419406
2018-10-28 00:12:34,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,763 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:12:34,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,813 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :457329
2018-10-28 00:12:34,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,835 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:12:34,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:34,938 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:34,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:34,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:34,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:34,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :541738
2018-10-28 00:12:34,952 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:34,953 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:34,953 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:12:34,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:35,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:35,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:35,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:35,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:35,015 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :577786
2018-10-28 00:12:35,024 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:35,025 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:35,025 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:12:35,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:35,109 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:35,115 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:35,115 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:35,115 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:35,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :611828
2018-10-28 00:12:35,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:35,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:35,139 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:12:35,139 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:35,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:35,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:35,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:35,191 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:35,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :640395
2018-10-28 00:12:35,202 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:35,203 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:35,203 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:12:35,204 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:35,463 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:35,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:35,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:35,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:35,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:12:35,479 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:12:35,480 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:35,480 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:12:37,655 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:37] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:12:40,749 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:40] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:12:43,212 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:12:43,213 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:43] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:12:43,258 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:43] "[37mGET /results%3Fid%3D51037 HTTP/1.1[0m" 200 -
2018-10-28 00:12:44,713 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:12:44,857 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,862 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,863 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,868 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,878 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,880 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,882 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,884 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,886 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,888 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,898 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,899 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,901 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,911 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,912 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,915 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,916 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,917 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,923 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,924 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:12:44,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:12:44,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:12:44,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:12:44,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:12:44,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:51037
2018-10-28 00:12:44,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :8153
2018-10-28 00:12:44,999 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:12:45,000 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:12:45,000 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm>
None
2018-10-28 00:12:45,014 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:12:46,345 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:46] "[37mPOST /results%3Fid%3D51037 HTTP/1.1[0m" 200 -
2018-10-28 00:12:49,433 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:49] "[37mPOST /results%3Fid%3D51037 HTTP/1.1[0m" 200 -
2018-10-28 00:12:52,517 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:12:52] "[37mPOST /results%3Fid%3D51037 HTTP/1.1[0m" 200 -
2018-10-28 00:12:55,363 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-28 00:14:47,005 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:14:49,418 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:14:49] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:14:53,368 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:14:53] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:14:53,912 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:14:53] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:14:55,451 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:14:55] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:15:03,383 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:03] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:15:03,539 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:03] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:15:03,656 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:15:03,676 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:15:03,684 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:15:03,719 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:15:03,755 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:15:03,813 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:15:03,816 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:15:03,850 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:15:03,851 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:15:03,856 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:15:03,857 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:15:06,640 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:06] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:15:08,114 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:15:08,320 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,346 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:15:08,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:15:08,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:15:08,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:15:08,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67413
2018-10-28 00:15:08,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :32911
2018-10-28 00:15:08,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:15:08,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:15:08,471 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:15:08,473 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:15:08,506 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:15:08,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:15:08,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:15:08,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67413
2018-10-28 00:15:08,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :66953
2018-10-28 00:15:08,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:15:08,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:15:08,510 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:15:08,574 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,577 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,579 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,588 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,631 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,672 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,679 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,680 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:15:08,717 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:15:08,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:15:08,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:15:08,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67413
2018-10-28 00:15:08,720 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :101872
2018-10-28 00:15:08,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:15:08,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:15:08,723 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:15:08,725 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,729 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:15:08,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:15:08,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:15:08,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:15:08,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67413
2018-10-28 00:15:08,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :137920
2018-10-28 00:15:08,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:15:08,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:15:08,770 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:15:08,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:15:08,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:15:08,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:15:08,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:15:08,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67413
2018-10-28 00:15:08,807 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :143843
2018-10-28 00:15:08,811 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:15:08,811 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:15:08,812 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:15:08,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:15:08,864 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:15:08,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:15:08,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:15:08,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67413
2018-10-28 00:15:08,869 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :172410
2018-10-28 00:15:08,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:15:08,876 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:15:08,877 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:15:08,881 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:15:08,929 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:15:08,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:15:08,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:15:08,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67413
2018-10-28 00:15:08,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :179525
2018-10-28 00:15:08,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:15:08,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:15:08,935 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:15:08,937 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:15:08,945 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:15:08,946 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:08] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:15:08,978 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:15:08,979 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:15:08,979 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:15:08,980 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67413
2018-10-28 00:15:08,980 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :34050
2018-10-28 00:15:08,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:15:08,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:15:08,982 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:15:08,982 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:15:08,989 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:08,992 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:08] "[37mGET /results%3Fid%3D67413 HTTP/1.1[0m" 200 -
2018-10-28 00:15:09,036 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:09,045 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:09,065 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:09,096 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:09,099 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:09,282 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:09,308 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:10,151 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:12,078 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:12] "[37mPOST /results%3Fid%3D67413 HTTP/1.1[0m" 200 -
2018-10-28 00:15:12,809 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:12] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:15:27,598 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:15:27,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:15:27,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:15:27,713 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 10696,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 20,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 901371,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 22,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 15, 27, 711805),
 'item_scraped_count': 8,
 'log_count/DEBUG': 56,
 'log_count/INFO': 49,
 'memusage/max': 64442368,
 'memusage/startup': 64442368,
 'request_depth_max': 2,
 'response_received_count': 22,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 45,
 'scheduler/enqueued/memory': 45,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 16, 15, 3, 855996)}
2018-10-28 00:15:27,713 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:15:35,165 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:15:35,985 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:35] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:15:37,857 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:37] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:15:45,579 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:45] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:15:45,670 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:15:45,824 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:15:45,840 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:15:45,845 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:15:45,872 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:15:45,911 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:15:45,975 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:15:45,978 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:15:46,007 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:15:46,008 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:15:46,012 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:15:46,013 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:15:47,822 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:15:47,824 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:47] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:15:48,654 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:15:48,867 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:48,881 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:48,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:15:49,043 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:15:49,043 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:15:49,044 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:15:49,044 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:82661
2018-10-28 00:15:49,044 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6625
2018-10-28 00:15:49,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:15:49,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:15:49,046 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:15:49,046 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:49] "[37mGET /results%3Fid%3D82661 HTTP/1.1[0m" 200 -
2018-10-28 00:15:49,047 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,050 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,051 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,054 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,057 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,061 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:15:49,065 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,069 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,071 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,099 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,102 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,104 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,108 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,110 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,112 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,115 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,145 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,182 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:49,217 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:15:51,195 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:15:51] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:16:04,985 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:16:05,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:16:05,101 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:16:05,101 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 10023,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 20,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 901329,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 22,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 16, 5, 100277),
 'item_scraped_count': 1,
 'log_count/DEBUG': 28,
 'log_count/INFO': 14,
 'memusage/max': 64069632,
 'memusage/startup': 64065536,
 'request_depth_max': 2,
 'response_received_count': 22,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 45,
 'scheduler/enqueued/memory': 45,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 16, 15, 46, 12533)}
2018-10-28 00:16:05,102 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:16:39,558 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:16:43,761 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:16:43] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:16:45,729 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:16:45] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:16:53,609 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:16:53] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:16:53,697 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:16:53] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:16:53,839 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:16:53,855 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:16:53,860 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:16:53,887 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:16:53,923 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:16:53,991 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:16:53,994 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:16:54,027 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:16:54,028 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:16:54,035 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:16:54,036 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:16:56,788 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:16:56] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:16:58,416 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:16:58,585 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,601 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,603 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,606 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,607 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,609 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,610 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,614 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,624 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,660 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,664 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,667 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,669 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,671 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,673 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,675 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:58,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:58,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:58,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:58,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:58,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :33870
2018-10-28 00:16:58,753 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:58,753 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:58,754 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:16:58,755 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,757 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,758 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,768 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:16:58,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:58,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:58,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:58,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:58,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:58,802 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :51960
2018-10-28 00:16:58,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:58,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:58,804 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:16:58,804 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:58,841 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:58,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:58,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:58,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:58,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :80527
2018-10-28 00:16:58,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:58,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:58,846 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:16:58,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:58,897 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:58,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:58,900 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:58,900 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:58,903 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :115446
2018-10-28 00:16:58,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:58,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:58,908 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:16:58,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:58,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:58,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:58,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:58,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:58,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :147249
2018-10-28 00:16:58,964 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:58,964 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:58,965 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:16:58,965 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,020 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :156596
2018-10-28 00:16:59,024 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,027 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:16:59,028 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,072 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,077 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,077 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :174973
2018-10-28 00:16:59,081 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,081 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,081 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:16:59,082 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,162 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,163 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,164 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,165 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :207186
2018-10-28 00:16:59,170 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,174 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:16:59,175 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:16:59,254 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :268920
2018-10-28 00:16:59,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,264 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:16:59,273 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,337 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,340 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,341 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,341 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,343 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :276035
2018-10-28 00:16:59,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,353 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,355 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:16:59,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,420 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,421 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :306807
2018-10-28 00:16:59,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,426 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:16:59,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,476 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:16:59,490 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,496 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,496 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,497 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,499 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :386472
2018-10-28 00:16:59,515 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,516 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:16:59,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,603 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,606 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,606 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,606 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,608 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :424395
2018-10-28 00:16:59,615 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,616 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:16:59,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :457743
2018-10-28 00:16:59,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,753 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:16:59,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,817 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,821 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,822 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :479973
2018-10-28 00:16:59,830 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,830 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,831 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:16:59,831 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,882 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:16:59] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:16:59,895 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,900 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,902 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :564382
2018-10-28 00:16:59,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:16:59,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:16:59,913 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:16:59,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:16:59,970 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:16:59,977 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:16:59,977 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:16:59,978 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:16:59,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :570305
2018-10-28 00:17:00,005 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:00,005 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:00,006 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:17:00,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:00,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:00,083 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:00,084 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:00,084 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:17:00,087 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :604347
2018-10-28 00:17:00,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:00,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:00,098 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:17:00,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:00,159 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:00,167 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:00,167 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:00,168 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:17:00,171 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :640395
2018-10-28 00:17:00,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:00,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:00,192 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:17:00,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:00,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:00,470 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:00,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:00,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:40617
2018-10-28 00:17:00,473 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:17:00,485 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:00,485 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:00,485 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:17:02,980 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:17:02] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:17:05,232 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:yes
2018-10-28 00:17:05,252 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:17:05] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:17:05,323 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:17:05] "[37mGET /results%3Fid%3D40617 HTTP/1.1[0m" 200 -
2018-10-28 00:17:08,294 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-28 00:17:08,294 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (shutdown)
2018-10-28 00:17:08,368 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-28 00:17:08,369 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-10-28 00:17:08,378 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:17:08,390 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:17:08,391 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 10399,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 20,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 876943,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 17, 8, 378102),
 'item_scraped_count': 20,
 'log_count/DEBUG': 106,
 'log_count/INFO': 111,
 'memusage/max': 63860736,
 'memusage/startup': 63860736,
 'request_depth_max': 1,
 'response_received_count': 21,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 1,
 'start_time': datetime.datetime(2018, 10, 27, 16, 16, 54, 35220)}
2018-10-28 00:17:08,392 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (shutdown)
2018-10-28 00:17:41,972 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:17:43,756 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:17:43] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:17:45,824 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:17:45] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:17:52,164 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:17:52] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:17:52,317 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:17:52] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:17:52,383 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:17:52,401 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:17:52,406 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:17:52,437 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:17:52,476 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:17:52,541 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:17:52,544 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:17:52,574 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:17:52,575 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:17:52,581 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:17:52,583 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:17:55,383 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:17:55,428 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:17:55] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:17:55,554 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,573 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,574 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,576 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,577 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,580 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,582 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,585 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,596 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,630 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,637 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,640 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,641 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,648 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,650 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,652 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,656 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:55,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:55,708 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:55,708 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:55,708 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:55,709 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6621
2018-10-28 00:17:55,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:55,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:55,710 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:17:55,712 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,714 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,725 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:55,725 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:55,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:55,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:55,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:55,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:55,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :40663
2018-10-28 00:17:55,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:55,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:55,766 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:17:55,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:55,796 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:55,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:55,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:55,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:55,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :58753
2018-10-28 00:17:55,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:55,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:55,799 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:17:55,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:55,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:55,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:55,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:55,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:55,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :93672
2018-10-28 00:17:55,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:55,851 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:55,851 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:17:55,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:55,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:55,915 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:55,916 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:55,916 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:55,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :127020
2018-10-28 00:17:55,923 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:55,923 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:55,924 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:17:55,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:55,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:55,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:55,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:55,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:55,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :211429
2018-10-28 00:17:55,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:55,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:55,988 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:17:55,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,028 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,029 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,029 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,030 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :242201
2018-10-28 00:17:56,034 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,034 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,034 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:17:56,035 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:17:56,109 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,111 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,114 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :321866
2018-10-28 00:17:56,123 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,123 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,124 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:17:56,125 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,196 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,198 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,198 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,200 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :359789
2018-10-28 00:17:56,206 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,207 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,207 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:17:56,224 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:17:56,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,262 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,265 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :388356
2018-10-28 00:17:56,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,272 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:17:56,273 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,316 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,317 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,318 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :420569
2018-10-28 00:17:56,331 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,332 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,332 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:17:56,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,392 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,395 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,396 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,396 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :427684
2018-10-28 00:17:56,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,413 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:17:56,414 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,459 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,462 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,462 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,462 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,463 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :460856
2018-10-28 00:17:56,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,471 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:17:56,472 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,513 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,514 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,514 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,515 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :483086
2018-10-28 00:17:56,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,523 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:17:56,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,598 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,604 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,605 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,606 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,608 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :514889
2018-10-28 00:17:56,630 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,630 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,631 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:17:56,631 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,684 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,687 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,687 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :550937
2018-10-28 00:17:56,697 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,697 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,698 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:17:56,698 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :560284
2018-10-28 00:17:56,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,801 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:17:56,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,863 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,869 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :578661
2018-10-28 00:17:56,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,878 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:17:56,879 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:56,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:17:56,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:56,973 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:56,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:56,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:56,980 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :640395
2018-10-28 00:17:56,991 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:56,991 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:56,992 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:17:57,018 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:17:57,288 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:17:57,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:17:57,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:17:57,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37629
2018-10-28 00:17:57,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:17:57,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:17:57,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:17:57,306 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:17:58,533 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:17:58] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:18:01,629 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:18:01] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:18:02,711 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-28 00:18:02,712 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (shutdown)
2018-10-28 00:18:02,785 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-28 00:18:02,787 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-10-28 00:18:02,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:18:02,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:18:02,812 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 10231,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 20,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 876943,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 18, 2, 798756),
 'item_scraped_count': 20,
 'log_count/DEBUG': 106,
 'log_count/INFO': 111,
 'memusage/max': 64057344,
 'memusage/startup': 64057344,
 'request_depth_max': 1,
 'response_received_count': 21,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 1,
 'start_time': datetime.datetime(2018, 10, 27, 16, 17, 52, 581914)}
2018-10-28 00:18:02,813 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (shutdown)
2018-10-28 00:22:33,925 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:22:39,663 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:22:39] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:22:43,035 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:22:43] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:22:50,959 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:22:50] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:22:51,115 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:22:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:22:51,218 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:22:51,242 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:22:51,247 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:22:51,278 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:22:51,316 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:22:51,377 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:22:51,379 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:22:51,412 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:22:51,412 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:22:51,418 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:22:51,420 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:22:54,257 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:22:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:22:56,285 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:22:56,450 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,452 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,467 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,469 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,472 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,475 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,476 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,478 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,484 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,516 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,520 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,523 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,525 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,527 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,529 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,532 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,544 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,552 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:56,598 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:56,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:56,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:56,599 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:56,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6621
2018-10-28 00:22:56,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:56,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:56,602 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:22:56,604 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,607 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,609 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:22:56,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:56,647 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:56,647 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:56,648 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:56,648 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:56,648 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :13736
2018-10-28 00:22:56,649 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:56,649 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:56,650 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:22:56,650 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:56,680 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:56,680 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:56,681 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:56,681 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:56,681 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :31826
2018-10-28 00:22:56,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:56,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:56,683 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:22:56,683 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:56,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:56,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:56,717 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:56,717 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:56,717 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :63629
2018-10-28 00:22:56,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:56,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:56,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:22:56,720 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:56,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:56,762 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:56,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:56,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:56,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :98548
2018-10-28 00:22:56,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:56,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:56,767 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:22:56,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:56,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:56,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:56,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:56,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:56,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :107895
2018-10-28 00:22:56,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:56,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:56,848 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:22:56,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:56,887 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:56,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:56,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:56,889 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:56,889 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :145818
2018-10-28 00:22:56,892 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:56,892 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:56,892 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:22:56,893 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:56,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:56,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:56,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:56,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:56,937 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :179166
2018-10-28 00:22:56,943 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:56,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:56,945 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:22:56,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,011 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,011 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :209938
2018-10-28 00:22:57,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,022 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,023 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:22:57,059 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,105 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,108 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :242151
2018-10-28 00:22:57,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,113 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,113 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:22:57,114 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,168 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,171 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,173 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,174 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,175 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :276193
2018-10-28 00:22:57,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,184 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:22:57,185 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,247 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :294570
2018-10-28 00:22:57,254 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,255 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,256 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:22:57,256 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,303 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :330618
2018-10-28 00:22:57,314 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,314 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,314 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:22:57,315 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,347 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:22:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:22:57,354 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,356 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,357 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,357 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :352848
2018-10-28 00:22:57,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,364 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:22:57,365 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,442 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,443 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,443 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,448 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :381415
2018-10-28 00:22:57,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,467 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:22:57,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:22:57,564 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,567 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,567 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,567 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :443149
2018-10-28 00:22:57,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,577 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:22:57,577 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,855 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,858 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :507101
2018-10-28 00:22:57,871 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,871 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,871 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:22:57,872 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:57,945 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:57,948 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:57,948 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:57,949 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:57,951 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :591510
2018-10-28 00:22:57,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:57,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:57,960 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:22:57,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:58,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:58,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:58,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:58,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:58,011 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :624682
2018-10-28 00:22:58,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:22:58,020 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:58,020 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:22:58,020 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:22:58,050 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:22:58,053 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:22:58] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:22:58,081 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:22:58,085 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:22:58,087 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:22:58,089 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:22:58,089 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:15126
2018-10-28 00:22:58,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :80367
2018-10-28 00:22:58,092 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:22:58,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:22:58,093 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:22:58,106 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:22:58] "[37mGET /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:01,232 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:01] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:04,267 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:23:04,319 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:04] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:04,490 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:04,593 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:23:04,695 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:04,740 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:04,840 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:04,844 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:04,850 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:04,885 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:04,894 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:04,954 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:05,139 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:05,200 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:05,206 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:05,295 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:05,453 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:05,641 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:07,399 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:07] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:09,396 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:23:09,766 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:23:09,881 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:23:09,881 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:23:09,882 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17578,
 'downloader/request_count': 39,
 'downloader/request_method_count/GET': 36,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1410436,
 'downloader/response_count': 39,
 'downloader/response_status_count/200': 39,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 23, 9, 881016),
 'item_scraped_count': 20,
 'log_count/DEBUG': 123,
 'log_count/INFO': 109,
 'memusage/max': 63553536,
 'memusage/startup': 63549440,
 'request_depth_max': 3,
 'response_received_count': 39,
 'scheduler/dequeued': 42,
 'scheduler/dequeued/memory': 42,
 'scheduler/enqueued': 67,
 'scheduler/enqueued/memory': 67,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 3,
 'start_time': datetime.datetime(2018, 10, 27, 16, 22, 51, 418454)}
2018-10-28 00:23:09,882 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:23:10,488 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:10] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:13,571 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:13] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:16,656 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:16] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:19,737 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:19] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:22,832 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:22] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:25,918 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:25] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:29,009 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:29] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:32,148 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:32] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:35,273 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:35] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:38,393 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:38] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:41,513 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:41] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:44,634 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:44] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:48,800 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:48] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:52,867 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:52] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:56,555 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:56] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:23:59,680 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:23:59] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:24:02,798 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:02] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:24:05,926 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:05] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:24:09,099 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:09] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:24:12,364 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:12] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:24:15,497 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:15] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:24:18,631 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:18] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:24:21,538 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:24:21,774 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:21] "[37mPOST /results%3Fid%3D15126 HTTP/1.1[0m" 200 -
2018-10-28 00:24:22,690 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:22] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:24:29,316 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:29] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:24:36,149 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:36] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:24:36,258 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:24:36,390 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:24:36,407 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:24:36,415 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:24:36,444 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:24:36,496 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:24:36,558 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:24:36,561 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:24:36,632 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:24:36,633 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:24:36,640 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:24:36,642 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:24:39,356 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:24:40,075 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:24:40,076 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:40] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:24:40,123 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:40] "[37mGET /results%3Fid%3D37754 HTTP/1.1[0m" 200 -
2018-10-28 00:24:42,170 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:24:42,345 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,348 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,353 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,355 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,361 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,363 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,372 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,384 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,404 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,409 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,441 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,443 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,445 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,447 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,449 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,450 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,452 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,453 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:24:42,497 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:24:42,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:24:42,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:24:42,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:37754
2018-10-28 00:24:42,499 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :22932
2018-10-28 00:24:42,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:24:42,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:24:42,500 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:24:42,502 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,504 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:24:42,510 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:24:43,213 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:43] "[37mPOST /results%3Fid%3D37754 HTTP/1.1[0m" 200 -
2018-10-28 00:24:46,298 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:46] "[37mPOST /results%3Fid%3D37754 HTTP/1.1[0m" 200 -
2018-10-28 00:24:47,898 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:24:47] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:24:55,691 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:24:55,797 - /anaconda3/lib/python3.6/site-packages/scrapy/dupefilters.py[line:70] - DEBUG: Filtered duplicate request: <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-28 00:24:55,806 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:24:55,807 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:24:55,807 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 10075,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 20,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 901051,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 22,
 'dupefilter/filtered': 21,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 24, 55, 806379),
 'item_scraped_count': 1,
 'log_count/DEBUG': 29,
 'log_count/INFO': 14,
 'memusage/max': 63959040,
 'memusage/startup': 63959040,
 'request_depth_max': 2,
 'response_received_count': 22,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 16, 24, 36, 640225)}
2018-10-28 00:24:55,808 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:31:29,965 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:31:31,534 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:31] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:31:33,760 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:33] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:31:41,684 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:41] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:31:41,842 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:41] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:31:41,942 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:31:41,968 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:31:41,975 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:31:42,015 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:31:42,046 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:31:42,108 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:31:42,111 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:31:42,139 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:31:42,140 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:31:42,146 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:31:42,147 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:31:45,030 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:31:45,373 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:31:45,374 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:45] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:31:45,416 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:45] "[37mGET /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:31:46,513 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:31:46,722 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:46,725 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:46,826 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:31:46,871 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:31:46,872 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:31:46,872 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:31:46,873 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:43392
2018-10-28 00:31:46,873 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :34050
2018-10-28 00:31:46,874 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:31:46,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:31:46,875 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:31:46,878 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:31:46,977 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,002 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,032 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,124 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,126 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,136 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,200 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,265 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,269 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,295 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,346 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,469 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,495 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:47,834 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:48,496 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:31:48,499 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:48] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:31:51,572 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:51] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:31:54,655 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:54] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:31:56,387 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:31:56,503 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:31:56,504 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:31:56,505 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 9105,
 'downloader/request_count': 19,
 'downloader/request_method_count/GET': 17,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 818866,
 'downloader/response_count': 19,
 'downloader/response_status_count/200': 19,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 31, 56, 503888),
 'item_scraped_count': 1,
 'log_count/DEBUG': 25,
 'log_count/INFO': 14,
 'memusage/max': 64061440,
 'memusage/startup': 64057344,
 'request_depth_max': 2,
 'response_received_count': 19,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 45,
 'scheduler/enqueued/memory': 45,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 16, 31, 42, 145972)}
2018-10-28 00:31:56,505 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:31:57,739 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:31:57] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:32:00,832 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:32:00] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:32:03,973 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:32:03] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:32:07,067 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:32:07] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:32:10,147 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:32:10] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:32:13,242 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:32:13] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:32:16,329 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:32:16] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:32:19,417 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:32:19] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:32:22,505 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:32:22] "[37mPOST /results%3Fid%3D43392 HTTP/1.1[0m" 200 -
2018-10-28 00:35:41,099 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:35:43,165 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:35:43] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:35:45,643 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:35:45] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:35:53,611 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:35:53] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:35:53,771 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:35:53] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:35:53,872 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:35:53,899 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:35:53,905 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:35:53,942 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:35:53,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:35:54,035 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:35:54,037 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:35:54,067 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:35:54,067 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:35:54,073 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:35:54,074 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:35:56,743 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:35:56,925 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,927 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,929 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,931 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,935 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,948 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,950 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,967 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,969 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,988 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,990 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:56,995 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:57,005 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:57,007 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:57,023 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:57,026 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:57,027 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:35:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:35:57,031 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:57,031 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,091 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,092 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,092 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,094 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7813
2018-10-28 00:35:57,095 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,095 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,097 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:35:57,101 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:57,103 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:57,106 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:35:57,118 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,153 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,154 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,154 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,154 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :36380
2018-10-28 00:35:57,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,156 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,157 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:35:57,157 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,191 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,192 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,192 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :58610
2018-10-28 00:35:57,198 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,199 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:35:57,201 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,265 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :89382
2018-10-28 00:35:57,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,273 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:35:57,274 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,330 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,331 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,331 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,331 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :98729
2018-10-28 00:35:57,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,334 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:35:57,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :130532
2018-10-28 00:35:57,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,371 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:35:57,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,402 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,403 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,404 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,404 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :148622
2018-10-28 00:35:57,409 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,410 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,411 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:35:57,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,498 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,502 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :186545
2018-10-28 00:35:57,513 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,519 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:35:57,520 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,567 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,568 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,568 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :220587
2018-10-28 00:35:57,572 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,572 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,573 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:35:57,573 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,651 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,654 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,655 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,655 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,656 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :304996
2018-10-28 00:35:57,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,668 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,668 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:35:57,669 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,740 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :337209
2018-10-28 00:35:57,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,746 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:35:57,746 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:57,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:57,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:57,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:57,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:57,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :401161
2018-10-28 00:35:57,992 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:57,992 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:57,992 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:35:57,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:58,041 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:58,043 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:58,043 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:58,043 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:58,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :419538
2018-10-28 00:35:58,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:58,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:58,051 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:35:58,054 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:58,084 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:58,086 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:58,086 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:58,087 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:58,088 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :425461
2018-10-28 00:35:58,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:58,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:58,093 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:35:58,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:58,154 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:35:58,165 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:58,167 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:58,167 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:58,168 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:58,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :487195
2018-10-28 00:35:58,175 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:58,175 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:58,176 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:35:58,176 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:58,252 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:58,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:58,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:58,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:58,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :522114
2018-10-28 00:35:58,285 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:58,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:58,286 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:35:58,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:58,338 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:35:58,353 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:58,357 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:58,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:58,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:58,359 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :601779
2018-10-28 00:35:58,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:58,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:58,368 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:35:58,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:58,448 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:58,451 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:58,452 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:58,452 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:58,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :635127
2018-10-28 00:35:58,492 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:58,492 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:58,493 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:35:58,493 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:58,552 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:58,556 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:58,556 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:58,557 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:58,558 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :671175
2018-10-28 00:35:58,568 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:58,568 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:58,569 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:35:58,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:35:58,652 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:35:58,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:35:58,664 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:35:58,668 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:25360
2018-10-28 00:35:58,675 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:35:58,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:35:58,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:35:58,704 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:36:00,144 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:36:00] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:36:02,387 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:36:02,388 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:36:02] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:36:02,431 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:36:02] "[37mGET /results%3Fid%3D25360 HTTP/1.1[0m" 200 -
2018-10-28 00:36:05,511 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:36:05] "[37mPOST /results%3Fid%3D25360 HTTP/1.1[0m" 200 -
2018-10-28 00:36:08,592 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:36:08] "[37mPOST /results%3Fid%3D25360 HTTP/1.1[0m" 200 -
2018-10-28 00:36:11,505 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-28 00:36:11,506 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (shutdown)
2018-10-28 00:36:11,508 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-28 00:36:11,510 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-10-28 00:36:11,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:36:11,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:36:11,518 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 10140,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 20,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 876967,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 36, 11, 516920),
 'item_scraped_count': 20,
 'log_count/DEBUG': 106,
 'log_count/INFO': 111,
 'memusage/max': 64278528,
 'memusage/startup': 64278528,
 'request_depth_max': 1,
 'response_received_count': 21,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 1,
 'start_time': datetime.datetime(2018, 10, 27, 16, 35, 54, 73046)}
2018-10-28 00:36:11,519 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (shutdown)
2018-10-28 00:39:14,387 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:39:18,260 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:18] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:39:20,305 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:20] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:39:28,888 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:28] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:39:29,032 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:29] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:39:29,121 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:39:29,140 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:39:29,146 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:39:29,177 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:39:29,210 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:39:29,274 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:39:29,276 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:39:29,305 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:39:29,306 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:39:29,315 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:39:29,317 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:39:32,169 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:32] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:39:32,470 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:39:32,637 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,645 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,652 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,654 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,656 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,657 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,665 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,667 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,675 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,677 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,689 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,692 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,694 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,697 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,699 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,708 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,721 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,723 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,738 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:32,740 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:32,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:32,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:32,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:32,781 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:32,781 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6621
2018-10-28 00:39:32,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:32,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:32,783 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:39:32,793 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:32,823 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:32,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:32,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:32,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:32,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :13736
2018-10-28 00:39:32,825 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:32,826 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:32,826 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:39:32,826 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:32,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:32,857 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:32,857 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:32,858 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:32,858 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :32113
2018-10-28 00:39:32,859 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:32,859 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:32,860 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:39:32,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:32,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:32,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:32,889 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:32,889 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:32,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :50203
2018-10-28 00:39:32,891 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:32,891 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:32,891 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:39:32,892 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:32,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:32,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:32,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:32,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:32,933 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :83375
2018-10-28 00:39:32,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:32,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:32,937 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:39:32,938 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:32,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:32,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:32,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:32,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:32,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :115588
2018-10-28 00:39:32,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:32,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:32,988 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:39:32,989 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,028 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,028 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :146360
2018-10-28 00:39:33,031 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,031 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,032 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:39:33,032 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,074 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,075 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :184283
2018-10-28 00:39:33,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,080 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:39:33,081 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,147 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,149 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,150 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,150 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,151 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :268692
2018-10-28 00:39:33,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,158 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:39:33,159 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,209 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,211 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,211 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,212 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,213 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :297259
2018-10-28 00:39:33,218 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,218 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,219 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:39:33,221 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:39:33,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,280 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,280 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,280 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :332178
2018-10-28 00:39:33,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,287 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:39:33,289 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,337 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,338 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,338 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,339 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :365526
2018-10-28 00:39:33,344 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,345 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,345 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:39:33,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,408 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,411 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,411 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :397329
2018-10-28 00:39:33,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,424 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:39:33,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,497 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,501 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :406676
2018-10-28 00:39:33,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,509 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:39:33,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,548 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,550 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,550 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,551 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,552 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :428906
2018-10-28 00:39:33,558 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,559 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,559 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:39:33,559 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,621 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,624 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,625 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,627 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,631 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :462948
2018-10-28 00:39:33,643 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,644 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,644 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:39:33,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:39:33,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :524682
2018-10-28 00:39:33,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:39:33,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,751 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:39:33,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:39:33,808 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:39:33,841 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:39:33,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:39:33,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:39:33,849 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:39:33,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:68553
2018-10-28 00:39:33,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :630
2018-10-28 00:39:33,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:39:33,850 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:33] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:39:33,851 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:39:33,851 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:39:33,852 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:39:33,902 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:33] "[37mGET /results%3Fid%3D68553 HTTP/1.1[0m" 200 -
2018-10-28 00:39:36,978 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:36] "[37mPOST /results%3Fid%3D68553 HTTP/1.1[0m" 200 -
2018-10-28 00:39:40,057 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:40] "[37mPOST /results%3Fid%3D68553 HTTP/1.1[0m" 200 -
2018-10-28 00:39:43,103 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:39:43,131 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:43] "[37mPOST /results%3Fid%3D68553 HTTP/1.1[0m" 200 -
2018-10-28 00:39:43,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:39:43,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:39:43,223 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 10079,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 20,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 901329,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 22,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 39, 43, 222036),
 'item_scraped_count': 18,
 'log_count/DEBUG': 98,
 'log_count/INFO': 99,
 'memusage/max': 63758336,
 'memusage/startup': 63758336,
 'request_depth_max': 2,
 'response_received_count': 22,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 45,
 'scheduler/enqueued/memory': 45,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 16, 39, 29, 315231)}
2018-10-28 00:39:43,223 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:39:46,214 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:39:46] "[37mPOST /results%3Fid%3D68553 HTTP/1.1[0m" 200 -
2018-10-28 00:51:50,448 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:51:52,284 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:51:52] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:51:54,544 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:51:54] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:52:01,259 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:52:01] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:52:01,406 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:52:01] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:52:01,483 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:52:01,503 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:52:01,508 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:52:01,537 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:52:01,573 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:52:01,640 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:52:01,643 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:52:01,674 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:52:01,675 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:52:01,681 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:52:01,682 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:52:06,366 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:52:06,556 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:06,564 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:06,585 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:06,588 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:06,593 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:06,620 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:06,649 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:06,657 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:06,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:06,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:06,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:06,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:06,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :19075
2018-10-28 00:52:06,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:06,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:06,705 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:52:06,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:06,748 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:06,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:06,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:06,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:06,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :56998
2018-10-28 00:52:06,751 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:06,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:06,752 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:52:06,753 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:06,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:06,786 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:06,786 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:06,787 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:06,787 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :88801
2018-10-28 00:52:06,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:06,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:06,790 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:52:06,790 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:06,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:06,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:06,853 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:06,853 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:06,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :98148
2018-10-28 00:52:06,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:06,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:06,857 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:52:06,857 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,091 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,091 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,092 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :162100
2018-10-28 00:52:07,096 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,096 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,097 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:52:07,101 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,103 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,106 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,108 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,110 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,111 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:52:07,192 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,194 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,195 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,196 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :223834
2018-10-28 00:52:07,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,200 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,200 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:52:07,200 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,244 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,244 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :258753
2018-10-28 00:52:07,249 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,249 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,249 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:52:07,251 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,252 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,294 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :265868
2018-10-28 00:52:07,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,302 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:52:07,303 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,373 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :299040
2018-10-28 00:52:07,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,382 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:52:07,383 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,430 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,430 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,431 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,432 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :331253
2018-10-28 00:52:07,437 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,438 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,438 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:52:07,438 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,486 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,488 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,488 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,490 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :364601
2018-10-28 00:52:07,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,495 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:52:07,496 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,540 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,546 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,546 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,548 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :382691
2018-10-28 00:52:07,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,564 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,566 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:52:07,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,630 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,631 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,631 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,633 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :411258
2018-10-28 00:52:07,639 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,640 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,640 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:52:07,641 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,643 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,645 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,646 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,654 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,699 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,699 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,700 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :447306
2018-10-28 00:52:07,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,708 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:52:07,708 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,777 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :478078
2018-10-28 00:52:07,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,798 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:52:07,800 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:07,809 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,855 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,857 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,858 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,858 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,859 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :500308
2018-10-28 00:52:07,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,867 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:52:07,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:07,911 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:52:07,929 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:07,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:07,935 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:07,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:07,938 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :579973
2018-10-28 00:52:07,950 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:07,950 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:07,951 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:52:07,951 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:08,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:08,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:08,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:08,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:08,018 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :585896
2018-10-28 00:52:08,035 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:08,036 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:08,036 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:52:08,036 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:08,108 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:08,111 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:08,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:08,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:08,114 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :670305
2018-10-28 00:52:08,124 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:08,124 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:08,125 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:52:08,130 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:08,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:08,213 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:08,213 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:08,214 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:08,215 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:52:08,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:08,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:08,238 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:52:15,544 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:52:15,700 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:15,705 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:15,708 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:15,798 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:15,802 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:15,871 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>table of length 436:  åºå· å·¥ä½œä»»åŠ¡ ç‰µå¤´éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 åˆ¶è®¢â€œåä¸‰äº”â€åŒ»æ”¹è§„åˆ’ å›½åŠ¡é™¢åŒ»æ”¹åŠ ...
2018-10-28 00:52:15,872 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 436:  åºå· å·¥ä½œä»»åŠ¡ ç‰µå¤´éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 åˆ¶è®¢â€œåä¸‰äº”â€åŒ»æ”¹è§„åˆ’ å›½åŠ¡é™¢åŒ»æ”¹åŠ ...
2018-10-28 00:52:15,896 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:15,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:15,900 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:15,900 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:15,902 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :780618
2018-10-28 00:52:15,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:15,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:15,913 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm>
None
2018-10-28 00:52:15,915 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:15,920 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:15,963 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:15,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:15,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:15,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:15,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :785997
2018-10-28 00:52:15,979 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:15,979 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:15,980 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm>
None
2018-10-28 00:52:15,980 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,030 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,035 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,036 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,036 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,039 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :818075
2018-10-28 00:52:16,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,052 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm>
None
2018-10-28 00:52:16,052 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,106 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :855399
2018-10-28 00:52:16,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,118 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm>
None
2018-10-28 00:52:16,119 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,120 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,122 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,123 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,124 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,128 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,129 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,173 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,177 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,177 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,178 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,179 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :857191
2018-10-28 00:52:16,191 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,191 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,191 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm>
None
2018-10-28 00:52:16,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,265 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,274 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :864642
2018-10-28 00:52:16,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,286 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm>
None
2018-10-28 00:52:16,289 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,313 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 3132:  ä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘ ã€Šå…³äºåšå¥½æ–°æ—¶æœŸæ•™è‚²å¯¹å¤–å¼€æ”¾å·¥ä½œçš„è‹¥å¹²æ„è§ã€‹...
2018-10-28 00:52:16,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,335 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :883857
2018-10-28 00:52:16,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,346 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm>
None
2018-10-28 00:52:16,347 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,395 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,402 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :890750
2018-10-28 00:52:16,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,416 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm>
None
2018-10-28 00:52:16,417 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :905267
2018-10-28 00:52:16,488 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,489 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm>
None
2018-10-28 00:52:16,490 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,563 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,573 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,574 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :932262
2018-10-28 00:52:16,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,611 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,612 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm>
None
2018-10-28 00:52:16,613 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,724 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1033341
2018-10-28 00:52:16,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,757 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm>
None
2018-10-28 00:52:16,765 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,766 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,768 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,769 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,770 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,771 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,773 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:52:16,781 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,851 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1056464
2018-10-28 00:52:16,876 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,876 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,877 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm>
None
2018-10-28 00:52:16,879 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:16,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 11110:  æ–°åç¤¾åŒ—äº¬4æœˆ26æ—¥ç”µ ä¸­å…±ä¸­å¤® å›½åŠ¡é™¢å…³äºå…¨é¢æŒ¯å…´ä¸œåŒ—åœ°åŒºç­‰è€å·¥ä¸šåŸºåœ°çš„è‹¥å¹²...
2018-10-28 00:52:16,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:16,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:16,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:16,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:16,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1123783
2018-10-28 00:52:16,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:16,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:16,998 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm>
None
2018-10-28 00:52:17,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:17,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:17,099 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:17,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:17,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:17,103 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1128045
2018-10-28 00:52:17,125 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:17,125 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:17,126 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm>
None
2018-10-28 00:52:17,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:17,198 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:17,204 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:17,204 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:17,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:17,208 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1163608
2018-10-28 00:52:17,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:17,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:17,234 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm>
None
2018-10-28 00:52:17,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:17,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 35: å›½åŠ¡é™¢å…³äºåšå¥½å…¨é¢æ¨å¼€ è¥æ”¹å¢è¯•ç‚¹å·¥ä½œçš„é€šçŸ¥ å›½å‘æ˜ç”µã€”2016ã€•1å·
2018-10-28 00:52:17,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:17,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:17,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:17,291 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:17,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1170874
2018-10-28 00:52:17,309 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:17,309 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:17,309 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm>
None
2018-10-28 00:52:17,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:17,331 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 1947:  æ–°åç¤¾åŒ—äº¬4æœˆ28æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘äº†ã€Šå…³äºå»ºç«‹è´«å›°...
2018-10-28 00:52:17,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:17,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:17,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:17,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:17,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1183093
2018-10-28 00:52:17,395 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:17,396 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:17,396 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm>
None
2018-10-28 00:52:17,397 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:17,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:17,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:17,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:17,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:17,463 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1208647
2018-10-28 00:52:17,480 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:17,480 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:17,480 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm>
None
2018-10-28 00:52:17,481 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:17,555 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:17,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:17,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:17,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:17,565 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1255633
2018-10-28 00:52:17,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:17,589 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:17,589 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm>
None
2018-10-28 00:52:17,591 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:17,664 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:17,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:17,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:17,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:17,675 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1259412
2018-10-28 00:52:17,702 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:17,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:17,703 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm>
None
2018-10-28 00:52:24,869 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:52:25,009 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/30/content_5059662.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,026 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/06/content_5061542.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,069 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/11/content_5062953.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:25,174 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:25,179 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:25,180 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:25,180 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:25,182 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1273815
2018-10-28 00:52:25,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:25,199 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:25,200 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/30/content_5059662.htm>
None
2018-10-28 00:52:25,202 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/14/content_5063934.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:25,270 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:25,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:25,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:25,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:25,282 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1285142
2018-10-28 00:52:25,309 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:25,309 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:25,310 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/06/content_5061542.htm>
None
2018-10-28 00:52:25,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:25,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:25,379 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:25,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:25,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:25,385 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1290267
2018-10-28 00:52:25,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:25,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:25,419 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/11/content_5062953.htm>
None
2018-10-28 00:52:25,421 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/28/content_5058928.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,425 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/15/content_5064431.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,429 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/18/content_5065392.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,442 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/11/content_5062975.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,447 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/14/content_5063951.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,449 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/11/content_5062973.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,450 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:25,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:25,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:25,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:25,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:25,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1291918
2018-10-28 00:52:25,542 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:25,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:25,543 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/14/content_5063934.htm>
None
2018-10-28 00:52:25,545 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/24/content_5057163.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:25,594 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:25,706 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:25,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:25,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:25,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:25,713 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1294024
2018-10-28 00:52:25,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:25,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:25,733 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/28/content_5058928.htm>
None
2018-10-28 00:52:25,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:25,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:25,804 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:25,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:25,805 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:25,808 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1299776
2018-10-28 00:52:25,850 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:25,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:25,853 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/15/content_5064431.htm>
None
2018-10-28 00:52:25,859 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:25,947 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:25,953 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:25,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:25,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:25,957 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1341088
2018-10-28 00:52:25,975 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:25,976 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:25,976 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/18/content_5065392.htm>
None
2018-10-28 00:52:25,977 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:26,050 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:26,062 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:26,063 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:26,063 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:26,070 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1346508
2018-10-28 00:52:26,097 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:26,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:26,098 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/11/content_5062975.htm>
None
2018-10-28 00:52:26,101 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/25/content_5058006.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:26,105 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/07/content_5062098.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:26,110 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-03/23/content_5056967.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:26,115 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/31/content_5060062.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:26,117 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/13/content_5063670.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:26,119 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/28/content_5059035.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:26,120 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/01/content_5060345.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:26,125 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:26,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>table of length 965:  åºå· å·¥ ä½œ ä»» åŠ¡ ç‰µå¤´è´Ÿè´£éƒ¨é—¨ 1 å±…æ°‘æ¶ˆè´¹ä»·æ ¼æ¶¨å¹…3%å·¦å³ å‘å±•æ”¹é©å§” ...
2018-10-28 00:52:26,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 965:  åºå· å·¥ ä½œ ä»» åŠ¡ ç‰µå¤´è´Ÿè´£éƒ¨é—¨ 1 å±…æ°‘æ¶ˆè´¹ä»·æ ¼æ¶¨å¹…3%å·¦å³ å‘å±•æ”¹é©å§” ...
2018-10-28 00:52:26,231 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:26,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:26,244 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:26,244 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:26,249 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1363613
2018-10-28 00:52:26,285 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:26,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:26,286 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/14/content_5063951.htm>
None
2018-10-28 00:52:26,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:26,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:26,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:26,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:26,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:26,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1368879
2018-10-28 00:52:26,398 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:26,399 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:26,399 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/11/content_5062973.htm>
None
2018-10-28 00:52:26,404 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/15/content_5064434.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:26,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:26,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:26,536 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:26,537 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:26,537 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:26,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1437692
2018-10-28 00:52:26,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:26,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:26,577 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/24/content_5057163.htm>
None
2018-10-28 00:52:26,586 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:26,658 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:26,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:26,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:26,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:26,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1449325
2018-10-28 00:52:26,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:26,721 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:26,723 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/25/content_5058006.htm>
None
2018-10-28 00:52:26,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:26,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 2199: å±±ä¸œçœäººæ°‘æ”¿åºœï¼š ä½ çœå…³äºæŠ¥è¯·å®¡æ‰¹ä¸œè¥å¸‚åŸå¸‚æ€»ä½“è§„åˆ’çš„è¯·ç¤ºæ”¶æ‚‰ã€‚ç»å›½åŠ¡é™¢æ‰¹å‡†ï¼Œç°...
2018-10-28 00:52:26,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:26,796 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:26,796 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:26,796 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:26,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1463546
2018-10-28 00:52:26,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:26,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:26,820 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/07/content_5062098.htm>
None
2018-10-28 00:52:26,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:26,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 4068:  æ–°åç¤¾åŒ—äº¬3æœˆ23æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘äº†ã€Šå¥å…¨è½å®ç¤¾ä¼š...
2018-10-28 00:52:26,902 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:26,909 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:26,909 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:26,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:26,914 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1488787
2018-10-28 00:52:26,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:26,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:26,967 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-03/23/content_5056967.htm>
None
2018-10-28 00:52:26,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:27,056 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:27,067 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:27,067 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:27,068 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:27,075 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1561464
2018-10-28 00:52:27,118 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:27,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:27,121 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/31/content_5060062.htm>
None
2018-10-28 00:52:27,122 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:27,226 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:27,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:27,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:27,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:27,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1632525
2018-10-28 00:52:27,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:27,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:27,259 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/13/content_5063670.htm>
None
2018-10-28 00:52:27,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:27,357 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:27,374 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:27,375 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:27,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:27,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1652840
2018-10-28 00:52:27,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:27,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:27,429 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/28/content_5059035.htm>
None
2018-10-28 00:52:27,430 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:27,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:27,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:27,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:27,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:27,555 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1684686
2018-10-28 00:52:27,615 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:27,615 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:27,615 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/01/content_5060345.htm>
None
2018-10-28 00:52:27,617 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/05/content_5061324.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 00:52:27,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:27,706 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:27,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:27,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:27,718 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:27,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1776116
2018-10-28 00:52:27,783 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:27,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:27,784 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/15/content_5064434.htm>
None
2018-10-28 00:52:27,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:52:27,874 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:52:27,882 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:52:27,883 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:52:27,883 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:67953
2018-10-28 00:52:27,886 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1788328
2018-10-28 00:52:27,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:52:27,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:52:27,910 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/05/content_5061324.htm>
None
2018-10-28 00:52:28,094 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-28 00:52:28,095 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (shutdown)
2018-10-28 00:52:28,163 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-28 00:52:28,164 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://sousuo.gov.cn/column/30469/37.htm via http://localhost:8050/execute> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-10-28 00:52:28,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:52:28,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:52:28,241 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 28581,
 'downloader/request_count': 64,
 'downloader/request_method_count/GET': 60,
 'downloader/request_method_count/POST': 4,
 'downloader/response_bytes': 2116852,
 'downloader/response_count': 63,
 'downloader/response_status_count/200': 63,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 52, 28, 187706),
 'item_scraped_count': 60,
 'log_count/DEBUG': 318,
 'log_count/INFO': 311,
 'memusage/max': 63815680,
 'memusage/startup': 63815680,
 'request_depth_max': 3,
 'response_received_count': 63,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 68,
 'scheduler/dequeued/memory': 68,
 'scheduler/enqueued': 69,
 'scheduler/enqueued/memory': 69,
 'splash/execute/request_count': 4,
 'splash/execute/response_count/200': 3,
 'start_time': datetime.datetime(2018, 10, 27, 16, 52, 1, 681270)}
2018-10-28 00:52:28,241 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (shutdown)
2018-10-28 00:52:58,814 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:53:00,081 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:00] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:53:02,045 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:02] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:53:12,910 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:12] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:53:13,019 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:13] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:53:13,141 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:53:13,156 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:53:13,161 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:53:13,188 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:53:13,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:53:13,289 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:53:13,291 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:53:13,318 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:53:13,319 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:53:13,325 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:53:13,327 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:53:16,126 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:16] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:53:17,465 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:53:17,662 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,665 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,667 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,669 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,670 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,672 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,674 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,676 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,698 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,713 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,715 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,717 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,720 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,721 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,723 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,733 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,739 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:17,797 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:17,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:17,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:17,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:17,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6621
2018-10-28 00:53:17,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:17,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:17,800 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:53:17,808 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:17,809 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:17,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:17,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:17,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:17,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:17,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :28851
2018-10-28 00:53:17,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:17,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:17,840 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:53:17,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:17,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:17,876 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:17,876 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:17,876 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:17,877 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :63770
2018-10-28 00:53:17,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:17,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:17,878 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:53:17,879 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:17,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:17,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:17,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:17,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:17,920 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :96942
2018-10-28 00:53:17,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:17,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:17,922 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:53:17,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:17,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:17,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:17,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:17,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:17,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :130290
2018-10-28 00:53:17,963 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:17,963 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:17,963 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:53:17,964 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,018 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,019 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,020 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :214699
2018-10-28 00:53:18,024 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,025 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,025 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:53:18,025 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,063 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,064 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,064 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,065 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,065 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :252622
2018-10-28 00:53:18,069 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,069 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,069 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:53:18,070 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,125 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,128 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :261969
2018-10-28 00:53:18,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,133 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,133 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:53:18,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,170 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,173 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,174 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :280346
2018-10-28 00:53:18,178 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,178 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,178 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:53:18,180 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:18,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,231 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,233 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :287461
2018-10-28 00:53:18,238 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,239 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:53:18,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,300 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:53:18,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,313 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :349195
2018-10-28 00:53:18,318 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,318 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,318 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:53:18,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,358 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,362 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :381408
2018-10-28 00:53:18,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,368 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:53:18,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:53:18,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :461073
2018-10-28 00:53:18,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,435 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:53:18,436 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,483 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,486 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,486 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,486 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,488 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :495115
2018-10-28 00:53:18,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,495 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:53:18,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,540 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :526918
2018-10-28 00:53:18,555 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,555 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,556 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:53:18,556 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,597 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,602 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :555485
2018-10-28 00:53:18,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,611 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,611 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:53:18,611 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,662 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,665 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,668 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :591533
2018-10-28 00:53:18,676 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,676 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,677 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:53:18,677 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,724 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,728 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,730 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :609623
2018-10-28 00:53:18,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,739 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:53:18,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,915 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :673575
2018-10-28 00:53:18,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:18,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:18,930 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:53:18,939 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:18,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:18,992 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:18,993 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:18,993 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:18,994 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:53:19,004 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:19,004 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:19,005 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:53:19,233 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:19] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:53:22,338 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:22] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:53:25,438 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:25] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:53:27,897 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:53:28,038 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,040 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,042 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,051 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,058 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,059 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,061 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,070 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,071 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,073 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,077 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,079 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,086 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,087 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,089 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,100 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,107 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,109 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,110 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,112 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:53:28,141 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,192 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,196 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,196 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,196 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,198 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :718864
2018-10-28 00:53:28,209 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,209 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,209 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm>
None
2018-10-28 00:53:28,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,304 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,308 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :724243
2018-10-28 00:53:28,320 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,320 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,321 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm>
None
2018-10-28 00:53:28,321 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,373 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,374 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,374 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :728022
2018-10-28 00:53:28,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,388 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,388 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm>
None
2018-10-28 00:53:28,389 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,457 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,460 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,463 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :829101
2018-10-28 00:53:28,472 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,473 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,473 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm>
None
2018-10-28 00:53:28,473 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,538 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,542 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,542 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,542 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,545 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:28] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:53:28,546 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :833363
2018-10-28 00:53:28,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,567 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm>
None
2018-10-28 00:53:28,567 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,605 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 11110:  æ–°åç¤¾åŒ—äº¬4æœˆ26æ—¥ç”µ ä¸­å…±ä¸­å¤® å›½åŠ¡é™¢å…³äºå…¨é¢æŒ¯å…´ä¸œåŒ—åœ°åŒºç­‰è€å·¥ä¸šåŸºåœ°çš„è‹¥å¹²...
2018-10-28 00:53:28,627 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,632 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,632 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,633 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,635 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :900682
2018-10-28 00:53:28,649 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,650 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,650 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm>
None
2018-10-28 00:53:28,651 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,675 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 1947:  æ–°åç¤¾åŒ—äº¬4æœˆ28æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘äº†ã€Šå…³äºå»ºç«‹è´«å›°...
2018-10-28 00:53:28,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,701 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,703 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :912901
2018-10-28 00:53:28,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,716 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm>
None
2018-10-28 00:53:28,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 3132:  ä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘ ã€Šå…³äºåšå¥½æ–°æ—¶æœŸæ•™è‚²å¯¹å¤–å¼€æ”¾å·¥ä½œçš„è‹¥å¹²æ„è§ã€‹...
2018-10-28 00:53:28,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :932116
2018-10-28 00:53:28,791 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,791 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,791 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm>
None
2018-10-28 00:53:28,792 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,841 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :939009
2018-10-28 00:53:28,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,852 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm>
None
2018-10-28 00:53:28,853 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,907 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:28,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:28,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:28,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:28,915 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :976333
2018-10-28 00:53:28,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:28,928 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:28,928 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm>
None
2018-10-28 00:53:28,928 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:28,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>table of length 436:  åºå· å·¥ä½œä»»åŠ¡ ç‰µå¤´éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 åˆ¶è®¢â€œåä¸‰äº”â€åŒ»æ”¹è§„åˆ’ å›½åŠ¡é™¢åŒ»æ”¹åŠ ...
2018-10-28 00:53:28,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 436:  åºå· å·¥ä½œä»»åŠ¡ ç‰µå¤´éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 åˆ¶è®¢â€œåä¸‰äº”â€åŒ»æ”¹è§„åˆ’ å›½åŠ¡é™¢åŒ»æ”¹åŠ ...
2018-10-28 00:53:29,009 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,016 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1052604
2018-10-28 00:53:29,030 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,030 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,030 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm>
None
2018-10-28 00:53:29,031 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:29,083 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,088 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,088 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,088 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,090 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1088167
2018-10-28 00:53:29,103 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,103 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,103 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm>
None
2018-10-28 00:53:29,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:29,150 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,154 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1111290
2018-10-28 00:53:29,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,172 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm>
None
2018-10-28 00:53:29,173 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:29,217 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,222 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,225 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1113082
2018-10-28 00:53:29,241 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,242 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm>
None
2018-10-28 00:53:29,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:29,286 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,292 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1120533
2018-10-28 00:53:29,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,306 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm>
None
2018-10-28 00:53:29,307 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:29,357 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1146087
2018-10-28 00:53:29,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,383 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,383 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm>
None
2018-10-28 00:53:29,383 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:29,407 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 35: å›½åŠ¡é™¢å…³äºåšå¥½å…¨é¢æ¨å¼€ è¥æ”¹å¢è¯•ç‚¹å·¥ä½œçš„é€šçŸ¥ å›½å‘æ˜ç”µã€”2016ã€•1å·
2018-10-28 00:53:29,431 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,436 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,437 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,437 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1153353
2018-10-28 00:53:29,459 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,460 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,460 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm>
None
2018-10-28 00:53:29,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:29,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,521 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,522 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,524 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1200339
2018-10-28 00:53:29,538 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,538 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,539 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm>
None
2018-10-28 00:53:29,541 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:29,591 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,597 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,597 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,597 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1227334
2018-10-28 00:53:29,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,617 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm>
None
2018-10-28 00:53:29,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:53:29,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:53:29,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:53:29,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:53:29,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:56020
2018-10-28 00:53:29,692 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1259412
2018-10-28 00:53:29,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:53:29,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:53:29,711 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm>
None
2018-10-28 00:53:31,650 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:53:31] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:53:35,864 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-28 00:53:35,864 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (shutdown)
2018-10-28 00:53:35,943 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-28 00:53:35,945 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-10-28 00:53:35,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:53:35,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:53:35,986 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 19402,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 40,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1495991,
 'downloader/response_count': 42,
 'downloader/response_status_count/200': 42,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 53, 35, 958990),
 'item_scraped_count': 40,
 'log_count/DEBUG': 213,
 'log_count/INFO': 211,
 'memusage/max': 63614976,
 'memusage/startup': 63614976,
 'request_depth_max': 2,
 'response_received_count': 42,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 47,
 'scheduler/enqueued/memory': 47,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 16, 53, 13, 325838)}
2018-10-28 00:53:35,986 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (shutdown)
2018-10-28 00:54:18,524 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:54:20,430 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:20] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:54:21,850 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:21] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:54:29,007 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:29] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:54:29,103 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:29] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:54:29,251 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:54:29,267 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:54:29,272 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:54:29,298 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:54:29,328 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:54:29,392 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:54:29,394 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:54:29,422 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:54:29,423 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:54:29,430 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:54:29,431 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:54:32,187 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:32] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:54:33,058 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:54:33,217 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,219 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,232 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,236 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,239 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,240 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,242 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,244 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,259 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,266 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,282 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,286 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,287 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,289 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,292 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,296 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,302 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,304 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,321 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,322 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7813
2018-10-28 00:54:33,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,372 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:54:33,376 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:33,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :25903
2018-10-28 00:54:33,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,418 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,419 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:54:33,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,452 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,454 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :58116
2018-10-28 00:54:33,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,455 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:54:33,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,487 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,488 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,490 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :86683
2018-10-28 00:54:33,493 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,494 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:54:33,495 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,538 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,539 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,540 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,540 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,541 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :117455
2018-10-28 00:54:33,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,546 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,546 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:54:33,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,589 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,589 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,590 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,590 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :139685
2018-10-28 00:54:33,593 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,593 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,594 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:54:33,594 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,641 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,642 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,642 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,642 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,643 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :149032
2018-10-28 00:54:33,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,646 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:54:33,646 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,692 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :186955
2018-10-28 00:54:33,695 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,695 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,695 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:54:33,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,754 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:54:33,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,771 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :266620
2018-10-28 00:54:33,779 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,780 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:54:33,781 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,832 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :299792
2018-10-28 00:54:33,841 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,842 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:54:33,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,895 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,897 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :331595
2018-10-28 00:54:33,904 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,905 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,905 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:54:33,907 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:33,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:33,971 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:33,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:33,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:33,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :367643
2018-10-28 00:54:33,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:33,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:33,985 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:54:33,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:34,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:34,047 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:34,048 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:34,048 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:34,049 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :400991
2018-10-28 00:54:34,056 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:34,056 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:34,056 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:54:34,057 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:34,093 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:34,096 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:34,096 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:34,096 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:34,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :419368
2018-10-28 00:54:34,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:34,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:34,104 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:54:34,105 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:34,151 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:34,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:34,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:34,155 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:34,162 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :425291
2018-10-28 00:54:34,174 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:34,174 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:34,174 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:54:34,175 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:34,424 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:34,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:34,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:34,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:34,430 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :489243
2018-10-28 00:54:34,438 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:34,438 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:34,438 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:54:34,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:34,484 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:34,486 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:34,487 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:34,487 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:34,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :524162
2018-10-28 00:54:34,496 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:34,496 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:34,497 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:54:34,497 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:34,555 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:54:34,572 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:34,574 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:34,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:34,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:34,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :585896
2018-10-28 00:54:34,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:34,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:34,584 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:54:34,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:34,632 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:34,637 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:34,638 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:34,638 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:34,640 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :619938
2018-10-28 00:54:34,649 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:34,649 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:34,649 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:54:34,650 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:34,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:34,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:34,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:34,743 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:34,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:54:34,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:54:34,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:34,757 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:54:35,282 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:35] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:54:36,085 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:54:36,086 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:36] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:54:36,184 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:36] "[37mGET /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:54:39,265 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:39] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:54:42,351 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:42] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:54:45,424 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:45] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:54:47,397 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:54:47,539 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,544 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,546 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,551 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,554 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,557 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,559 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,562 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,572 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,574 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,579 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,582 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,586 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,587 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,596 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,600 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,602 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,603 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,607 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,609 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:54:47,642 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:54:47,683 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:54:47,684 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:54:47,685 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:54:47,685 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76197
2018-10-28 00:54:47,686 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7595
2018-10-28 00:54:47,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:54:47,689 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:54:47,689 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm>
None
2018-10-28 00:54:47,766 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:54:48,516 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:48] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:54:51,606 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:51] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:54:54,687 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:54] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:54:55,390 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:54:55,501 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:54:55,502 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:54:55,502 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 19332,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 40,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1519975,
 'downloader/response_count': 43,
 'downloader/response_status_count/200': 43,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 54, 55, 501527),
 'item_scraped_count': 21,
 'log_count/DEBUG': 131,
 'log_count/INFO': 114,
 'memusage/max': 63631360,
 'memusage/startup': 63631360,
 'request_depth_max': 3,
 'response_received_count': 43,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 67,
 'scheduler/enqueued/memory': 67,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 3,
 'start_time': datetime.datetime(2018, 10, 27, 16, 54, 29, 430462)}
2018-10-28 00:54:55,503 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:54:57,783 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:54:57] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:00,895 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:00] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:03,988 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:03] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:07,084 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:07] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:10,194 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:10] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:13,290 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:13] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:16,369 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:16] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:19,458 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:19] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:22,544 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:22] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:25,650 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:25] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:28,737 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:28] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:32,794 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:32] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:36,775 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:36] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:40,895 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:40] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:45,076 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:45] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:48,734 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:48] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:52,892 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:52] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:55:56,826 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:55:56] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:00,980 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:00] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:04,944 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:04] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:08,749 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:08] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:12,727 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:12] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:16,724 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:16] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:20,728 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:20] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:24,791 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:24] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:29,193 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:29] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:32,733 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:32] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:36,994 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:36] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:40,768 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:40] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:44,990 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:44] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:48,803 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:48] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:53,330 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:53] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:56:57,262 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:56:57] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:00,738 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:00] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:05,089 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:05] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:08,719 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:08] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:12,726 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:12] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:16,999 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:16] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:20,773 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:20] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:24,717 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:24] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:28,721 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:28] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:32,722 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:32] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:36,715 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:36] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:40,721 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:40] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:45,135 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:45] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:49,067 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:49] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:52,734 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:52] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:57:56,876 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:57:56] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:00,896 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:00] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:04,763 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:04] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:08,726 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:08] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:12,999 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:12] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:16,718 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:16] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:21,019 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:21] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:24,795 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:24] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:28,720 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:28] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:32,722 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:32] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:37,200 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:37] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:40,739 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:40] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:44,716 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:44] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:47,442 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:58:48,734 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:48] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:58:52,875 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:58:52] "[37mPOST /results%3Fid%3D76197 HTTP/1.1[0m" 200 -
2018-10-28 00:59:02,738 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 00:59:03,572 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:03] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 00:59:05,650 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:05] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 00:59:13,211 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:13] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 00:59:13,361 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:13] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:59:13,431 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 00:59:13,449 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 00:59:13,454 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 00:59:13,483 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 00:59:13,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 00:59:13,585 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 00:59:13,587 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 00:59:13,618 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 00:59:13,619 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 00:59:13,625 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 00:59:13,627 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 00:59:16,453 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:16] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:59:18,119 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:59:18,300 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,303 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,305 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,306 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,308 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,311 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,313 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,341 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,343 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,348 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,356 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,359 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,360 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,361 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,363 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,367 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,369 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,386 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,394 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,400 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:18,402 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,434 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,434 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,434 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :6621
2018-10-28 00:59:18,436 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,436 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,436 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 00:59:18,442 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,472 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,473 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,473 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,473 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :24711
2018-10-28 00:59:18,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,475 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 00:59:18,476 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,510 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :53278
2018-10-28 00:59:18,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,511 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 00:59:18,512 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,548 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,548 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,549 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,549 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :88197
2018-10-28 00:59:18,551 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,551 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,551 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 00:59:18,552 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,586 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :106574
2018-10-28 00:59:18,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,588 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 00:59:18,589 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,632 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,633 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,633 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :115921
2018-10-28 00:59:18,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,636 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 00:59:18,636 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,670 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :151969
2018-10-28 00:59:18,674 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,675 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,675 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 00:59:18,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :215921
2018-10-28 00:59:18,865 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,865 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,866 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 00:59:18,866 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,911 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :248134
2018-10-28 00:59:18,916 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,917 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 00:59:18,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:18,955 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:18,956 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:18,957 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:18,957 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:18,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :255249
2018-10-28 00:59:18,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:18,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:18,968 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 00:59:18,969 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,016 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,017 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,017 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,018 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :286021
2018-10-28 00:59:19,025 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,027 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 00:59:19,028 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,075 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,078 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,079 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,081 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :319369
2018-10-28 00:59:19,088 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,088 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,089 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 00:59:19,089 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,132 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,135 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :351172
2018-10-28 00:59:19,140 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,141 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,141 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 00:59:19,142 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,185 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :373402
2018-10-28 00:59:19,192 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,193 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 00:59:19,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,253 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 00:59:19,268 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,270 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,271 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :435136
2018-10-28 00:59:19,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,279 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 00:59:19,280 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,324 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,327 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,328 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,328 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :468308
2018-10-28 00:59:19,335 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,335 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,336 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 00:59:19,336 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,386 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :506231
2018-10-28 00:59:19,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,394 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 00:59:19,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,438 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,440 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,441 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,441 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,442 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :540273
2018-10-28 00:59:19,450 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,450 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,450 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 00:59:19,451 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,499 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 00:59:19,521 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :619938
2018-10-28 00:59:19,537 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,538 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,538 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 00:59:19,539 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:19,565 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:19] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 00:59:19,606 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:19,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:19,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:19,611 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:19,612 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 00:59:19,623 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 00:59:19,623 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:19,623 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 00:59:21,058 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 00:59:21,059 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:21] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 00:59:21,106 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:21] "[37mGET /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:24,200 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:24] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:27,299 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:27] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:30,383 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:30] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:33,469 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:33] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:36,572 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:36] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:37,689 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:59:37,831 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,835 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,836 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,839 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,841 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,843 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,848 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,852 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,864 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,866 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,868 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,870 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,871 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,872 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,878 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,879 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,890 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,894 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,895 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,901 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 00:59:37,934 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 00:59:37,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 00:59:37,973 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 00:59:37,973 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 00:59:37,973 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:17349
2018-10-28 00:59:37,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :32780
2018-10-28 00:59:37,975 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 00:59:37,975 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 00:59:37,975 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm>
None
2018-10-28 00:59:38,021 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:59:39,678 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:39] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:42,186 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 00:59:42,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 00:59:42,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 00:59:42,302 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 19283,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 40,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1519975,
 'downloader/response_count': 43,
 'downloader/response_status_count/200': 43,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 16, 59, 42, 300972),
 'item_scraped_count': 21,
 'log_count/DEBUG': 131,
 'log_count/INFO': 114,
 'memusage/max': 63717376,
 'memusage/startup': 63717376,
 'request_depth_max': 3,
 'response_received_count': 43,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 67,
 'scheduler/enqueued/memory': 67,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 3,
 'start_time': datetime.datetime(2018, 10, 27, 16, 59, 13, 625898)}
2018-10-28 00:59:42,302 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 00:59:42,761 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:42] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:45,842 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:45] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:48,929 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:48] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:52,023 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:52] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:55,103 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:55] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 00:59:58,197 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 00:59:58] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 01:00:01,281 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:01] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 01:00:04,354 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:04] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 01:00:07,439 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:07] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 01:00:10,528 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:10] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 01:00:13,620 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:13] "[37mPOST /results%3Fid%3D17349 HTTP/1.1[0m" 200 -
2018-10-28 01:00:17,943 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 01:00:18,515 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:18] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 01:00:20,449 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:20] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 01:00:26,760 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:26] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 01:00:26,908 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:26] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:00:26,990 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 01:00:27,008 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 01:00:27,013 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 01:00:27,042 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 01:00:27,124 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 01:00:27,222 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 01:00:27,225 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 01:00:27,274 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 01:00:27,274 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 01:00:27,279 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 01:00:27,280 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 01:00:29,990 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:29] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:00:30,073 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:00:30,246 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,249 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,254 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,256 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,258 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,259 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,263 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,277 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,286 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,290 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,293 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,297 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,314 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,317 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,319 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,334 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,340 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,342 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,346 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,350 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:30,351 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,392 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,393 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7813
2018-10-28 01:00:30,395 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,395 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,395 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 01:00:30,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,438 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,438 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :30043
2018-10-28 01:00:30,440 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,441 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,441 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 01:00:30,441 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,476 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :63215
2018-10-28 01:00:30,477 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,477 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,477 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 01:00:30,478 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,520 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,521 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :95018
2018-10-28 01:00:30,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,524 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,524 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 01:00:30,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,573 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,577 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,578 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :127231
2018-10-28 01:00:30,581 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,582 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,582 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 01:00:30,583 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,630 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,630 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,630 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,631 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :155798
2018-10-28 01:00:30,633 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,634 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,634 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 01:00:30,635 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :190717
2018-10-28 01:00:30,676 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,676 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,677 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 01:00:30,677 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,704 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,705 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,706 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,706 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :196640
2018-10-28 01:00:30,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,710 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,711 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 01:00:30,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,766 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 01:00:30,776 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,782 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :276305
2018-10-28 01:00:30,787 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,788 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,788 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 01:00:30,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 01:00:30,889 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,891 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,891 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,892 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :338039
2018-10-28 01:00:30,897 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,898 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 01:00:30,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:30,950 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:30,955 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:30,956 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:30,956 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:30,958 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :374087
2018-10-28 01:00:30,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:30,973 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:30,973 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 01:00:30,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:31,047 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:31,050 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:31,050 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:31,050 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:31,052 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :404859
2018-10-28 01:00:31,058 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:31,058 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:31,059 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 01:00:31,066 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:31,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:31,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:31,120 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:31,120 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:31,121 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :414206
2018-10-28 01:00:31,126 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:31,126 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:31,126 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 01:00:31,127 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:31,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:31,210 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:31,212 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:31,213 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:31,214 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :498615
2018-10-28 01:00:31,226 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:31,227 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:31,227 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 01:00:31,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:31,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:31,298 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:31,299 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:31,299 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:31,301 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :536538
2018-10-28 01:00:31,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:31,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:31,310 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 01:00:31,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:31,357 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:31,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:31,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:31,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:31,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :554628
2018-10-28 01:00:31,370 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:31,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:31,371 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 01:00:31,372 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:31,414 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:31,419 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:31,420 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:31,421 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:31,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :573005
2018-10-28 01:00:31,438 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:31,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:31,439 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 01:00:31,440 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:31,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:31,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:31,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:31,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:31,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :607047
2018-10-28 01:00:31,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:31,528 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:31,529 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 01:00:31,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:31,770 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:31,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:31,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:31,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:31,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :670999
2018-10-28 01:00:31,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:31,784 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:31,785 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 01:00:31,785 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:31,833 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:31,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:31,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:31,836 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:31,837 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 01:00:31,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:00:31,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:31,847 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 01:00:33,089 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:33] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:00:33,804 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 01:00:33,805 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:33] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 01:00:33,853 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:33] "[37mGET /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:00:36,934 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:36] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:00:40,016 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:40] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:00:40,645 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:00:40,788 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,792 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,793 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,795 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,797 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,800 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,801 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,810 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,819 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,826 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,829 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,832 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,833 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,835 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,837 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,839 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,842 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,857 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,859 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,861 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:00:40,891 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:00:40,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:00:40,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:00:40,928 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:00:40,928 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:53352
2018-10-28 01:00:40,929 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7595
2018-10-28 01:00:40,929 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 01:00:40,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:00:40,930 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm>
None
2018-10-28 01:00:40,944 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 01:00:43,102 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:43] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:00:46,196 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:46] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:00:49,292 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:49] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:00:52,373 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:52] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:00:55,457 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:55] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:00:56,629 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:00:56,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 01:00:56,742 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 01:00:56,742 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 19739,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 40,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1519975,
 'downloader/response_count': 43,
 'downloader/response_status_count/200': 43,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 17, 0, 56, 741289),
 'item_scraped_count': 21,
 'log_count/DEBUG': 131,
 'log_count/INFO': 114,
 'memusage/max': 64045056,
 'memusage/startup': 64045056,
 'request_depth_max': 3,
 'response_received_count': 43,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 67,
 'scheduler/enqueued/memory': 67,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 3,
 'start_time': datetime.datetime(2018, 10, 27, 17, 0, 27, 279560)}
2018-10-28 01:00:56,742 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 01:00:58,538 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:00:58] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:01,636 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:01] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:04,736 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:04] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:07,820 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:07] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:10,901 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:10] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:13,988 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:13] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:17,105 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:17] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:20,200 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:20] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:23,291 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:23] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:26,399 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:26] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:29,503 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:29] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:32,590 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:32] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:35,703 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:35] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:38,788 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:38] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:41,876 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:41] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:44,970 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:44] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:48,068 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:48] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:51,158 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:51] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:54,239 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:54] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:01:57,328 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:01:57] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:00,411 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:00] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:03,499 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:03] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:06,602 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:06] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:09,693 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:09] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:12,779 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:12] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:16,223 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:16] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:19,318 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:19] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:22,403 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:22] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:25,508 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:25] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:28,593 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:28] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:31,690 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:31] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:34,802 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:34] "[37mPOST /results%3Fid%3D53352 HTTP/1.1[0m" 200 -
2018-10-28 01:02:38,326 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 01:02:39,287 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:39] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 01:02:41,165 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:41] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 01:02:48,211 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:48] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 01:02:48,356 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:48] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:02:48,418 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 01:02:48,436 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 01:02:48,441 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 01:02:48,472 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 01:02:48,501 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 01:02:48,564 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 01:02:48,566 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 01:02:48,597 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 01:02:48,598 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 01:02:48,605 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 01:02:48,606 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 01:02:51,454 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:51] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:02:52,905 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:02:53,096 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,103 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,198 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,234 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :19075
2018-10-28 01:02:53,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,237 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,237 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 01:02:53,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,278 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :56998
2018-10-28 01:02:53,281 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,281 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,282 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 01:02:53,323 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,327 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,343 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,378 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,389 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,425 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,465 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,466 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,467 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :90346
2018-10-28 01:02:53,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,469 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,469 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 01:02:53,471 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,474 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,507 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,508 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :123518
2018-10-28 01:02:53,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,511 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,512 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 01:02:53,512 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,546 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,547 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,548 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :154290
2018-10-28 01:02:53,550 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,551 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,551 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 01:02:53,553 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,554 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,560 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,561 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,613 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,614 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,614 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :163637
2018-10-28 01:02:53,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,621 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 01:02:53,622 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,670 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,673 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,674 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,675 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :185867
2018-10-28 01:02:53,678 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,679 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 01:02:53,681 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,689 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,732 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,734 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :218080
2018-10-28 01:02:53,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,738 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 01:02:53,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,801 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 01:02:53,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :279814
2018-10-28 01:02:53,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,821 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 01:02:53,821 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,860 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,863 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,863 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :314733
2018-10-28 01:02:53,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,869 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,869 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 01:02:53,870 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,920 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,923 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :348775
2018-10-28 01:02:53,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,932 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 01:02:53,934 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,936 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:53,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:53,978 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:53,980 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:53,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:53,981 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:53,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :355890
2018-10-28 01:02:53,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:53,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:53,988 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 01:02:53,988 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:54,035 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 01:02:54,048 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:54,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:54,051 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:54,052 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:54,053 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :435555
2018-10-28 01:02:54,059 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:54,060 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:54,060 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 01:02:54,061 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:54,062 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:54,064 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:54,067 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:54,121 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:54,123 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:54,124 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:54,124 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:54,126 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :471603
2018-10-28 01:02:54,133 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:54,133 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:54,134 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 01:02:54,134 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:54,175 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:54,178 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:54,178 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:54,178 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:54,180 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :503406
2018-10-28 01:02:54,186 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:54,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:54,187 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 01:02:54,188 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:54,193 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:54,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:54,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:54,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:54,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:54,242 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :521496
2018-10-28 01:02:54,250 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:54,250 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:54,251 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 01:02:54,251 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:54,290 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:54,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:54,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:54,293 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:54,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :527419
2018-10-28 01:02:54,302 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:54,302 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:54,303 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 01:02:54,303 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:54,346 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:54,350 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:54,350 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:54,350 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:54,352 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :555986
2018-10-28 01:02:54,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:54,361 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:54,361 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 01:02:54,362 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:02:54,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:54,423 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:54,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:54,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:54,427 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:54,428 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :640395
2018-10-28 01:02:54,437 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:54,437 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:54,437 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 01:02:54,465 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:02:54,550 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:02:54] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:02:54,675 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:02:54,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:02:54,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:02:54,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:02:54,681 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 01:02:54,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:02:54,691 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:02:54,691 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 01:03:06,422 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:03:06,585 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:06,589 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:06,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:06,745 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:06,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:06,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:06,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:06,752 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :736425
2018-10-28 01:03:06,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:06,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:06,762 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm>
None
2018-10-28 01:03:06,765 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:06,808 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:06,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:06,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:06,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:06,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :761979
2018-10-28 01:03:06,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:06,824 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:06,824 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm>
None
2018-10-28 01:03:06,826 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:06,827 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:06,828 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:06,833 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:06,864 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:06,867 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:06,874 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:06,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:06,990 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:06,996 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:06,996 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:06,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:06,999 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :788974
2018-10-28 01:03:07,015 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,016 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,016 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm>
None
2018-10-28 01:03:07,021 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,023 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,026 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,043 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:07,100 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:07,104 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:07,105 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:07,105 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:07,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :795867
2018-10-28 01:03:07,118 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,118 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,118 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm>
None
2018-10-28 01:03:07,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:07,158 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:07,162 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:07,162 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:07,162 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:07,164 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :797659
2018-10-28 01:03:07,180 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,180 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,181 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm>
None
2018-10-28 01:03:07,181 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:07,238 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:07,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:07,246 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:07,246 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:07,248 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :820782
2018-10-28 01:03:07,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,270 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm>
None
2018-10-28 01:03:07,270 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:07,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:07,323 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:07,324 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:07,324 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:07,325 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :835299
2018-10-28 01:03:07,336 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,337 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,337 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm>
None
2018-10-28 01:03:07,337 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:07,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:07,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:07,381 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:07,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:07,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :839078
2018-10-28 01:03:07,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,406 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,407 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm>
None
2018-10-28 01:03:07,407 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:07,490 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:07,500 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:07,501 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:07,501 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:07,505 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :874641
2018-10-28 01:03:07,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,523 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm>
None
2018-10-28 01:03:07,525 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,526 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,528 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,529 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,530 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,531 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,532 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,545 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:07,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:07,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>table of length 436:  åºå· å·¥ä½œä»»åŠ¡ ç‰µå¤´éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 åˆ¶è®¢â€œåä¸‰äº”â€åŒ»æ”¹è§„åˆ’ å›½åŠ¡é™¢åŒ»æ”¹åŠ ...
2018-10-28 01:03:07,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 436:  åºå· å·¥ä½œä»»åŠ¡ ç‰µå¤´éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 åˆ¶è®¢â€œåä¸‰äº”â€åŒ»æ”¹è§„åˆ’ å›½åŠ¡é™¢åŒ»æ”¹åŠ ...
2018-10-28 01:03:07,648 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:07,657 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:07,658 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:07,658 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:07,664 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :950912
2018-10-28 01:03:07,694 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,695 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,696 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm>
None
2018-10-28 01:03:07,696 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:07,758 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:07,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:07,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:07,764 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:07,767 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :988236
2018-10-28 01:03:07,779 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,780 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm>
None
2018-10-28 01:03:07,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:07,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:07,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:07,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:07,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:07,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1089315
2018-10-28 01:03:07,900 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:07,900 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:07,900 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm>
None
2018-10-28 01:03:07,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:08,008 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:08,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:08,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:08,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:08,016 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1093577
2018-10-28 01:03:08,031 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:08,032 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:08,032 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm>
None
2018-10-28 01:03:08,032 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:08,072 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 11110:  æ–°åç¤¾åŒ—äº¬4æœˆ26æ—¥ç”µ ä¸­å…±ä¸­å¤® å›½åŠ¡é™¢å…³äºå…¨é¢æŒ¯å…´ä¸œåŒ—åœ°åŒºç­‰è€å·¥ä¸šåŸºåœ°çš„è‹¥å¹²...
2018-10-28 01:03:08,125 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:08,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:08,138 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:08,139 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:08,147 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1160896
2018-10-28 01:03:08,188 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:08,188 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:08,188 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm>
None
2018-10-28 01:03:08,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:08,215 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 1947:  æ–°åç¤¾åŒ—äº¬4æœˆ28æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘äº†ã€Šå…³äºå»ºç«‹è´«å›°...
2018-10-28 01:03:08,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:08,248 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:08,248 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:08,248 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:08,251 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1173115
2018-10-28 01:03:08,275 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:08,276 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:08,276 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm>
None
2018-10-28 01:03:08,277 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:08,373 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:08,379 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:08,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:08,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:08,382 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1180566
2018-10-28 01:03:08,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:08,401 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:08,401 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm>
None
2018-10-28 01:03:08,401 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:08,429 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 3132:  ä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘ ã€Šå…³äºåšå¥½æ–°æ—¶æœŸæ•™è‚²å¯¹å¤–å¼€æ”¾å·¥ä½œçš„è‹¥å¹²æ„è§ã€‹...
2018-10-28 01:03:08,453 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:08,457 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:08,457 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:08,458 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:08,460 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1199781
2018-10-28 01:03:08,475 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:08,476 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:08,476 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm>
None
2018-10-28 01:03:08,476 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:08,515 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 35: å›½åŠ¡é™¢å…³äºåšå¥½å…¨é¢æ¨å¼€ è¥æ”¹å¢è¯•ç‚¹å·¥ä½œçš„é€šçŸ¥ å›½å‘æ˜ç”µã€”2016ã€•1å·
2018-10-28 01:03:08,558 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:08,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:08,570 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:08,570 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:08,575 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1207047
2018-10-28 01:03:08,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:08,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:08,611 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm>
None
2018-10-28 01:03:08,611 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:08,659 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:08,664 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:08,665 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:08,665 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:08,667 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1212426
2018-10-28 01:03:08,682 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:08,683 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:08,683 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm>
None
2018-10-28 01:03:08,684 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:08,802 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:08,811 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:08,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:08,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:08,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1259412
2018-10-28 01:03:08,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:08,834 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:08,835 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm>
None
2018-10-28 01:03:13,131 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:03:13,428 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/14/content_5063934.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:13,512 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/15/content_5064431.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:13,529 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:13,587 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:13,592 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:13,593 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:13,593 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:13,595 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1261063
2018-10-28 01:03:13,613 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:13,613 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:13,613 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/14/content_5063934.htm>
None
2018-10-28 01:03:13,615 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/11/content_5062973.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:13,617 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/07/content_5062098.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:13,618 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/18/content_5065392.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:13,622 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/28/content_5058928.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:13,622 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:13,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:13,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:13,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:13,680 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:13,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1266815
2018-10-28 01:03:13,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:13,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:13,716 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/15/content_5064431.htm>
None
2018-10-28 01:03:13,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/11/content_5062975.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:13,721 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/15/content_5064434.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:13,724 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/14/content_5063951.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:13,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:13,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:13,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:13,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:13,854 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:13,857 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1272081
2018-10-28 01:03:13,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:13,876 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:13,876 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/11/content_5062973.htm>
None
2018-10-28 01:03:13,877 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:13,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 2199: å±±ä¸œçœäººæ°‘æ”¿åºœï¼š ä½ çœå…³äºæŠ¥è¯·å®¡æ‰¹ä¸œè¥å¸‚åŸå¸‚æ€»ä½“è§„åˆ’çš„è¯·ç¤ºæ”¶æ‚‰ã€‚ç»å›½åŠ¡é™¢æ‰¹å‡†ï¼Œç°...
2018-10-28 01:03:13,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:13,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:13,970 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:13,971 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:13,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1286302
2018-10-28 01:03:14,004 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:14,004 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:14,004 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/07/content_5062098.htm>
None
2018-10-28 01:03:14,005 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:14,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:14,082 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:14,082 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:14,083 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:14,085 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1327614
2018-10-28 01:03:14,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:14,113 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:14,113 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/18/content_5065392.htm>
None
2018-10-28 01:03:14,114 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:14,230 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:14,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:14,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:14,236 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:14,239 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1329720
2018-10-28 01:03:14,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:14,260 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:14,260 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/28/content_5058928.htm>
None
2018-10-28 01:03:14,262 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/24/content_5057163.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,264 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/11/content_5062953.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,266 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/28/content_5059035.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,267 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/25/content_5058006.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,268 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/13/content_5063670.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,269 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/30/content_5059662.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,271 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-03/23/content_5056967.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,272 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/05/content_5061324.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,279 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:14,351 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:14,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:14,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:14,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:14,371 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1335140
2018-10-28 01:03:14,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:14,417 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:14,419 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/11/content_5062975.htm>
None
2018-10-28 01:03:14,421 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:14,519 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:14,534 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:14,535 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:14,536 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:14,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1426570
2018-10-28 01:03:14,597 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:14,598 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:14,599 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/15/content_5064434.htm>
None
2018-10-28 01:03:14,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:14,669 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>table of length 965:  åºå· å·¥ ä½œ ä»» åŠ¡ ç‰µå¤´è´Ÿè´£éƒ¨é—¨ 1 å±…æ°‘æ¶ˆè´¹ä»·æ ¼æ¶¨å¹…3%å·¦å³ å‘å±•æ”¹é©å§” ...
2018-10-28 01:03:14,670 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 965:  åºå· å·¥ ä½œ ä»» åŠ¡ ç‰µå¤´è´Ÿè´£éƒ¨é—¨ 1 å±…æ°‘æ¶ˆè´¹ä»·æ ¼æ¶¨å¹…3%å·¦å³ å‘å±•æ”¹é©å§” ...
2018-10-28 01:03:14,707 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:14,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:14,724 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:14,726 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:14,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1443675
2018-10-28 01:03:14,793 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:14,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:14,797 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/14/content_5063951.htm>
None
2018-10-28 01:03:14,800 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-03/31/content_5060062.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,802 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/06/content_5061542.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,808 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/01/content_5060345.htm> (referer: http://sousuo.gov.cn/column/30469/36.htm)
2018-10-28 01:03:14,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:14,901 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:14,907 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:14,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:14,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:14,911 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1512488
2018-10-28 01:03:14,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:14,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:14,933 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/24/content_5057163.htm>
None
2018-10-28 01:03:14,933 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:15,017 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:15,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:15,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:15,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:15,030 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1517613
2018-10-28 01:03:15,059 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:15,060 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:15,060 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/11/content_5062953.htm>
None
2018-10-28 01:03:15,060 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:15,130 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:15,136 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:15,136 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:15,137 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:15,140 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1537928
2018-10-28 01:03:15,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:15,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:15,189 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/28/content_5059035.htm>
None
2018-10-28 01:03:15,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:15,287 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:15,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:15,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:15,295 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:15,298 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1549561
2018-10-28 01:03:15,320 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:15,320 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:15,321 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/25/content_5058006.htm>
None
2018-10-28 01:03:15,321 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:15,443 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:15,455 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:15,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:15,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:15,460 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1620622
2018-10-28 01:03:15,503 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:15,503 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:15,503 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/13/content_5063670.htm>
None
2018-10-28 01:03:15,504 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:15,576 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:15,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:15,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:15,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:15,588 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1635025
2018-10-28 01:03:15,613 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:15,614 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:15,614 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/30/content_5059662.htm>
None
2018-10-28 01:03:15,614 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:15,645 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 4068:  æ–°åç¤¾åŒ—äº¬3æœˆ23æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘äº†ã€Šå¥å…¨è½å®ç¤¾ä¼š...
2018-10-28 01:03:15,680 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:15,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:15,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:15,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:15,690 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1660266
2018-10-28 01:03:15,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:15,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:15,712 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-03/23/content_5056967.htm>
None
2018-10-28 01:03:15,712 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:15,787 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:15,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:15,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:15,796 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:15,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1672478
2018-10-28 01:03:15,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:15,821 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:15,821 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/05/content_5061324.htm>
None
2018-10-28 01:03:15,830 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:15,910 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:15,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:15,918 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:15,919 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:15,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1745155
2018-10-28 01:03:15,953 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:15,954 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:15,954 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-03/31/content_5060062.htm>
None
2018-10-28 01:03:15,955 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:16,057 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:16,066 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:16,066 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:16,066 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:16,069 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1756482
2018-10-28 01:03:16,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:16,098 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:16,098 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/06/content_5061542.htm>
None
2018-10-28 01:03:16,099 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:16,187 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:16,197 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:16,197 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:16,197 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:65742
2018-10-28 01:03:16,200 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1788328
2018-10-28 01:03:16,227 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:16,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:16,228 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/01/content_5060345.htm>
None
2018-10-28 01:03:18,246 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-28 01:03:18,247 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (shutdown)
2018-10-28 01:03:18,311 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-28 01:03:18,313 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://sousuo.gov.cn/column/30469/37.htm via http://localhost:8050/execute> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-10-28 01:03:18,334 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 01:03:18,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 01:03:18,367 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 28762,
 'downloader/request_count': 64,
 'downloader/request_method_count/GET': 60,
 'downloader/request_method_count/POST': 4,
 'downloader/response_bytes': 2116827,
 'downloader/response_count': 63,
 'downloader/response_status_count/200': 63,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 10, 27, 17, 3, 18, 334784),
 'item_scraped_count': 60,
 'log_count/DEBUG': 318,
 'log_count/INFO': 311,
 'memusage/max': 63717376,
 'memusage/startup': 63717376,
 'request_depth_max': 3,
 'response_received_count': 63,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 68,
 'scheduler/dequeued/memory': 68,
 'scheduler/enqueued': 69,
 'scheduler/enqueued/memory': 69,
 'splash/execute/request_count': 4,
 'splash/execute/response_count/200': 3,
 'start_time': datetime.datetime(2018, 10, 27, 17, 2, 48, 605094)}
2018-10-28 01:03:18,367 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (shutdown)
2018-10-28 01:03:46,366 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 01:03:47,933 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:03:47] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 01:03:49,891 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:03:49] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 01:03:56,531 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:03:56] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 01:03:56,620 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:03:56] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:03:56,767 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 01:03:56,782 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 01:03:56,787 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 01:03:56,814 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 01:03:56,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 01:03:56,908 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 01:03:56,911 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 01:03:56,938 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 01:03:56,939 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 01:03:56,943 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 01:03:56,944 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 01:03:59,518 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:03:59,691 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,693 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,699 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,701 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,704 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,709 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,729 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,731 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,743 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,745 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,750 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,758 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,761 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,763 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,767 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:03:59] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:03:59,768 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,772 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,774 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,782 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,795 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,797 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:03:59,798 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:59,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:59,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:59,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:59,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:03:59,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7813
2018-10-28 01:03:59,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:59,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:59,847 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 01:03:59,861 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:59,897 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:59,897 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:59,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:59,898 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:03:59,899 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :30043
2018-10-28 01:03:59,900 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:59,900 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:59,900 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 01:03:59,901 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:59,929 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:59,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:59,930 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:59,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:03:59,931 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :48133
2018-10-28 01:03:59,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:59,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:59,933 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 01:03:59,933 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:03:59,971 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:03:59,972 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:03:59,973 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:03:59,973 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:03:59,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :66510
2018-10-28 01:03:59,976 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:03:59,977 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:03:59,977 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 01:03:59,980 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,053 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,054 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,055 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,055 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,056 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :150919
2018-10-28 01:04:00,059 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,059 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,060 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 01:04:00,060 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,105 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,106 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :188842
2018-10-28 01:04:00,110 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,110 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,111 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 01:04:00,111 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,162 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 01:04:00,177 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,182 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,182 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,183 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,184 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :268507
2018-10-28 01:04:00,189 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,190 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,190 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 01:04:00,191 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,255 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :299279
2018-10-28 01:04:00,265 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,265 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,266 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 01:04:00,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,323 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,325 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,325 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,325 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,326 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :308626
2018-10-28 01:04:00,331 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,331 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,332 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 01:04:00,333 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,373 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,375 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,376 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,377 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :341798
2018-10-28 01:04:00,383 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,384 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 01:04:00,411 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,491 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,496 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :375840
2018-10-28 01:04:00,502 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,503 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,503 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 01:04:00,509 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,555 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,557 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,558 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,558 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,559 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :409188
2018-10-28 01:04:00,565 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,565 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,566 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 01:04:00,567 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,809 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :473140
2018-10-28 01:04:00,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,821 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,821 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 01:04:00,821 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,881 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,881 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,882 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,883 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :509188
2018-10-28 01:04:00,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,891 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 01:04:00,891 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,924 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:00,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:00,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:00,927 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:00,929 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :515111
2018-10-28 01:04:00,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:00,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:00,936 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 01:04:00,937 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:00,998 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 01:04:01,017 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:01,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:01,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:01,028 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:01,035 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :576845
2018-10-28 01:04:01,054 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:01,055 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:01,055 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 01:04:01,055 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:01,141 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:01,145 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:01,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:01,146 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:01,149 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :608648
2018-10-28 01:04:01,170 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:01,171 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:01,171 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 01:04:01,172 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:01,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:01,263 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:01,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:01,264 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:01,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :640861
2018-10-28 01:04:01,276 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:01,276 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:01,277 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 01:04:01,277 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:01,325 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:01,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:01,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:01,330 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:01,332 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :675780
2018-10-28 01:04:01,341 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:01,342 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:01,342 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 01:04:01,342 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:01,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:01,398 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:01,398 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:01,399 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:01,400 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 01:04:01,410 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:01,410 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:01,410 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 01:04:02,874 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:04:02] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:04:05,961 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:04:05] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:04:07,502 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:04:07,645 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,656 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,658 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,661 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,666 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,669 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,671 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,673 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,676 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,691 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,699 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,701 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,706 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,716 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,718 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,719 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,722 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,726 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,737 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,740 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:04:07,748 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:07,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 1947:  æ–°åç¤¾åŒ—äº¬4æœˆ28æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘äº†ã€Šå…³äºå»ºç«‹è´«å›°...
2018-10-28 01:04:07,808 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:07,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:07,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:07,815 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:07,819 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :716566
2018-10-28 01:04:07,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:07,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:07,835 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm>
None
2018-10-28 01:04:07,886 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:07,937 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:07,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:07,945 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:07,946 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:07,949 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :739689
2018-10-28 01:04:07,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:07,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:07,967 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm>
None
2018-10-28 01:04:07,967 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,002 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 3132:  ä¸­å…±ä¸­å¤®åŠå…¬å…ã€å›½åŠ¡é™¢åŠå…¬å…å°å‘ ã€Šå…³äºåšå¥½æ–°æ—¶æœŸæ•™è‚²å¯¹å¤–å¼€æ”¾å·¥ä½œçš„è‹¥å¹²æ„è§ã€‹...
2018-10-28 01:04:08,038 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,045 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,046 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,046 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,049 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :758904
2018-10-28 01:04:08,064 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,065 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,065 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm>
None
2018-10-28 01:04:08,066 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,112 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,116 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,116 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,117 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :773421
2018-10-28 01:04:08,130 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,130 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,131 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm>
None
2018-10-28 01:04:08,131 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,195 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,202 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,204 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,208 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :810745
2018-10-28 01:04:08,228 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,229 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,229 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm>
None
2018-10-28 01:04:08,231 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,299 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,302 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,303 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,303 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,306 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :837740
2018-10-28 01:04:08,318 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,318 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,319 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm>
None
2018-10-28 01:04:08,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,394 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,401 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,402 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,403 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,405 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :869818
2018-10-28 01:04:08,435 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,437 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,437 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm>
None
2018-10-28 01:04:08,439 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,516 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>table of length 436:  åºå· å·¥ä½œä»»åŠ¡ ç‰µå¤´éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 åˆ¶è®¢â€œåä¸‰äº”â€åŒ»æ”¹è§„åˆ’ å›½åŠ¡é™¢åŒ»æ”¹åŠ ...
2018-10-28 01:04:08,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 436:  åºå· å·¥ä½œä»»åŠ¡ ç‰µå¤´éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 åˆ¶è®¢â€œåä¸‰äº”â€åŒ»æ”¹è§„åˆ’ å›½åŠ¡é™¢åŒ»æ”¹åŠ ...
2018-10-28 01:04:08,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,548 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,549 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,549 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,551 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :946089
2018-10-28 01:04:08,563 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,564 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,564 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm>
None
2018-10-28 01:04:08,565 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,635 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,637 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,638 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,641 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :971643
2018-10-28 01:04:08,669 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,669 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,670 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm>
None
2018-10-28 01:04:08,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,727 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,731 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,733 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :973435
2018-10-28 01:04:08,748 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,749 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm>
None
2018-10-28 01:04:08,750 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,803 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,812 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,816 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,820 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :980886
2018-10-28 01:04:08,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,848 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,848 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm>
None
2018-10-28 01:04:08,849 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:08,936 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:08,941 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:08,942 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:08,942 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:08,944 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :986265
2018-10-28 01:04:08,959 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:08,960 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:08,960 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm>
None
2018-10-28 01:04:08,961 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:09,012 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:09,026 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:09,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:09,027 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:09,036 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :993158
2018-10-28 01:04:09,070 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:09,072 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:09,074 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm>
None
2018-10-28 01:04:09,076 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:09,084 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:04:09] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:04:09,198 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:09,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:09,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:09,205 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:09,209 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1094237
2018-10-28 01:04:09,262 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:09,265 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:09,265 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm>
None
2018-10-28 01:04:09,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:09,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:09,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:09,368 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:09,369 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:09,372 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1129800
2018-10-28 01:04:09,389 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:09,389 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:09,389 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm>
None
2018-10-28 01:04:09,390 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:09,426 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 11110:  æ–°åç¤¾åŒ—äº¬4æœˆ26æ—¥ç”µ ä¸­å…±ä¸­å¤® å›½åŠ¡é™¢å…³äºå…¨é¢æŒ¯å…´ä¸œåŒ—åœ°åŒºç­‰è€å·¥ä¸šåŸºåœ°çš„è‹¥å¹²...
2018-10-28 01:04:09,483 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:09,488 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:09,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:09,489 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:09,494 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1197119
2018-10-28 01:04:09,541 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:09,543 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:09,544 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm>
None
2018-10-28 01:04:09,544 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:09,595 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:09,600 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:09,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:09,601 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:09,603 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1200898
2018-10-28 01:04:09,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:09,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:09,620 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm>
None
2018-10-28 01:04:09,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:09,643 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>div{01} of length 35: å›½åŠ¡é™¢å…³äºåšå¥½å…¨é¢æ¨å¼€ è¥æ”¹å¢è¯•ç‚¹å·¥ä½œçš„é€šçŸ¥ å›½å‘æ˜ç”µã€”2016ã€•1å·
2018-10-28 01:04:09,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:09,678 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:09,678 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:09,680 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:09,688 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1208164
2018-10-28 01:04:09,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:09,716 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:09,717 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm>
None
2018-10-28 01:04:09,723 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:09,838 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:09,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:09,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:09,844 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:09,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1255150
2018-10-28 01:04:09,865 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:09,865 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:09,865 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm>
None
2018-10-28 01:04:09,868 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:04:09,997 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:04:10,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:04:10,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:04:10,011 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:88055
2018-10-28 01:04:10,014 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :1259412
2018-10-28 01:04:10,034 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:04:10,034 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:04:10,034 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm>
None
2018-10-28 01:04:11,199 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-28 01:04:11,200 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (shutdown)
2018-10-28 01:04:11,210 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-28 01:04:11,215 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-10-28 01:04:11,235 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 01:04:11,266 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 01:04:11,267 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 19655,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 40,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1495991,
 'downloader/response_count': 42,
 'downloader/response_status_count/200': 42,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 10, 27, 17, 4, 11, 235106),
 'item_scraped_count': 40,
 'log_count/DEBUG': 213,
 'log_count/INFO': 211,
 'memusage/max': 63905792,
 'memusage/startup': 63905792,
 'request_depth_max': 2,
 'response_received_count': 42,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 47,
 'scheduler/enqueued/memory': 47,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 2,
 'start_time': datetime.datetime(2018, 10, 27, 17, 3, 56, 943564)}
2018-10-28 01:04:11,267 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (shutdown)
2018-10-28 01:05:21,868 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 01:05:24,159 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:05:24] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 01:05:26,110 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:05:26] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 01:05:33,375 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:05:33] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 01:05:33,485 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:05:33] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:05:33,601 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 01:05:33,617 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 01:05:33,621 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 01:05:33,648 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 01:05:33,679 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 01:05:33,741 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 01:05:33,743 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 01:05:33,771 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 01:05:33,772 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 01:05:33,779 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 01:05:33,780 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 01:05:36,573 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:05:36] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:05:37,964 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:05:38,164 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,167 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,169 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,171 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,172 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,174 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,176 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,178 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,210 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,216 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,221 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,226 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,230 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,232 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,234 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,240 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,245 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,257 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,267 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,269 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:05:38,270 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,310 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :32501
2018-10-28 01:05:38,313 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,313 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,313 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 01:05:38,321 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,365 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :70424
2018-10-28 01:05:38,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,367 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 01:05:38,367 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,409 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,411 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,412 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,413 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :103772
2018-10-28 01:05:38,415 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,416 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 01:05:38,416 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,456 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,457 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,458 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,458 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,459 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :132339
2018-10-28 01:05:38,462 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,463 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,463 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 01:05:38,463 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,517 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,518 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,519 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :154569
2018-10-28 01:05:38,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,524 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,524 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 01:05:38,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,560 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,561 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,561 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,562 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :185341
2018-10-28 01:05:38,565 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,565 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,565 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 01:05:38,566 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,603 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,604 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,604 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,605 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,606 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :221389
2018-10-28 01:05:38,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,609 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,610 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 01:05:38,610 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,693 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 01:05:38,711 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,715 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,719 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,720 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :283123
2018-10-28 01:05:38,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,738 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,739 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 01:05:38,740 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,786 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,790 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,791 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,793 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :317165
2018-10-28 01:05:38,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,801 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 01:05:38,814 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,867 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,869 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,869 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,870 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,871 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :326512
2018-10-28 01:05:38,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,876 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 01:05:38,879 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,917 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:38,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:38,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:38,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:38,923 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :344602
2018-10-28 01:05:38,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:38,932 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:38,933 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 01:05:38,933 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:38,999 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:39,004 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:39,005 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:39,005 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:39,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :379521
2018-10-28 01:05:39,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:39,021 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:39,022 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 01:05:39,022 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:39,060 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:39,063 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:39,063 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:39,063 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:39,064 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :385444
2018-10-28 01:05:39,071 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:39,071 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:39,071 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 01:05:39,072 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:39,143 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:39,147 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:39,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:39,148 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:39,153 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :469853
2018-10-28 01:05:39,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:39,169 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:39,170 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 01:05:39,171 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:39,240 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 01:05:39,253 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:39,256 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:39,256 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:39,257 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:39,259 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :549518
2018-10-28 01:05:39,268 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:39,268 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:39,268 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 01:05:39,269 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:39,315 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:39,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:39,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:39,319 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:39,321 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :567895
2018-10-28 01:05:39,328 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:39,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:39,329 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 01:05:39,329 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:39,380 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:39,384 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:39,385 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:39,385 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:39,387 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :575010
2018-10-28 01:05:39,407 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:39,408 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:39,408 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 01:05:39,409 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:39,468 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:39,471 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:39,472 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:39,472 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:39,473 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :607223
2018-10-28 01:05:39,483 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:39,483 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:39,484 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 01:05:39,484 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:39,711 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:05:39] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:05:39,756 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:39,760 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:39,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:39,761 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:39,763 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :671175
2018-10-28 01:05:39,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:39,774 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:39,775 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 01:05:39,775 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:05:39,835 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:05:39,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:05:39,839 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:05:39,840 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:76182
2018-10-28 01:05:39,842 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 01:05:39,852 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:05:39,853 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:05:39,853 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 01:05:42,805 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:05:42] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:05:45,910 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:05:45] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:05:49,009 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:05:49] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:05:49,227 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:258] - INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-10-28 01:05:49,228 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (shutdown)
2018-10-28 01:05:49,244 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:265] - INFO: Received SIGTERM twice, forcing unclean shutdown
2018-10-28 01:05:49,246 - /anaconda3/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py[line:75] - DEBUG: Retrying <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-10-28 01:05:49,258 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 01:05:49,272 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 01:05:49,273 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 10112,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 20,
 'downloader/request_method_count/POST': 2,
 'downloader/response_bytes': 876943,
 'downloader/response_count': 21,
 'downloader/response_status_count/200': 21,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2018, 10, 27, 17, 5, 49, 258429),
 'item_scraped_count': 20,
 'log_count/DEBUG': 106,
 'log_count/INFO': 111,
 'memusage/max': 63791104,
 'memusage/startup': 63787008,
 'request_depth_max': 1,
 'response_received_count': 21,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'splash/execute/request_count': 2,
 'splash/execute/response_count/200': 1,
 'start_time': datetime.datetime(2018, 10, 27, 17, 5, 33, 779033)}
2018-10-28 01:05:49,273 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (shutdown)
2018-10-28 01:10:40,139 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO:  * Running on http://127.0.0.1:9998/ (Press CTRL+C to quit)
2018-10-28 01:10:43,194 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:10:43] "[37mGET / HTTP/1.1[0m" 200 -
2018-10-28 01:10:45,612 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:10:45] "[37mPOST / HTTP/1.1[0m" 200 -
2018-10-28 01:10:52,447 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:10:52] "[37mPOST /scrapy HTTP/1.1[0m" 200 -
2018-10-28 01:10:52,586 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:10:52] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:10:52,678 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:146] - INFO: Scrapy 1.5.1 started (bot: ScrapyTool)
2018-10-28 01:10:52,701 - /anaconda3/lib/python3.6/site-packages/scrapy/utils/log.py[line:149] - INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.3.1, Platform Darwin-17.7.0-x86_64-i386-64bit
2018-10-28 01:10:52,706 - /anaconda3/lib/python3.6/site-packages/scrapy/crawler.py[line:38] - INFO: Overridden settings: {'BOT_NAME': 'ScrapyTool', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'ScrapyTool.spiders', 'RETRY_TIMES': 10, 'SPIDER_MODULES': ['ScrapyTool.spiders']}
2018-10-28 01:10:52,737 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2018-10-28 01:10:52,769 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:84] - DEBUG: [spider]current table name is : scrapy_gov_policy_explain
2018-10-28 01:10:52,833 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapyTool.ScrapyTool.middlewares.MyUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-28 01:10:52,835 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-28 01:10:52,862 - /anaconda3/lib/python3.6/site-packages/scrapy/middleware.py[line:53] - INFO: Enabled item pipelines:
['ScrapyTool.pipelines.RedisPipeline',
 'ScrapyTool.pipelines.ScrapytoolPipeline']
2018-10-28 01:10:52,863 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:256] - INFO: Spider opened
2018-10-28 01:10:52,873 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/logstats.py[line:48] - INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-28 01:10:52,875 - /anaconda3/lib/python3.6/site-packages/scrapy/extensions/telnet.py[line:60] - DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-28 01:10:57,198 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:10:57,374 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,385 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,387 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,389 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,392 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,393 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,399 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,409 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,420 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,428 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,437 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,440 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,441 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,444 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,446 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,452 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,456 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,462 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,474 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,479 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:57,523 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:57,524 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:57,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:57,525 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:57,526 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :22928
2018-10-28 01:10:57,527 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:57,527 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:57,528 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/19/content_5074696.htm>
None
2018-10-28 01:10:57,529 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:10:57,539 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:57,583 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:57,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:57,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:57,584 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:57,585 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :51495
2018-10-28 01:10:57,586 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:57,586 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:57,587 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/16/content_5073722.htm>
None
2018-10-28 01:10:57,587 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:57,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:57,616 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:57,617 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:57,617 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:57,618 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :69872
2018-10-28 01:10:57,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:57,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:57,620 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071534.htm>
None
2018-10-28 01:10:57,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:57,666 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:57,669 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:57,670 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:57,671 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:57,672 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :101675
2018-10-28 01:10:57,674 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:57,675 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:57,675 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/06/content_5070778.htm>
None
2018-10-28 01:10:57,676 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:57,677 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:10:57] "[37mPOST /result HTTP/1.1[0m" 200 -
2018-10-28 01:10:57,735 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:57,736 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:57,737 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:57,739 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:57,741 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :134847
2018-10-28 01:10:57,747 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:57,748 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:57,748 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/18/content_5074416.htm>
None
2018-10-28 01:10:57,749 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:57,793 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:57,794 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:57,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:57,795 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:57,796 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :172770
2018-10-28 01:10:57,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:57,799 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:57,800 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/12/content_5072633.htm>
None
2018-10-28 01:10:57,800 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:57,862 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing div{01}>#UCAP-CONTENT.pages_content of length 13133:  æ–°åç¤¾åŒ—äº¬5æœˆ19æ—¥ç”µ è¿‘æ—¥ï¼Œä¸­å…±ä¸­å¤®ã€å›½åŠ¡é™¢å°å‘äº†ã€Šå›½å®¶åˆ›æ–°é©±åŠ¨å‘å±•æˆ˜ç•¥çº²è¦...
2018-10-28 01:10:57,875 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:57,877 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:57,877 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:57,878 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:57,879 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :252435
2018-10-28 01:10:57,888 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:57,889 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:57,889 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/xinwen/2016-05/19/content_5074812.htm>
None
2018-10-28 01:10:57,890 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:57,966 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:57,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:57,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:57,968 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:57,969 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :261782
2018-10-28 01:10:57,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:57,974 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:57,975 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-06/01/content_5078729.htm>
None
2018-10-28 01:10:57,975 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,004 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,006 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,007 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :267705
2018-10-28 01:10:58,011 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,012 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,012 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/25/content_5076639.htm>
None
2018-10-28 01:10:58,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,243 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,247 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :331657
2018-10-28 01:10:58,251 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,252 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,252 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/26/content_5077076.htm>
None
2018-10-28 01:10:58,265 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,309 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,311 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,312 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,313 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :349747
2018-10-28 01:10:58,317 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,318 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,318 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075016.htm>
None
2018-10-28 01:10:58,320 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,360 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,363 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,364 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,366 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :381960
2018-10-28 01:10:58,389 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,390 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,390 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/17/content_5074120.htm>
None
2018-10-28 01:10:58,391 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,443 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,445 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,446 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,447 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,448 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :389075
2018-10-28 01:10:58,460 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,461 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,461 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/10/content_5071941.htm>
None
2018-10-28 01:10:58,462 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,545 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,551 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,553 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,554 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,557 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :423994
2018-10-28 01:10:58,568 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,569 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,569 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/20/content_5075099.htm>
None
2018-10-28 01:10:58,570 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,617 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,619 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,620 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,621 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :457342
2018-10-28 01:10:58,627 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,627 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,628 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/11/content_5072221.htm>
None
2018-10-28 01:10:58,628 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,722 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/Article.py[line:343] - DEBUG: Not removing td.b12c>table of length 1090:  åºå· é‡ç‚¹ä»»åŠ¡ è´£ä»»éƒ¨é—¨ æ—¶é—´è¿›åº¦ 1 å‘å¸ƒä¸€æ‰¹äº§ä¸šè½¬å‹å‡çº§å‘å±•æ€¥éœ€çš„ç§‘æŠ€æˆæœ...
2018-10-28 01:10:58,773 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,778 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,780 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :519076
2018-10-28 01:10:58,788 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,789 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,789 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/09/content_5071536.htm>
None
2018-10-28 01:10:58,790 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,843 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,845 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,846 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,847 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :549848
2018-10-28 01:10:58,855 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,855 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,855 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/13/content_5073049.htm>
None
2018-10-28 01:10:58,856 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,908 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,911 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,911 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,912 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,913 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :583890
2018-10-28 01:10:58,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:58,921 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:58,921 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/24/content_5076241.htm>
None
2018-10-28 01:10:58,922 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:58,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:58,993 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:58,993 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:58,993 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:58,995 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :619938
2018-10-28 01:10:59,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:59,010 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:59,011 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/30/content_5078070.htm>
None
2018-10-28 01:10:59,013 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:10:59,103 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:10:59,107 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:10:59,108 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:10:59,108 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:10:59,110 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :704347
2018-10-28 01:10:59,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:start
2018-10-28 01:10:59,119 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:10:59,120 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-05/31/content_5078377.htm>
None
2018-10-28 01:11:00,187 - /Users/tian/zaluan/ScrapyA/app/views.py[line:371] - INFO: ç”¨æˆ·é€‰æ‹©æ˜¯å¦å­˜å‚¨çˆ¬å–ç»“æœ:no
2018-10-28 01:11:00,188 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:11:00] "[32mPOST /crawling HTTP/1.1[0m" 302 -
2018-10-28 01:11:00,235 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:11:00] "[37mGET /results%3Fid%3D64446 HTTP/1.1[0m" 200 -
2018-10-28 01:11:03,694 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/35.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:11:03,842 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,844 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066570.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,848 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/xinwen/2016-04/29/content_5069311.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,849 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/28/content_5068878.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,851 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/2016-04/26/content_5068242.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,853 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068352.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,855 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/30/content_5069485.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,857 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070199.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,874 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/20/content_5066278.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,876 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/22/content_5066842.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,880 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070516.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,882 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/21/content_5066526.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,892 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/04/content_5070227.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,894 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068058.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,895 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/27/content_5068405.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,897 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/03/content_5069963.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,903 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/19/content_5065730.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,915 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-05/05/content_5070314.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,918 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/25/content_5067597.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,921 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://www.gov.cn/zhengce/content/2016-04/26/content_5068131.htm> (referer: http://sousuo.gov.cn/column/30469/35.htm)
2018-10-28 01:11:03,945 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:267] - DEBUG: ---crawl start---
2018-10-28 01:11:03,982 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:109] - DEBUG: piplines:start to Redis items
2018-10-28 01:11:03,983 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:40] - INFO: helloworld1
2018-10-28 01:11:03,984 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:42] - INFO: helloworld2
2018-10-28 01:11:03,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:43] - INFO: the id in pipeline:64446
2018-10-28 01:11:03,985 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:44] - INFO: the userinfo in pipeline is :7595
2018-10-28 01:11:03,986 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:49] - INFO: the flag in pipelines:no
2018-10-28 01:11:03,987 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/pipelines.py[line:51] - DEBUG: ç”¨æˆ·è¿˜æ²¡æœ‰ç‚¹å‡»ä¿å­˜æŒ‰é’®
2018-10-28 01:11:03,987 - /anaconda3/lib/python3.6/site-packages/scrapy/core/scraper.py[line:237] - DEBUG: Scraped from <200 http://www.gov.cn/zhengce/content/2016-04/30/content_5069490.htm>
None
2018-10-28 01:11:04,001 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:295] - INFO: Closing spider (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 01:11:05,331 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:11:05] "[37mPOST /results%3Fid%3D64446 HTTP/1.1[0m" 200 -
2018-10-28 01:11:10,441 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:11:10] "[37mPOST /results%3Fid%3D64446 HTTP/1.1[0m" 200 -
2018-10-28 01:11:15,533 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:11:15] "[37mPOST /results%3Fid%3D64446 HTTP/1.1[0m" 200 -
2018-10-28 01:11:19,128 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:238] - DEBUG: Crawled (200) <GET http://sousuo.gov.cn/column/30469/36.htm via http://localhost:8050/execute> (referer: None)
2018-10-28 01:11:19,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:344] - INFO: spiderå…³é—­äº†
2018-10-28 01:11:19,245 - /Users/tian/zaluan/ScrapyA/scrapyTool/ScrapyTool/spiders/toolSpider.py[line:355] - INFO: aha,the spider closed
2018-10-28 01:11:19,246 - /anaconda3/lib/python3.6/site-packages/scrapy/statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 18983,
 'downloader/request_count': 43,
 'downloader/request_method_count/GET': 40,
 'downloader/request_method_count/POST': 3,
 'downloader/response_bytes': 1519975,
 'downloader/response_count': 43,
 'downloader/response_status_count/200': 43,
 'finish_reason': 'ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no',
 'finish_time': datetime.datetime(2018, 10, 27, 17, 11, 19, 245073),
 'item_scraped_count': 21,
 'log_count/DEBUG': 131,
 'log_count/INFO': 114,
 'memusage/max': 63946752,
 'memusage/startup': 63946752,
 'request_depth_max': 3,
 'response_received_count': 43,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 67,
 'scheduler/enqueued/memory': 67,
 'splash/execute/request_count': 3,
 'splash/execute/response_count/200': 3,
 'start_time': datetime.datetime(2018, 10, 27, 17, 10, 52, 873656)}
2018-10-28 01:11:19,246 - /anaconda3/lib/python3.6/site-packages/scrapy/core/engine.py[line:326] - INFO: Spider closed (ç”¨æˆ·ä¸æƒ³ç»§ç»­çˆ¬å–no)
2018-10-28 01:11:20,626 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:11:20] "[37mPOST /results%3Fid%3D64446 HTTP/1.1[0m" 200 -
2018-10-28 01:11:25,718 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:11:25] "[37mPOST /results%3Fid%3D64446 HTTP/1.1[0m" 200 -
2018-10-28 01:11:30,956 - /anaconda3/lib/python3.6/site-packages/werkzeug/_internal.py[line:88] - INFO: 127.0.0.1 - - [28/Oct/2018 01:11:30] "[37mPOST /results%3Fid%3D64446 HTTP/1.1[0m" 200 -
